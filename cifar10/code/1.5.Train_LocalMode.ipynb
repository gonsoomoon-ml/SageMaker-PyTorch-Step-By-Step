{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 1.5] 로컬 모드 훈련\n",
    "\n",
    "본 워크샵의 모든 노트북은 `conda_python3` 여기에서 작업 합니다.\n",
    "\n",
    "이 노트북은 아래와 같은 작업을 합니다.\n",
    "- 아래는 세이지메이커의 어떤 피쳐도 사용하지 않고, PyTorch 만을 사용해서 훈련 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch CIFAR-10 local training  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"sagemaker/DEMO-pytorch-cnn-cifar10\"\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance type = local_gpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "instance_type = \"local\"\n",
    "\n",
    "try:\n",
    "    if subprocess.call(\"nvidia-smi\") == 0:\n",
    "        ## Set type to GPU if one is present\n",
    "        instance_type = \"local_gpu\"\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"Instance type = \" + instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the data\n",
    "We use the ```sagemaker.Session.upload_data``` function to upload our datasets to an S3 location. The return value inputs identifies the location -- we will use this later when we start the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3 inputs:  s3://sagemaker-ap-northeast-2-057716757052/data/cifar10\n"
     ]
    }
   ],
   "source": [
    "inputs = sagemaker_session.upload_data(path=\"../data\", bucket=bucket, key_prefix=\"data/cifar10\")\n",
    "print(\"s3 inputs: \", inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a script for training \n",
    "Here is the full code for the network model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance type = local_gpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "instance_type = \"local\"\n",
    "\n",
    "try:\n",
    "    if subprocess.call(\"nvidia-smi\") == 0:\n",
    "        ## Set type to GPU if one is present\n",
    "        instance_type = \"local_gpu\"\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"Instance type = \" + instance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating c5xivjdtjf-algo-1-sa2f6 ... \n",
      "Creating c5xivjdtjf-algo-1-sa2f6 ... done\n",
      "Attaching to c5xivjdtjf-algo-1-sa2f6\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m 2021-06-01 08:25:35,272 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m 2021-06-01 08:25:35,315 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m 2021-06-01 08:25:35,318 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m 2021-06-01 08:25:35,471 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m /opt/conda/bin/python3.6 -m pip install -r requirements.txt\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m Requirement already satisfied: torch==1.6.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (1.6.0)\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m Requirement already satisfied: torchvision==0.7.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (0.7.0)\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m Collecting torchsummary==1.5.1\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m   Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torch==1.6.0->-r requirements.txt (line 1)) (1.19.1)\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m Requirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from torch==1.6.0->-r requirements.txt (line 1)) (0.18.2)\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.6/site-packages (from torchvision==0.7.0->-r requirements.txt (line 2)) (8.2.0)\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m Installing collected packages: torchsummary\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m Successfully installed torchsummary-1.5.1\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m \n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m 2021-06-01 08:25:37,433 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m \n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m Training Env:\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m \n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m {\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m         \"training\": \"/opt/ml/input/data/training\"\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m     },\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m     \"current_host\": \"algo-1-sa2f6\",\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m         \"algo-1-sa2f6\"\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m     ],\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m         \"epochs\": 1,\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m         \"lr\": 0.1\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m     },\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m         \"training\": {\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m         }\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m     },\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m     \"job_name\": \"pytorch-training-2021-06-01-08-23-08-450\",\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m     \"master_hostname\": \"algo-1-sa2f6\",\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m     \"module_dir\": \"s3://sagemaker-ap-northeast-2-057716757052/pytorch-training-2021-06-01-08-23-08-450/source/sourcedir.tar.gz\",\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m     \"module_name\": \"train\",\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m     \"num_cpus\": 32,\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m     \"num_gpus\": 4,\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m         \"current_host\": \"algo-1-sa2f6\",\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m             \"algo-1-sa2f6\"\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m         ]\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m     },\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m     \"user_entry_point\": \"train.py\"\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m }\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m \n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m Environment variables:\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m \n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m SM_HOSTS=[\"algo-1-sa2f6\"]\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m SM_HPS={\"epochs\":1,\"lr\":0.1}\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m SM_USER_ENTRY_POINT=train.py\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-sa2f6\",\"hosts\":[\"algo-1-sa2f6\"]}\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m SM_INPUT_DATA_CONFIG={\"training\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m SM_CHANNELS=[\"training\"]\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m SM_CURRENT_HOST=algo-1-sa2f6\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m SM_MODULE_NAME=train\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m SM_NUM_CPUS=32\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m SM_NUM_GPUS=4\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m SM_MODULE_DIR=s3://sagemaker-ap-northeast-2-057716757052/pytorch-training-2021-06-01-08-23-08-450/source/sourcedir.tar.gz\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-sa2f6\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-sa2f6\"],\"hyperparameters\":{\"epochs\":1,\"lr\":0.1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2021-06-01-08-23-08-450\",\"log_level\":20,\"master_hostname\":\"algo-1-sa2f6\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-2-057716757052/pytorch-training-2021-06-01-08-23-08-450/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":32,\"num_gpus\":4,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-sa2f6\",\"hosts\":[\"algo-1-sa2f6\"]},\"user_entry_point\":\"train.py\"}\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m SM_USER_ARGS=[\"--epochs\",\"1\",\"--lr\",\"0.1\"]\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m SM_HP_EPOCHS=1\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m SM_HP_LR=0.1\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m \n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m \n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m /opt/conda/bin/python3.6 train.py --epochs 1 --lr 0.1\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m \n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m \n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m Distributed training - False\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m Device Type: cuda\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m Loading Cifar10 dataset\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m Model loaded\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m Gpu count: 4\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m [2021-06-01 08:25:40.962 algo-1-sa2f6:31 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m [2021-06-01 08:25:41.202 algo-1-sa2f6:31 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m NCCL version 2.4.8+cuda10.1\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m [1,  2000] loss: 2.356\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m [1,  4000] loss: 2.357\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m [1,  6000] loss: 2.360\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m [1,  8000] loss: 2.364\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m [1, 10000] loss: 2.362\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m [1, 12000] loss: 2.361\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m Finished Training\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m Saving the model.\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m \n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 |\u001b[0m 2021-06-01 08:28:03,245 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\u001b[36mc5xivjdtjf-algo-1-sa2f6 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "cifar10_estimator = PyTorch(\n",
    "    entry_point=\"train.py\",    \n",
    "    source_dir='source',    \n",
    "    role=role,\n",
    "    framework_version='1.6.0',\n",
    "    py_version='py3',\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    hyperparameters={'epochs': 1, \n",
    "                     'lr': 0.1,\n",
    "                    }                      \n",
    "    \n",
    ")\n",
    "cifar10_estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Host Mode 로 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-01 08:28:04 Starting - Starting the training job...\n",
      "2021-06-01 08:28:27 Starting - Launching requested ML instancesProfilerReport-1622536084: InProgress\n",
      "......\n",
      "2021-06-01 08:29:28 Starting - Preparing the instances for training.........\n",
      "2021-06-01 08:30:58 Downloading - Downloading input data\n",
      "2021-06-01 08:30:58 Training - Downloading the training image............\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-06-01 08:33:00,433 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-06-01 08:33:00,475 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2021-06-01 08:33:03,497 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-06-01 08:33:03,974 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch==1.6.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (1.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torchvision==0.7.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (0.7.0)\u001b[0m\n",
      "\u001b[34mCollecting torchsummary==1.5.1\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torch==1.6.0->-r requirements.txt (line 1)) (1.19.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from torch==1.6.0->-r requirements.txt (line 1)) (0.18.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.6/site-packages (from torchvision==0.7.0->-r requirements.txt (line 2)) (8.2.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: torchsummary\u001b[0m\n",
      "\u001b[34mSuccessfully installed torchsummary-1.5.1\n",
      "\u001b[0m\n",
      "\u001b[34m2021-06-01 08:33:06,556 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"lr\": 0.01,\n",
      "        \"epochs\": 2\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2021-06-01-08-28-04-095\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-northeast-2-057716757052/pytorch-training-2021-06-01-08-28-04-095/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 32,\n",
      "    \"num_gpus\": 4,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":2,\"lr\":0.01}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=32\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=4\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-northeast-2-057716757052/pytorch-training-2021-06-01-08-28-04-095/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":2,\"lr\":0.01},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2021-06-01-08-28-04-095\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-2-057716757052/pytorch-training-2021-06-01-08-28-04-095/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":32,\"num_gpus\":4,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"2\",\"--lr\",\"0.01\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.01\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=2\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train.py --epochs 2 --lr 0.01\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mDistributed training - False\u001b[0m\n",
      "\u001b[34mDevice Type: cuda\u001b[0m\n",
      "\u001b[34mLoading Cifar10 dataset\u001b[0m\n",
      "\u001b[34mModel loaded\u001b[0m\n",
      "\u001b[34mGpu count: 4\u001b[0m\n",
      "\u001b[34m[2021-06-01 08:33:14.299 algo-1:31 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2021-06-01 08:33:14.651 algo-1:31 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2021-06-01 08:33:14.652 algo-1:31 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2021-06-01 08:33:14.652 algo-1:31 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2021-06-01 08:33:14.653 algo-1:31 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2021-06-01 08:33:14.653 algo-1:31 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2021-06-01 08:33:14.653 algo-1:31 INFO hook.py:584] name:module.conv1.weight count_params:450\u001b[0m\n",
      "\u001b[34m[2021-06-01 08:33:14.653 algo-1:31 INFO hook.py:584] name:module.conv1.bias count_params:6\u001b[0m\n",
      "\u001b[34m[2021-06-01 08:33:14.653 algo-1:31 INFO hook.py:584] name:module.conv2.weight count_params:2400\u001b[0m\n",
      "\u001b[34m[2021-06-01 08:33:14.653 algo-1:31 INFO hook.py:584] name:module.conv2.bias count_params:16\u001b[0m\n",
      "\u001b[34m[2021-06-01 08:33:14.653 algo-1:31 INFO hook.py:584] name:module.fc1.weight count_params:48000\u001b[0m\n",
      "\u001b[34m[2021-06-01 08:33:14.653 algo-1:31 INFO hook.py:584] name:module.fc1.bias count_params:120\u001b[0m\n",
      "\u001b[34m[2021-06-01 08:33:14.654 algo-1:31 INFO hook.py:584] name:module.fc2.weight count_params:10080\u001b[0m\n",
      "\u001b[34m[2021-06-01 08:33:14.654 algo-1:31 INFO hook.py:584] name:module.fc2.bias count_params:84\u001b[0m\n",
      "\u001b[34m[2021-06-01 08:33:14.654 algo-1:31 INFO hook.py:584] name:module.fc3.weight count_params:840\u001b[0m\n",
      "\u001b[34m[2021-06-01 08:33:14.654 algo-1:31 INFO hook.py:584] name:module.fc3.bias count_params:10\u001b[0m\n",
      "\u001b[34m[2021-06-01 08:33:14.654 algo-1:31 INFO hook.py:586] Total Trainable Params: 62006\u001b[0m\n",
      "\u001b[34m[2021-06-01 08:33:14.654 algo-1:31 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2021-06-01 08:33:14.656 algo-1:31 INFO hook.py:476] Hook is writing from the hook with pid: 31\n",
      "\u001b[0m\n",
      "\u001b[34mNCCL version 2.4.8+cuda10.1\u001b[0m\n",
      "\n",
      "2021-06-01 08:33:30 Training - Training image download completed. Training in progress.\u001b[34m[1,  2000] loss: 2.088\u001b[0m\n",
      "\u001b[34m[1,  4000] loss: 1.947\u001b[0m\n",
      "\u001b[34m[1,  6000] loss: 1.935\u001b[0m\n",
      "\u001b[34m[1,  8000] loss: 1.944\u001b[0m\n",
      "\u001b[34m[1, 10000] loss: 1.928\u001b[0m\n",
      "\u001b[34m[1, 12000] loss: 1.956\u001b[0m\n",
      "\u001b[34m[2,  2000] loss: 2.007\u001b[0m\n",
      "\u001b[34m[2,  4000] loss: 2.016\u001b[0m\n",
      "\u001b[34m[2,  6000] loss: 1.996\u001b[0m\n",
      "\u001b[34m[2,  8000] loss: 2.024\u001b[0m\n",
      "\u001b[34m[2, 10000] loss: 2.027\u001b[0m\n",
      "\u001b[34m[2, 12000] loss: 2.056\u001b[0m\n",
      "\u001b[34mFinished Training\u001b[0m\n",
      "\u001b[34mSaving the model.\u001b[0m\n",
      "\u001b[34m2021-06-01 08:37:51,890 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-06-01 08:38:35 Uploading - Uploading generated training model\n",
      "2021-06-01 08:39:10 Completed - Training job completed\n",
      "ProfilerReport-1622536084: NoIssuesFound\n",
      "Training seconds: 486\n",
      "Billable seconds: 486\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "instance_type = 'ml.p3.8xlarge'\n",
    "\n",
    "cifar10_estimator = PyTorch(\n",
    "    entry_point=\"train.py\",    \n",
    "    source_dir='source',    \n",
    "    role=role,\n",
    "    framework_version='1.6.0',\n",
    "    py_version='py3',\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    hyperparameters={'epochs': 2, \n",
    "                     'lr': 0.01,\n",
    "                    }                      \n",
    "    \n",
    ")\n",
    "cifar10_estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifact_path:  s3://sagemaker-ap-northeast-2-057716757052/pytorch-training-2021-06-01-08-28-04-095/output/model.tar.gz\n",
      "Stored 'artifact_path' (str)\n"
     ]
    }
   ],
   "source": [
    "last_job_name = cifar10_estimator.latest_training_job.job_name\n",
    "artifact_path = \"s3://{}/{}/output/model.tar.gz\".format(bucket, last_job_name)\n",
    "print(\"artifact_path: \", artifact_path)\n",
    "\n",
    "%store artifact_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
