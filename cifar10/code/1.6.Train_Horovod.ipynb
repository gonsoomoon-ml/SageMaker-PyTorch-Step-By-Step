{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 현재 작업 중입니다.\n",
    "\n",
    "<!-- # [Module 1.6] Horovod 훈련\n",
    "\n",
    "\n",
    "본 워크샵의 모든 노트북은 `conda_python3` 여기에서 작업 합니다.\n",
    "\n",
    "이 노트북은 아래와 같은 작업을 합니다.\n",
    "- 아래는 세이지메이커의 어떤 피쳐도 사용하지 않고, PyTorch 만을 사용해서 훈련 합니다. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch CIFAR-10 local training  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"sagemaker/DEMO-pytorch-cnn-cifar10\"\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance type = local_gpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "instance_type = \"local\"\n",
    "\n",
    "try:\n",
    "    if subprocess.call(\"nvidia-smi\") == 0:\n",
    "        ## Set type to GPU if one is present\n",
    "        instance_type = \"local_gpu\"\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"Instance type = \" + instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the data\n",
    "We use the ```sagemaker.Session.upload_data``` function to upload our datasets to an S3 location. The return value inputs identifies the location -- we will use this later when we start the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3 inputs:  s3://sagemaker-us-east-1-057716757052/data/cifar10\n"
     ]
    }
   ],
   "source": [
    "inputs = sagemaker_session.upload_data(path=\"../data\", bucket=bucket, key_prefix=\"data/cifar10\")\n",
    "print(\"s3 inputs: \", inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a script for training \n",
    "- epoch 10 , 20\n",
    "    - 각각 테스트 정확도 55.2, 62.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "instance_type = \"local_gpu\"\n",
    "# instance_type = \"ml.p3.8xlarge\"\n",
    "\n",
    "job_name ='cifar10-horovod'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시스템의 이전 도커 컨테이너 삭제\n",
    "- 아래와 같은 명령어를 사용하여 저장 공간을 확보 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 도커 컨테이너 모두 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "devtmpfs         30G   76K   30G   1% /dev\n",
      "tmpfs            30G  320K   30G   1% /dev/shm\n",
      "/dev/xvda1      104G   91G   14G  88% /\n",
      "/dev/xvdf       984G  8.6G  925G   1% /home/ec2-user/SageMaker\n",
      "unknown flag: --all\n",
      "See 'docker container prune --help'.\n",
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "devtmpfs         30G   76K   30G   1% /dev\n",
      "tmpfs            30G  320K   30G   1% /dev/shm\n",
      "/dev/xvda1      104G   91G   14G  88% /\n",
      "/dev/xvdf       984G  8.6G  925G   1% /home/ec2-user/SageMaker\n"
     ]
    }
   ],
   "source": [
    "! df -h\n",
    "! docker container prune -f --all\n",
    "! df -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 도커 이미지 모두 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "devtmpfs         30G   76K   30G   1% /dev\n",
      "tmpfs            30G  320K   30G   1% /dev/shm\n",
      "/dev/xvda1      104G   91G   14G  88% /\n",
      "/dev/xvdf       984G  8.6G  925G   1% /home/ec2-user/SageMaker\n",
      "Total reclaimed space: 0B\n",
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "devtmpfs         30G   76K   30G   1% /dev\n",
      "tmpfs            30G  320K   30G   1% /dev/shm\n",
      "/dev/xvda1      104G   91G   14G  88% /\n",
      "/dev/xvdf       984G  8.6G  925G   1% /home/ec2-user/SageMaker\n"
     ]
    }
   ],
   "source": [
    "! df -h\n",
    "! docker image prune -f --all\n",
    "! df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating bepciuprgg-algo-1-5icaf ... \n",
      "Creating bepciuprgg-algo-1-5icaf ... done\n",
      "Attaching to bepciuprgg-algo-1-5icaf\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m 2021-09-27 07:28:33,416 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m 2021-09-27 07:28:33,441 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m 2021-09-27 07:28:33,445 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m 2021-09-27 07:28:33,609 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m /opt/conda/bin/python3.6 -m pip install -r requirements.txt\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Requirement already satisfied: torch==1.6.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (1.6.0)\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Requirement already satisfied: torchvision==0.7.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (0.7.0)\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Collecting torchsummary==1.5.1\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m   Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Requirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from torch==1.6.0->-r requirements.txt (line 1)) (0.18.2)\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torch==1.6.0->-r requirements.txt (line 1)) (1.19.1)\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.6/site-packages (from torchvision==0.7.0->-r requirements.txt (line 2)) (8.2.0)\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Installing collected packages: torchsummary\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Successfully installed torchsummary-1.5.1\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m \n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m 2021-09-27 07:28:35,331 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m \n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Training Env:\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m \n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m {\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m         \"training\": \"/opt/ml/input/data/training\"\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m     },\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m     \"current_host\": \"algo-1-5icaf\",\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m         \"algo-1-5icaf\"\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m     ],\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m         \"epochs\": 3,\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m         \"lr\": 0.001,\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m         \"batch-size\": 64,\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m         \"log-interval\": 100,\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m         \"backend\": \"gloo\"\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m     },\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m         \"training\": {\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m         }\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m     },\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m     \"job_name\": \"cifar10-horovod-2021-09-27-07-28-24-448\",\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m     \"master_hostname\": \"algo-1-5icaf\",\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-057716757052/cifar10-horovod-2021-09-27-07-28-24-448/source/sourcedir.tar.gz\",\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m     \"module_name\": \"train_horovod\",\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m     \"num_cpus\": 4,\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m     \"num_gpus\": 1,\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m         \"current_host\": \"algo-1-5icaf\",\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m             \"algo-1-5icaf\"\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m         ]\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m     },\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m     \"user_entry_point\": \"train_horovod.py\"\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m }\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m \n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Environment variables:\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m \n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m SM_HOSTS=[\"algo-1-5icaf\"]\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m SM_HPS={\"backend\":\"gloo\",\"batch-size\":64,\"epochs\":3,\"log-interval\":100,\"lr\":0.001}\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m SM_USER_ENTRY_POINT=train_horovod.py\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-5icaf\",\"hosts\":[\"algo-1-5icaf\"]}\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m SM_INPUT_DATA_CONFIG={\"training\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m SM_CHANNELS=[\"training\"]\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m SM_CURRENT_HOST=algo-1-5icaf\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m SM_MODULE_NAME=train_horovod\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m SM_NUM_CPUS=4\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m SM_NUM_GPUS=1\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-057716757052/cifar10-horovod-2021-09-27-07-28-24-448/source/sourcedir.tar.gz\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-5icaf\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-5icaf\"],\"hyperparameters\":{\"backend\":\"gloo\",\"batch-size\":64,\"epochs\":3,\"log-interval\":100,\"lr\":0.001},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"cifar10-horovod-2021-09-27-07-28-24-448\",\"log_level\":20,\"master_hostname\":\"algo-1-5icaf\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-057716757052/cifar10-horovod-2021-09-27-07-28-24-448/source/sourcedir.tar.gz\",\"module_name\":\"train_horovod\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-5icaf\",\"hosts\":[\"algo-1-5icaf\"]},\"user_entry_point\":\"train_horovod.py\"}\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m SM_USER_ARGS=[\"--backend\",\"gloo\",\"--batch-size\",\"64\",\"--epochs\",\"3\",\"--log-interval\",\"100\",\"--lr\",\"0.001\"]\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m SM_HP_EPOCHS=3\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m SM_HP_LR=0.001\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m SM_HP_BATCH-SIZE=64\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m SM_HP_LOG-INTERVAL=100\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m SM_HP_BACKEND=gloo\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m \n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m \n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m /opt/conda/bin/python3.6 train_horovod.py --backend gloo --batch-size 64 --epochs 3 --log-interval 100 --lr 0.001\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m \n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m \n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Get train data sampler and data loader\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Get test data sampler and data loader\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Processes 50000/50000 (100%) of train data\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Processes 10000/10000 (100%) of test data\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Model loaded\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m [2021-09-27 07:28:38.772 algo-1-5icaf:32 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m [2021-09-27 07:28:39.033 algo-1-5icaf:32 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Train Epoch: 1 [6400/50000 (13%)] Loss: -0.034753\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Train Epoch: 1 [12800/50000 (26%)] Loss: -0.077525\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Train Epoch: 1 [19200/50000 (38%)] Loss: -0.101786\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Train Epoch: 1 [25600/50000 (51%)] Loss: -0.147391\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Train Epoch: 1 [32000/50000 (64%)] Loss: -0.193293\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Train Epoch: 1 [38400/50000 (77%)] Loss: -0.226884\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Train Epoch: 1 [44800/50000 (90%)] Loss: -0.295584\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Test set: Average loss: -0.4675, Accuracy: 10.03%\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m \n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Train Epoch: 2 [6400/50000 (13%)] Loss: -2.876648\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Train Epoch: 2 [12800/50000 (26%)] Loss: nan\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Train Epoch: 2 [19200/50000 (38%)] Loss: nan\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Train Epoch: 2 [25600/50000 (51%)] Loss: nan\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Train Epoch: 2 [32000/50000 (64%)] Loss: nan\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Train Epoch: 2 [38400/50000 (77%)] Loss: nan\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Train Epoch: 2 [44800/50000 (90%)] Loss: nan\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Test set: Average loss: nan, Accuracy: 10.00%\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m \n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Train Epoch: 3 [6400/50000 (13%)] Loss: nan\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Train Epoch: 3 [12800/50000 (26%)] Loss: nan\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Train Epoch: 3 [19200/50000 (38%)] Loss: nan\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Train Epoch: 3 [25600/50000 (51%)] Loss: nan\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Train Epoch: 3 [32000/50000 (64%)] Loss: nan\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Train Epoch: 3 [38400/50000 (77%)] Loss: nan\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Train Epoch: 3 [44800/50000 (90%)] Loss: nan\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Test set: Average loss: nan, Accuracy: 10.00%\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m \n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Training is finished\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m Saving the model.\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m /opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m   warnings.warn(warning.format(ret))\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m \n",
      "\u001b[36mbepciuprgg-algo-1-5icaf |\u001b[0m 2021-09-27 07:29:35,837 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\u001b[36mbepciuprgg-algo-1-5icaf exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "cifar10_estimator = PyTorch(\n",
    "    entry_point=\"train_horovod.py\",    \n",
    "    source_dir='source',    \n",
    "    base_job_name = job_name,\n",
    "    role=role,\n",
    "    framework_version='1.6.0',\n",
    "    py_version='py3',\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=instance_type,\n",
    "    hyperparameters={\"epochs\": 3, \n",
    "                     'lr': 0.001,\n",
    "                     'batch-size': 64,\n",
    "                     'log-interval' : 100,\n",
    "                     \"backend\": \"gloo\",                     \n",
    "                    },    \n",
    ")\n",
    "cifar10_estimator.fit({\"training\" : inputs})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 로컬모드에서 도커 이미지 다운로드 된 것을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY                                                      TAG                 IMAGE ID            CREATED             SIZE\n",
      "763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training   1.6.0-gpu-py3       30e42e4701a4        5 months ago        8.6GB\n"
     ]
    }
   ],
   "source": [
    "! docker image ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "instance_type\n",
    "\n",
    "cifar10_estimator = PyTorch(\n",
    "    entry_point=\"train_horovod.py\",    \n",
    "    source_dir='source',    \n",
    "    base_job_name = job_name,\n",
    "    role=role,\n",
    "    framework_version='1.6.0',\n",
    "    py_version='py3',\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=instance_type,\n",
    "    hyperparameters={\"epochs\": 3, \n",
    "                     'lr': 0.001,\n",
    "                     'batch-size': 64,\n",
    "                     \"backend\": \"gloo\",                     \n",
    "                    },    \n",
    ")\n",
    "cifar10_estimator.fit({\"training\" : inputs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horovod_artifact_path = cifar10_estimator.model_data\n",
    "print(\"horovod_artifact_path: \", horovod_artifact_path)\n",
    "\n",
    "\n",
    "%store horovod_artifact_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! aws s3 ls {horovod_artifact_path} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
