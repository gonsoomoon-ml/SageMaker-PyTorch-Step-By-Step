{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 1.6] Horovod 훈련\n",
    "\n",
    "본 워크샵의 모든 노트북은 `conda_python3` 여기에서 작업 합니다.\n",
    "\n",
    "이 노트북은 아래와 같은 작업을 합니다.\n",
    "- 아래는 세이지메이커의 어떤 피쳐도 사용하지 않고, PyTorch 만을 사용해서 훈련 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch CIFAR-10 local training  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"sagemaker/DEMO-pytorch-cnn-cifar10\"\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance type = local_gpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "instance_type = \"local\"\n",
    "\n",
    "try:\n",
    "    if subprocess.call(\"nvidia-smi\") == 0:\n",
    "        ## Set type to GPU if one is present\n",
    "        instance_type = \"local_gpu\"\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"Instance type = \" + instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the data\n",
    "We use the ```sagemaker.Session.upload_data``` function to upload our datasets to an S3 location. The return value inputs identifies the location -- we will use this later when we start the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3 inputs:  s3://sagemaker-ap-northeast-2-057716757052/data/cifar10\n"
     ]
    }
   ],
   "source": [
    "inputs = sagemaker_session.upload_data(path=\"../data\", bucket=bucket, key_prefix=\"data/cifar10\")\n",
    "print(\"s3 inputs: \", inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a script for training \n",
    "Here is the full code for the network model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "instance_type = \"local_gpu\"\n",
    "# instance_type = \"ml.p3.8xlarge\"\n",
    "\n",
    "job_name ='cifar10-horovod'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 4f3ecy1q7r-algo-1-1zxze ... \n",
      "Creating 4f3ecy1q7r-algo-1-1zxze ... done\n",
      "Attaching to 4f3ecy1q7r-algo-1-1zxze\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m 2021-06-08 02:10:31,698 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m 2021-06-08 02:10:31,740 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m 2021-06-08 02:10:31,743 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m 2021-06-08 02:10:31,926 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m /opt/conda/bin/python3.6 -m pip install -r requirements.txt\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Requirement already satisfied: torch==1.6.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (1.6.0)\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Requirement already satisfied: torchvision==0.7.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (0.7.0)\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Collecting torchsummary==1.5.1\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m   Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Collecting sagemaker_inference==1.5.5\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m   Downloading sagemaker_inference-1.5.5.tar.gz (20 kB)\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from sagemaker_inference==1.5.5->-r requirements.txt (line 4)) (1.19.1)\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sagemaker_inference==1.5.5->-r requirements.txt (line 4)) (1.15.0)\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Requirement already satisfied: psutil in /opt/conda/lib/python3.6/site-packages (from sagemaker_inference==1.5.5->-r requirements.txt (line 4)) (5.8.0)\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Requirement already satisfied: retrying==1.3.3 in /opt/conda/lib/python3.6/site-packages (from sagemaker_inference==1.5.5->-r requirements.txt (line 4)) (1.3.3)\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from sagemaker_inference==1.5.5->-r requirements.txt (line 4)) (1.5.2)\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Requirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from torch==1.6.0->-r requirements.txt (line 1)) (0.18.2)\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.6/site-packages (from torchvision==0.7.0->-r requirements.txt (line 2)) (8.2.0)\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Building wheels for collected packages: sagemaker-inference\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m   Building wheel for sagemaker-inference (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m \u001b[?25h  Created wheel for sagemaker-inference: filename=sagemaker_inference-1.5.5-py2.py3-none-any.whl size=26977 sha256=1285813c7a78266b1228be4a34aa5cefe6a2fdc97e7cbba1350df1f2c18aa4bf\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m   Stored in directory: /root/.cache/pip/wheels/a4/bf/81/8e084e445a44e9fbc9d64efc7afb2a660ecd06285ea4a51fa0\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Successfully built sagemaker-inference\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Installing collected packages: torchsummary, sagemaker-inference\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Successfully installed sagemaker-inference-1.5.5 torchsummary-1.5.1\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m \n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m 2021-06-08 02:10:35,058 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m \n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Training Env:\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m \n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m {\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m         \"training\": \"/opt/ml/input/data/training\"\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m     },\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m     \"current_host\": \"algo-1-1zxze\",\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m     \"hosts\": [\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m         \"algo-1-1zxze\"\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m     ],\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m         \"epochs\": 1,\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m         \"backend\": \"gloo\"\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m     },\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m         \"training\": {\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m         }\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m     },\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m     \"job_name\": \"cifar10-horovod-2021-06-08-02-10-25-236\",\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m     \"master_hostname\": \"algo-1-1zxze\",\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m     \"module_dir\": \"s3://sagemaker-ap-northeast-2-057716757052/cifar10-horovod-2021-06-08-02-10-25-236/source/sourcedir.tar.gz\",\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m     \"module_name\": \"train_horovod\",\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m     \"num_cpus\": 32,\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m     \"num_gpus\": 4,\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m         \"current_host\": \"algo-1-1zxze\",\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m         \"hosts\": [\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m             \"algo-1-1zxze\"\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m         ]\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m     },\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m     \"user_entry_point\": \"train_horovod.py\"\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m }\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m \n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Environment variables:\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m \n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m SM_HOSTS=[\"algo-1-1zxze\"]\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m SM_HPS={\"backend\":\"gloo\",\"epochs\":1}\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m SM_USER_ENTRY_POINT=train_horovod.py\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-1zxze\",\"hosts\":[\"algo-1-1zxze\"]}\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m SM_INPUT_DATA_CONFIG={\"training\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m SM_CHANNELS=[\"training\"]\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m SM_CURRENT_HOST=algo-1-1zxze\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m SM_MODULE_NAME=train_horovod\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m SM_NUM_CPUS=32\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m SM_NUM_GPUS=4\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m SM_MODULE_DIR=s3://sagemaker-ap-northeast-2-057716757052/cifar10-horovod-2021-06-08-02-10-25-236/source/sourcedir.tar.gz\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-1zxze\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-1zxze\"],\"hyperparameters\":{\"backend\":\"gloo\",\"epochs\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"cifar10-horovod-2021-06-08-02-10-25-236\",\"log_level\":20,\"master_hostname\":\"algo-1-1zxze\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-2-057716757052/cifar10-horovod-2021-06-08-02-10-25-236/source/sourcedir.tar.gz\",\"module_name\":\"train_horovod\",\"network_interface_name\":\"eth0\",\"num_cpus\":32,\"num_gpus\":4,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-1zxze\",\"hosts\":[\"algo-1-1zxze\"]},\"user_entry_point\":\"train_horovod.py\"}\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m SM_USER_ARGS=[\"--backend\",\"gloo\",\"--epochs\",\"1\"]\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m SM_HP_EPOCHS=1\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m SM_HP_BACKEND=gloo\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m \n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m \n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m /opt/conda/bin/python3.6 train_horovod.py --backend gloo --epochs 1\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m \n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m \n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Get train data sampler and data loader\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Get test data sampler and data loader\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Processes 50000/50000 (100%) of train data\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Processes 10000/10000 (100%) of test data\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Model loaded\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m [2021-06-08 02:10:38.701 algo-1-1zxze:37 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m [2021-06-08 02:10:38.936 algo-1-1zxze:37 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m NCCL version 2.4.8+cuda10.1\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [640/50000 (1%)] Loss: 2.321342\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [1280/50000 (3%)] Loss: 2.308100\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [1920/50000 (4%)] Loss: 2.308891\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [2560/50000 (5%)] Loss: 2.291915\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [3200/50000 (6%)] Loss: 2.312550\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [3840/50000 (8%)] Loss: 2.314280\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [4480/50000 (9%)] Loss: 2.312576\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [5120/50000 (10%)] Loss: 2.315177\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [5760/50000 (12%)] Loss: 2.295863\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [6400/50000 (13%)] Loss: 2.305438\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [7040/50000 (14%)] Loss: 2.306653\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [7680/50000 (15%)] Loss: 2.301949\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [8320/50000 (17%)] Loss: 2.306799\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [8960/50000 (18%)] Loss: 2.304988\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [9600/50000 (19%)] Loss: 2.300297\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [10240/50000 (20%)] Loss: 2.301208\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [10880/50000 (22%)] Loss: 2.297847\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [11520/50000 (23%)] Loss: 2.304170\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [12160/50000 (24%)] Loss: 2.297876\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [12800/50000 (26%)] Loss: 2.301647\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [13440/50000 (27%)] Loss: 2.299576\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [14080/50000 (28%)] Loss: 2.307082\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [14720/50000 (29%)] Loss: 2.300591\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [15360/50000 (31%)] Loss: 2.297276\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [16000/50000 (32%)] Loss: 2.297249\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [16640/50000 (33%)] Loss: 2.295190\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [17280/50000 (35%)] Loss: 2.301494\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [17920/50000 (36%)] Loss: 2.297096\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [18560/50000 (37%)] Loss: 2.299757\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [19200/50000 (38%)] Loss: 2.301011\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [19840/50000 (40%)] Loss: 2.296378\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [20480/50000 (41%)] Loss: 2.299983\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [21120/50000 (42%)] Loss: 2.298400\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [21760/50000 (43%)] Loss: 2.302494\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [22400/50000 (45%)] Loss: 2.301636\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [23040/50000 (46%)] Loss: 2.296009\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [23680/50000 (47%)] Loss: 2.297444\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [24320/50000 (49%)] Loss: 2.293919\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [24960/50000 (50%)] Loss: 2.290648\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [25600/50000 (51%)] Loss: 2.304311\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [26240/50000 (52%)] Loss: 2.291386\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [26880/50000 (54%)] Loss: 2.294993\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [27520/50000 (55%)] Loss: 2.284130\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [28160/50000 (56%)] Loss: 2.294387\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [28800/50000 (58%)] Loss: 2.296887\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [29440/50000 (59%)] Loss: 2.296327\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [30080/50000 (60%)] Loss: 2.293545\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [30720/50000 (61%)] Loss: 2.291348\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [31360/50000 (63%)] Loss: 2.286210\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [32000/50000 (64%)] Loss: 2.284824\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [32640/50000 (65%)] Loss: 2.290664\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [33280/50000 (66%)] Loss: 2.282462\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [33920/50000 (68%)] Loss: 2.290518\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [34560/50000 (69%)] Loss: 2.288548\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [35200/50000 (70%)] Loss: 2.280983\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [35840/50000 (72%)] Loss: 2.286746\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [36480/50000 (73%)] Loss: 2.276717\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [37120/50000 (74%)] Loss: 2.276094\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [37760/50000 (75%)] Loss: 2.261576\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [38400/50000 (77%)] Loss: 2.272556\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [39040/50000 (78%)] Loss: 2.257026\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [39680/50000 (79%)] Loss: 2.257092\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [40320/50000 (81%)] Loss: 2.257373\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [40960/50000 (82%)] Loss: 2.256159\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [41600/50000 (83%)] Loss: 2.221439\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [42240/50000 (84%)] Loss: 2.252996\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [42880/50000 (86%)] Loss: 2.244588\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [43520/50000 (87%)] Loss: 2.220019\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [44160/50000 (88%)] Loss: 2.250747\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [44800/50000 (90%)] Loss: 2.231874\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [45440/50000 (91%)] Loss: 2.265629\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [46080/50000 (92%)] Loss: 2.254987\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [46720/50000 (93%)] Loss: 2.264896\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [47360/50000 (95%)] Loss: 2.195177\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [48000/50000 (96%)] Loss: 2.196208\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [48640/50000 (97%)] Loss: 2.130310\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [49280/50000 (98%)] Loss: 2.240089\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Train Epoch: 1 [49920/50000 (100%)] Loss: 2.246542\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Test set: Average loss: 2.1678, Accuracy: 26.11%\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m \n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Training is finished\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m Saving the model.\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m /opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m   warnings.warn(warning.format(ret))\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m \n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze |\u001b[0m 2021-06-08 02:11:05,511 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\u001b[36m4f3ecy1q7r-algo-1-1zxze exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "cifar10_estimator = PyTorch(\n",
    "    entry_point=\"train_horovod.py\",    \n",
    "    source_dir='source',    \n",
    "    base_job_name = job_name,\n",
    "    role=role,\n",
    "    framework_version='1.6.0',\n",
    "    py_version='py3',\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=instance_type,\n",
    "    hyperparameters={\"epochs\": 1, \"backend\": \"gloo\"},    \n",
    ")\n",
    "cifar10_estimator.fit({\"training\" : inputs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horovod_artifact_path:  s3://sagemaker-ap-northeast-2-057716757052/cifar10-horovod-2021-06-08-02-10-25-236/model.tar.gz\n",
      "Stored 'horovod_artifact_path' (str)\n"
     ]
    }
   ],
   "source": [
    "horovod_artifact_path = cifar10_estimator.model_data\n",
    "print(\"horovod_artifact_path: \", horovod_artifact_path)\n",
    "\n",
    "\n",
    "%store horovod_artifact_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-08 02:11:07     230777 cifar10-horovod-2021-06-08-02-10-25-236/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "! aws s3 ls {horovod_artifact_path} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
