{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8132f6d",
   "metadata": {},
   "source": [
    "# [Module 1.3] 체크 포인트를 생성을 통한 스팟 인스턴스 훈련\n",
    "\n",
    "### 본 워크샵의 모든 노트북은 `conda_python3` 여기에서 작업 합니다.\n",
    "\n",
    "이 노트북은 아래와 같은 작업을 합니다.\n",
    "- 체크포인트를 사용하는 방법\n",
    "- 기본 환경 세팅\n",
    "- 데이터 세트를 S3에 업로드\n",
    "- 체크 포인트를 사용한 훈련 시니라오\n",
    "    - 첫 번째 훈련 잡 실행\n",
    "    - 두 번째 훈련 잡 실행\n",
    "- 훈련 잡 로그 분석\n",
    "- 모델 아티펙트 저장\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dbb82f",
   "metadata": {},
   "source": [
    "## 세이지 메이커에서 체크포인트를 사용하는 방법\n",
    "\n",
    "개발자 가이드 --> [체코 포인트 사용하기](https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/model-checkpoints.html)\n",
    "\n",
    "![checkpoint_how.png](img/checkpoint_how.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683744ff",
   "metadata": {},
   "source": [
    "## 기본 세팅\n",
    "사용하는 패키지는 import 시점에 다시 재로딩 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23ec8865",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3974ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker version: 2.45.0\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import uuid\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "print('SageMaker version: ' + sagemaker.__version__)\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/DEMO-pytorch-cnn-cifar10'\n",
    "\n",
    "role = sagemaker.get_execution_role()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2f41d6",
   "metadata": {},
   "source": [
    "### 체크 포인트 파일 저장 경로\n",
    "- S3에 체크포인트 경로를 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27962cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpointing Path: s3://sagemaker-ap-northeast-2-057716757052/checkpoint-98bd0bc7\n"
     ]
    }
   ],
   "source": [
    "checkpoint_suffix = str(uuid.uuid4())[:8]\n",
    "checkpoint_s3_path = 's3://{}/checkpoint-{}'.format(bucket, checkpoint_suffix)\n",
    "\n",
    "print('Checkpointing Path: {}'.format(checkpoint_s3_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a748b69",
   "metadata": {},
   "source": [
    "#### 로컬의 GPU, CPU 여부로 instance_type 결정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57ad6ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance type = local_gpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "\n",
    "try:\n",
    "    if subprocess.call(\"nvidia-smi\") == 0:\n",
    "        ## Set type to GPU if one is present\n",
    "        instance_type = \"local_gpu\"\n",
    "    else:\n",
    "        instance_type = \"local\"        \n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"Instance type = \" + instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea5262c",
   "metadata": {},
   "source": [
    "### 데이터 세트를 S3에 업로드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5137a0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3 inputs:  s3://sagemaker-ap-northeast-2-057716757052/data/cifar10\n"
     ]
    }
   ],
   "source": [
    "inputs = sagemaker_session.upload_data(path=\"../data\", bucket=bucket, key_prefix=\"data/cifar10\")\n",
    "print(\"s3 inputs: \", inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0a1c1f",
   "metadata": {},
   "source": [
    "## 체크포인트를 이용한 훈련 시나리오\n",
    "총 훈련 작업은 10개의 epoch 까지를 실행을 합니다. 아래와 같이 두개의 훈련 잡을 통해서 합니다.\n",
    "- 첫번째의 훈련잡은 5 epoch 까지만을 실행 합니다.\n",
    "    - 매번의 epoch 마다 checkpoint 파일을 S3의  checkpoint_s3_uri 에 저장합니다.\n",
    "    \n",
    "    \n",
    "```python\n",
    "def _save_checkpoint(model, optimizer, epoch, loss, args):\n",
    "    print(\"epoch: {} - loss: {}\".format(epoch+1, loss))\n",
    "    checkpointing_path = args.checkpoint_path + '/checkpoint.pth'\n",
    "    print(\"Saving the Checkpoint: {}\".format(checkpointing_path))\n",
    "    torch.save({\n",
    "        'epoch': epoch+1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "        }, checkpointing_path)\n",
    "\n",
    "\n",
    "```\n",
    "- 두번째의 훈련잡은 6 epoch 부터 10 epoch 까지 실행합니다.\n",
    "    - 훈련이 시작시에  checkpoint_s3_uri 에서 마지막 훈련 결과(가중치)를 가져와서 모델에 로딩한 후에 시작 합니다.\n",
    "\n",
    "### 스팟 인스턴스 훈련 시나리오\n",
    "- 스팟 인스턴스로 훈련을 하다가 이 리소스가 다른 유저에게 빼앗기면, 훈련이 중단되고 스팟 인스턴스가 다시 사용가능할때에, checkpoint_s3_uri 에서 마지막 저장된 체크포인트를 가져와서 다시 훈련을 재개 합니다. \n",
    "- 상세 사항은 개발자 가이드를 보세요. --> [관리형 스팟 교육](https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/model-managed-spot-training.html)\n",
    "\n",
    "#### 체크포인트를 S3에 성공적으로 복사하려면 debugger_hook_config 매개 변수를 False로 설정해야 합니다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04df505a",
   "metadata": {},
   "source": [
    "### 첫 번째 훈련 잡을 실행\n",
    "- 스팟 인스턴스에 필요한 인자를 설정 합니다.\n",
    "- 5 epochs 까지를 훈련 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8857542",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_spot_instances = True\n",
    "max_run=600\n",
    "max_wait = 1200 if use_spot_instances else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0423b54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'epochs': 5}\n",
    "\n",
    "from sagemaker.pytorch import PyTorch\n",
    "spot_estimator = PyTorch(\n",
    "                            entry_point='train_spot.py',\n",
    "                            source_dir='source',                                                            \n",
    "                            role=role,\n",
    "                            framework_version='1.6.0',\n",
    "                            py_version='py3',\n",
    "                            instance_count=1,\n",
    "                            instance_type='ml.p3.2xlarge',\n",
    "                            base_job_name='cifar10-pytorch-spot-1',\n",
    "                            hyperparameters=hyperparameters,\n",
    "                            checkpoint_s3_uri=checkpoint_s3_path,\n",
    "                            debugger_hook_config=False,\n",
    "                            use_spot_instances=use_spot_instances,\n",
    "                            max_run=max_run,\n",
    "                            max_wait=max_wait)\n",
    "\n",
    "spot_estimator.fit(inputs, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "936b3df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-29 05:26:18 Starting - Starting the training job...\n",
      "2021-07-29 05:26:20 Starting - Launching requested ML instancesProfilerReport-1627536377: InProgress\n",
      "......\n",
      "2021-07-29 05:27:29 Starting - Preparing the instances for training............\n",
      "2021-07-29 05:29:47 Downloading - Downloading input data\n",
      "2021-07-29 05:29:47 Training - Downloading the training image........\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-07-29 05:30:57,298 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-07-29 05:30:57,323 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2021-07-29 05:31:00,353 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-07-29 05:31:00,660 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch==1.6.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (1.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torchvision==0.7.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (0.7.0)\u001b[0m\n",
      "\u001b[34mCollecting torchsummary==1.5.1\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from torch==1.6.0->-r requirements.txt (line 1)) (0.18.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torch==1.6.0->-r requirements.txt (line 1)) (1.19.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.6/site-packages (from torchvision==0.7.0->-r requirements.txt (line 2)) (8.2.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: torchsummary\u001b[0m\n",
      "\u001b[34mSuccessfully installed torchsummary-1.5.1\u001b[0m\n",
      "\u001b[34m2021-07-29 05:31:03,224 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 5\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"cifar10-pytorch-spot-1-2021-07-29-05-26-17-833\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-northeast-2-057716757052/cifar10-pytorch-spot-1-2021-07-29-05-26-17-833/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_spot\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_spot.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":5}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_spot.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_spot\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-northeast-2-057716757052/cifar10-pytorch-spot-1-2021-07-29-05-26-17-833/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":5},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"cifar10-pytorch-spot-1-2021-07-29-05-26-17-833\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-2-057716757052/cifar10-pytorch-spot-1-2021-07-29-05-26-17-833/source/sourcedir.tar.gz\",\"module_name\":\"train_spot\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_spot.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"5\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=5\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train_spot.py --epochs 5\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mDistributed training - False\u001b[0m\n",
      "\u001b[34mCheckpointing directory /opt/ml/checkpoints exists\u001b[0m\n",
      "\u001b[34mDevice Type: cuda\u001b[0m\n",
      "\u001b[34mLoading Cifar10 dataset\u001b[0m\n",
      "\u001b[34mModel loaded from get_model_network()\u001b[0m\n",
      "\n",
      "2021-07-29 05:31:04 Training - Training image download completed. Training in progress.\u001b[34m[2021-07-29 05:31:09.121 algo-1:31 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2021-07-29 05:31:09.424 algo-1:31 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,  2000] loss: 2.280\u001b[0m\n",
      "\u001b[34m[1,  4000] loss: 1.958\u001b[0m\n",
      "\u001b[34m[1,  6000] loss: 1.702\u001b[0m\n",
      "\u001b[34m[1,  8000] loss: 1.606\u001b[0m\n",
      "\u001b[34m[1, 10000] loss: 1.544\u001b[0m\n",
      "\u001b[34m[1, 12000] loss: 1.465\u001b[0m\n",
      "\u001b[34mepoch: 1 - loss: 1.5614159107208252\u001b[0m\n",
      "\u001b[34mSaving the Checkpoint: /opt/ml/checkpoints/checkpoint.pth\u001b[0m\n",
      "\u001b[34m[2,  2000] loss: 1.393\u001b[0m\n",
      "\u001b[34m[2,  4000] loss: 1.373\u001b[0m\n",
      "\u001b[34m[2,  6000] loss: 1.364\u001b[0m\n",
      "\u001b[34m[2,  8000] loss: 1.326\u001b[0m\n",
      "\u001b[34m[2, 10000] loss: 1.303\u001b[0m\n",
      "\u001b[34m[2, 12000] loss: 1.294\u001b[0m\n",
      "\u001b[34mepoch: 2 - loss: 1.0252461433410645\u001b[0m\n",
      "\u001b[34mSaving the Checkpoint: /opt/ml/checkpoints/checkpoint.pth\u001b[0m\n",
      "\u001b[34m[3,  2000] loss: 1.217\u001b[0m\n",
      "\u001b[34m[3,  4000] loss: 1.193\u001b[0m\n",
      "\u001b[34m[3,  6000] loss: 1.219\u001b[0m\n",
      "\u001b[34m[3,  8000] loss: 1.199\u001b[0m\n",
      "\u001b[34m[3, 10000] loss: 1.170\u001b[0m\n",
      "\u001b[34m[3, 12000] loss: 1.206\u001b[0m\n",
      "\u001b[34mepoch: 3 - loss: 2.5190157890319824\u001b[0m\n",
      "\u001b[34mSaving the Checkpoint: /opt/ml/checkpoints/checkpoint.pth\u001b[0m\n",
      "\u001b[34m[4,  2000] loss: 1.109\u001b[0m\n",
      "\u001b[34m[4,  4000] loss: 1.113\u001b[0m\n",
      "\u001b[34m[4,  6000] loss: 1.112\u001b[0m\n",
      "\u001b[34m[4,  8000] loss: 1.098\u001b[0m\n",
      "\u001b[34m[4, 10000] loss: 1.103\u001b[0m\n",
      "\u001b[34m[4, 12000] loss: 1.120\u001b[0m\n",
      "\u001b[34mepoch: 4 - loss: 0.8097826242446899\u001b[0m\n",
      "\u001b[34mSaving the Checkpoint: /opt/ml/checkpoints/checkpoint.pth\u001b[0m\n",
      "\u001b[34m[5,  2000] loss: 1.004\u001b[0m\n",
      "\u001b[34m[5,  4000] loss: 1.053\u001b[0m\n",
      "\u001b[34m[5,  6000] loss: 1.030\u001b[0m\n",
      "\u001b[34m[5,  8000] loss: 1.058\u001b[0m\n",
      "\u001b[34m[5, 10000] loss: 1.039\u001b[0m\n",
      "\u001b[34m[5, 12000] loss: 1.053\u001b[0m\n",
      "\u001b[34mepoch: 5 - loss: 0.9024291634559631\u001b[0m\n",
      "\u001b[34mSaving the Checkpoint: /opt/ml/checkpoints/checkpoint.pth\u001b[0m\n",
      "\u001b[34mFinished Training\u001b[0m\n",
      "\u001b[34mthe model is saved at /opt/ml/model/model.pth\n",
      "\u001b[0m\n",
      "\u001b[34m2021-07-29 05:36:07,987 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-07-29 05:36:20 Uploading - Uploading generated training model\n",
      "2021-07-29 05:36:20 Completed - Training job completed\n",
      "Training seconds: 407\n",
      "Billable seconds: 122\n",
      "Managed Spot Training savings: 70.0%\n"
     ]
    }
   ],
   "source": [
    "spot_estimator.logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0315454",
   "metadata": {},
   "source": [
    "### 세이지 메이커 콘솔에서 체크포인트 확인\n",
    "- 이제 SageMaker 콘솔에서 트레이닝 작업에서 체크포인트 구성을 직접 볼 수 있습니다.\n",
    "- SageMaker 콘솔에 로그인하고 최신 교육 작업을 선택한 다음 체크포인트 구성 섹션으로 스크롤합니다.\n",
    "- S3 출력 경로 링크를 선택하면 체크포인팅 데이터가 저장된 S3 버킷으로 연결됩니다.\n",
    "- 거기에 하나의 파일 (checkpoint.pth) 이 있음을 알 수 있습니다.\n",
    "\n",
    "![checkpoint_console-1.png](img/checkpoint_console.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda50f98",
   "metadata": {},
   "source": [
    "### 두 번째 훈련 잡을 실행\n",
    "- 이전 체크포인트 이후 부터 6 epochs ~ 10 epochs 까지를 훈련 합니다.\n",
    "- 훈련 시작시에 다음의 단계가 진행 됩니다.\n",
    "    - 체크포인트 s3 위치에서 체크포인트 데이터를 확인\n",
    "    - 체크 포인트가 파일이 있을 경우 훈련 도커 컨테이너의 `/ opt/ml/체크포인트'에 복사됩니다.\n",
    "- 아래의 체크 포인트 로딩하는 함수를 참조 하세요.\n",
    "\n",
    "\n",
    "```python\n",
    "def _load_checkpoint(model, optimizer, args):\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(\"Checkpoint file found!\")\n",
    "    print(\"Loading Checkpoint From: {}\".format(args.checkpoint_path + '/checkpoint.pth'))\n",
    "    checkpoint = torch.load(args.checkpoint_path + '/checkpoint.pth')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch_number = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    print(\"Checkpoint File Loaded - epoch_number: {} - loss: {}\".format(epoch_number, loss))\n",
    "    print('Resuming training from epoch: {}'.format(epoch_number+1))\n",
    "    print(\"--------------------------------------------\")\n",
    "    return model, optimizer, epoch_number\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38f6a053",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'epochs': 10}\n",
    "\n",
    "\n",
    "spot_estimator = PyTorch(\n",
    "                            entry_point='train_spot.py',\n",
    "                            source_dir='source',                                                            \n",
    "                            role=role,\n",
    "                            framework_version='1.6.0',\n",
    "                            py_version='py3',\n",
    "                            instance_count=1,\n",
    "                            instance_type='ml.p3.2xlarge',\n",
    "                            base_job_name='cifar10-pytorch-spot-2',\n",
    "                            hyperparameters=hyperparameters,\n",
    "                            checkpoint_s3_uri=checkpoint_s3_path,\n",
    "                            debugger_hook_config=False,\n",
    "                            use_spot_instances=use_spot_instances,\n",
    "                            max_run=max_run,\n",
    "                            max_wait=max_wait)\n",
    "\n",
    "spot_estimator.fit(inputs, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2819ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-29 05:36:35 Starting - Starting the training job...\n",
      "2021-07-29 05:36:58 Starting - Launching requested ML instancesProfilerReport-1627536994: InProgress\n",
      "......\n",
      "2021-07-29 05:37:58 Starting - Preparing the instances for training............\n",
      "2021-07-29 05:39:58 Downloading - Downloading input data...\n",
      "2021-07-29 05:40:19 Training - Downloading the training image.....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-07-29 05:41:18,025 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-07-29 05:41:18,049 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2021-07-29 05:41:19,477 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-07-29 05:41:19,804 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch==1.6.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (1.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torchvision==0.7.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (0.7.0)\u001b[0m\n",
      "\u001b[34mCollecting torchsummary==1.5.1\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from torch==1.6.0->-r requirements.txt (line 1)) (0.18.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torch==1.6.0->-r requirements.txt (line 1)) (1.19.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.6/site-packages (from torchvision==0.7.0->-r requirements.txt (line 2)) (8.2.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: torchsummary\u001b[0m\n",
      "\u001b[34mSuccessfully installed torchsummary-1.5.1\n",
      "\u001b[0m\n",
      "\u001b[34m2021-07-29 05:41:22,268 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 10\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"cifar10-pytorch-spot-2-2021-07-29-05-36-34-586\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-northeast-2-057716757052/cifar10-pytorch-spot-2-2021-07-29-05-36-34-586/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_spot\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_spot.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":10}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_spot.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_spot\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-northeast-2-057716757052/cifar10-pytorch-spot-2-2021-07-29-05-36-34-586/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"cifar10-pytorch-spot-2-2021-07-29-05-36-34-586\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-2-057716757052/cifar10-pytorch-spot-2-2021-07-29-05-36-34-586/source/sourcedir.tar.gz\",\"module_name\":\"train_spot\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_spot.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"10\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train_spot.py --epochs 10\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "2021-07-29 05:41:19 Training - Training image download completed. Training in progress.\u001b[34mDistributed training - False\u001b[0m\n",
      "\u001b[34mCheckpointing directory /opt/ml/checkpoints exists\u001b[0m\n",
      "\u001b[34mDevice Type: cuda\u001b[0m\n",
      "\u001b[34mLoading Cifar10 dataset\u001b[0m\n",
      "\u001b[34mModel loaded from get_model_network()\u001b[0m\n",
      "\u001b[34m--------------------------------------------\u001b[0m\n",
      "\u001b[34mCheckpoint file found!\u001b[0m\n",
      "\u001b[34mLoading Checkpoint From: /opt/ml/checkpoints/checkpoint.pth\u001b[0m\n",
      "\u001b[34mCheckpoint File Loaded - epoch_number: 5 - loss: 0.9024291634559631\u001b[0m\n",
      "\u001b[34mResuming training from epoch: 6\u001b[0m\n",
      "\u001b[34m--------------------------------------------\u001b[0m\n",
      "\u001b[34m[2021-07-29 05:41:27.948 algo-1:31 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2021-07-29 05:41:28.245 algo-1:31 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[6,  2000] loss: 0.963\u001b[0m\n",
      "\u001b[34m[6,  4000] loss: 0.985\u001b[0m\n",
      "\u001b[34m[6,  6000] loss: 0.983\u001b[0m\n",
      "\u001b[34m[6,  8000] loss: 0.995\u001b[0m\n",
      "\u001b[34m[6, 10000] loss: 0.982\u001b[0m\n",
      "\u001b[34m[6, 12000] loss: 0.993\u001b[0m\n",
      "\u001b[34mepoch: 6 - loss: 0.6467633843421936\u001b[0m\n",
      "\u001b[34mSaving the Checkpoint: /opt/ml/checkpoints/checkpoint.pth\u001b[0m\n",
      "\u001b[34m[7,  2000] loss: 0.918\u001b[0m\n",
      "\u001b[34m[7,  4000] loss: 0.912\u001b[0m\n",
      "\u001b[34m[7,  6000] loss: 0.933\u001b[0m\n",
      "\u001b[34m[7,  8000] loss: 0.945\u001b[0m\n",
      "\u001b[34m[7, 10000] loss: 0.938\u001b[0m\n",
      "\u001b[34m[7, 12000] loss: 0.974\u001b[0m\n",
      "\u001b[34mepoch: 7 - loss: 0.47228318452835083\u001b[0m\n",
      "\u001b[34mSaving the Checkpoint: /opt/ml/checkpoints/checkpoint.pth\u001b[0m\n",
      "\u001b[34m[8,  2000] loss: 0.865\u001b[0m\n",
      "\u001b[34m[8,  4000] loss: 0.881\u001b[0m\n",
      "\u001b[34m[8,  6000] loss: 0.887\u001b[0m\n",
      "\u001b[34m[8,  8000] loss: 0.911\u001b[0m\n",
      "\u001b[34m[8, 10000] loss: 0.890\u001b[0m\n",
      "\u001b[34m[8, 12000] loss: 0.929\u001b[0m\n",
      "\u001b[34mepoch: 8 - loss: 0.6137577891349792\u001b[0m\n",
      "\u001b[34mSaving the Checkpoint: /opt/ml/checkpoints/checkpoint.pth\u001b[0m\n",
      "\u001b[34m[9,  2000] loss: 0.805\u001b[0m\n",
      "\u001b[34m[9,  4000] loss: 0.838\u001b[0m\n",
      "\u001b[34m[9,  6000] loss: 0.862\u001b[0m\n",
      "\u001b[34m[9,  8000] loss: 0.878\u001b[0m\n",
      "\u001b[34m[9, 10000] loss: 0.885\u001b[0m\n",
      "\u001b[34m[9, 12000] loss: 0.892\u001b[0m\n",
      "\u001b[34mepoch: 9 - loss: 0.6265579462051392\u001b[0m\n",
      "\u001b[34mSaving the Checkpoint: /opt/ml/checkpoints/checkpoint.pth\u001b[0m\n",
      "\u001b[34m[10,  2000] loss: 0.770\u001b[0m\n",
      "\u001b[34m[10,  4000] loss: 0.799\u001b[0m\n",
      "\u001b[34m[10,  6000] loss: 0.817\u001b[0m\n",
      "\u001b[34m[10,  8000] loss: 0.850\u001b[0m\n",
      "\u001b[34m[10, 10000] loss: 0.854\u001b[0m\n",
      "\n",
      "2021-07-29 05:46:40 Uploading - Uploading generated training model\u001b[34m[10, 12000] loss: 0.854\u001b[0m\n",
      "\u001b[34mepoch: 10 - loss: 0.9091147184371948\u001b[0m\n",
      "\u001b[34mSaving the Checkpoint: /opt/ml/checkpoints/checkpoint.pth\u001b[0m\n",
      "\u001b[34mFinished Training\u001b[0m\n",
      "\u001b[34mthe model is saved at /opt/ml/model/model.pth\u001b[0m\n",
      "\u001b[34m2021-07-29 05:46:34,152 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-07-29 05:47:00 Completed - Training job completed\n",
      "ProfilerReport-1627536994: NoIssuesFound\n",
      "Training seconds: 413\n",
      "Billable seconds: 124\n",
      "Managed Spot Training savings: 70.0%\n"
     ]
    }
   ],
   "source": [
    "spot_estimator.logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fac1f27",
   "metadata": {},
   "source": [
    "### 훈련 잡 로그 분석\n",
    "\n",
    "훈련 잡 로그를 분석하면 훈련 잡 이 6번째 epoch 부터 시작된다는 것을 알 수 있습니다.\n",
    "\n",
    "`_load_체크포인트` 함수의 출력을 볼 수 있습니다:\n",
    "\n",
    "```\n",
    "--------------------------------------------\n",
    "Checkpoint file found!\n",
    "Loading Checkpoint From: /opt/ml/checkpoints/checkpoint.pth\n",
    "Checkpoint File Loaded - epoch_number: 5 - loss: 0.8455273509025574\n",
    "Resuming training from epoch: 6\n",
    "--------------------------------------------\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeb4718",
   "metadata": {},
   "source": [
    "훈련이 완료 된 후에 S3 의 체크포인트 파일이 업데이트가 됩니다.\n",
    "```python\n",
    "checkpoint.pth\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd4fb85",
   "metadata": {},
   "source": [
    "## 모델 아티펙트 저장\n",
    "- 아티펙트를 저장하여 추론에 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3433830e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spot_artifact_path:  s3://sagemaker-ap-northeast-2-057716757052/cifar10-pytorch-spot-2-2021-07-29-05-36-34-586/output/model.tar.gz\n",
      "Stored 'spot_artifact_path' (str)\n"
     ]
    }
   ],
   "source": [
    "spot_artifact_path = spot_estimator.model_data\n",
    "print(\"spot_artifact_path: \", spot_artifact_path)\n",
    "\n",
    "%store spot_artifact_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82bd9b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceca7b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d133a334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
