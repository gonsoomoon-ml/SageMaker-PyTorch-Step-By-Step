{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 1.7] DDP 훈련\n",
    "\n",
    "본 워크샵의 모든 노트북은 `conda_python3` 여기에서 작업 합니다.\n",
    "\n",
    "이 노트북은 아래와 같은 작업을 합니다.\n",
    "- 아래는 세이지메이커의 어떤 피쳐도 사용하지 않고, PyTorch 만을 사용해서 훈련 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch CIFAR-10 local training  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"sagemaker/DEMO-pytorch-cnn-cifar10\"\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the data\n",
    "We use the ```sagemaker.Session.upload_data``` function to upload our datasets to an S3 location. The return value inputs identifies the location -- we will use this later when we start the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3 inputs:  s3://sagemaker-us-east-1-057716757052/data/cifar10\n"
     ]
    }
   ],
   "source": [
    "s3_inputs = sagemaker_session.upload_data(path=\"../data\", bucket=bucket, key_prefix=\"data/cifar10\")\n",
    "print(\"s3 inputs: \", s3_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a script for training \n",
    "- epoch 10 , 20\n",
    "    - 각각 테스트 정확도 55.2, 62.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml.p3.16xlarge\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    " #instance_type = \"local_gpu\"\n",
    "instance_type=\"ml.p3.16xlarge\"\n",
    "\n",
    "if instance_type == 'local_gpu':\n",
    "    sess = sagemaker.local.LocalSession()\n",
    "    inputs = 'file://../data'    \n",
    "    instance_count = 1\n",
    "    hyperparameters={\"epochs\": 1, \n",
    "                     'batch-size': 128,                     \n",
    "                     'lr': 0.01,\n",
    "                    }    \n",
    "    print(instance_type)\n",
    "else:\n",
    "    sess = sagemaker.Session()\n",
    "    inputs = s3_inputs\n",
    "    instance_count = 2\n",
    "    hyperparameters={\"epochs\": 20, \n",
    "                     'batch-size': 128,                     \n",
    "                     'lr': 0.01,\n",
    "                    }        \n",
    "    print(instance_type)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-09 08:48:04 Starting - Starting the training job...\n",
      "2021-07-09 08:48:29 Starting - Launching requested ML instancesProfilerReport-1625820484: InProgress\n",
      ".........\n",
      "2021-07-09 08:49:49 Starting - Preparing the instances for training.........\n",
      "2021-07-09 08:51:30 Downloading - Downloading input data......\n",
      "2021-07-09 08:52:35 Training - Downloading the training image...............\n",
      "2021-07-09 08:55:05 Training - Training image download completed. Training in progress..\u001b[35mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[35mbash: no job control in this shell\u001b[0m\n",
      "\u001b[35m2021-07-09 08:55:05,445 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[35m2021-07-09 08:55:05,523 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-07-09 08:55:06,034 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-07-09 08:55:06,112 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[35m2021-07-09 08:55:08,551 sagemaker_pytorch_container.training INFO     Invoking SMDataParallel\u001b[0m\n",
      "\u001b[35m2021-07-09 08:55:08,552 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[35m2021-07-09 08:55:08,949 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[35m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34m2021-07-09 08:55:09,142 sagemaker_pytorch_container.training INFO     Invoking SMDataParallel\u001b[0m\n",
      "\u001b[34m2021-07-09 08:55:09,142 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-07-09 08:55:09,480 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[35mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\n",
      "\u001b[35m2021-07-09 08:55:11,217 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[35m2021-07-09 08:55:11,218 sagemaker-training-toolkit INFO     Waiting for MPI Master to create SSH daemon.\u001b[0m\n",
      "\u001b[35m2021-07-09 08:55:11,219 sagemaker-training-toolkit INFO     Cannot connect to host algo-1\u001b[0m\n",
      "\u001b[35m2021-07-09 08:55:11,219 sagemaker-training-toolkit INFO     Connection failed with exception: \n",
      " [Errno None] Unable to connect to port 22 on 10.0.250.66\u001b[0m\n",
      "\u001b[35m2021-07-09 08:55:12,228 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[35m2021-07-09 08:55:12,473 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[35m2021-07-09 08:55:12,473 sagemaker-training-toolkit INFO     Can connect to host algo-1\u001b[0m\n",
      "\u001b[35m2021-07-09 08:55:12,473 sagemaker-training-toolkit INFO     MPI Master online, creating SSH daemon.\u001b[0m\n",
      "\u001b[35m2021-07-09 08:55:12,473 sagemaker-training-toolkit INFO     Writing environment variables to /etc/environment for the MPI process.\u001b[0m\n",
      "\u001b[35m2021-07-09 08:55:12,478 sagemaker-training-toolkit INFO     Waiting for MPI process to finish.\u001b[0m\n",
      "\u001b[35m2021-07-09 08:55:15,486 sagemaker-training-toolkit INFO     Process[es]: [psutil.Process(pid=57, name='orted', status='sleeping', started='08:55:14')]\u001b[0m\n",
      "\u001b[35m2021-07-09 08:55:15,486 sagemaker-training-toolkit INFO     Orted process found [psutil.Process(pid=57, name='orted', status='sleeping', started='08:55:14')]\u001b[0m\n",
      "\u001b[35m2021-07-09 08:55:15,487 sagemaker-training-toolkit INFO     Waiting for orted process [psutil.Process(pid=57, name='orted', status='sleeping', started='08:55:14')]\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\n",
      "\u001b[34m2021-07-09 08:55:11,997 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[34m2021-07-09 08:55:11,997 sagemaker-training-toolkit INFO     Creating SSH daemon.\u001b[0m\n",
      "\u001b[34m2021-07-09 08:55:12,000 sagemaker-training-toolkit INFO     Waiting for MPI workers to establish their SSH connections\u001b[0m\n",
      "\u001b[34m2021-07-09 08:55:12,002 sagemaker-training-toolkit INFO     Cannot connect to host algo-2 at port 22. Retrying...\u001b[0m\n",
      "\u001b[34m2021-07-09 08:55:12,002 sagemaker-training-toolkit INFO     Connection closed\u001b[0m\n",
      "\u001b[34m2021-07-09 08:55:13,010 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[34m2021-07-09 08:55:13,091 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34m2021-07-09 08:55:13,091 sagemaker-training-toolkit INFO     Can connect to host algo-2 at port 22\u001b[0m\n",
      "\u001b[34m2021-07-09 08:55:13,091 sagemaker-training-toolkit INFO     Connection closed\u001b[0m\n",
      "\u001b[34m2021-07-09 08:55:13,091 sagemaker-training-toolkit INFO     Worker algo-2 available for communication\u001b[0m\n",
      "\u001b[34m2021-07-09 08:55:13,091 sagemaker-training-toolkit INFO     Network interface name: eth0\u001b[0m\n",
      "\u001b[34m2021-07-09 08:55:13,091 sagemaker-training-toolkit INFO     Host: ['algo-1', 'algo-2']\u001b[0m\n",
      "\u001b[34m2021-07-09 08:55:13,092 sagemaker-training-toolkit INFO     instance type: ml.p3.16xlarge\u001b[0m\n",
      "\u001b[34m2021-07-09 08:55:13,172 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_distributed_dataparallel_enabled\": true,\n",
      "        \"sagemaker_distributed_dataparallel_custom_mpi_options\": \"\",\n",
      "        \"sagemaker_instance_type\": \"ml.p3.16xlarge\"\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 128,\n",
      "        \"lr\": 0.01,\n",
      "        \"epochs\": 20\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"cifar10-ddp-2021-07-09-08-48-04-181\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-057716757052/cifar10-ddp-2021-07-09-08-48-04-181/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_ddp\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 64,\n",
      "    \"num_gpus\": 8,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_ddp.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":128,\"epochs\":20,\"lr\":0.01}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_ddp.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_distributed_dataparallel_custom_mpi_options\":\"\",\"sagemaker_distributed_dataparallel_enabled\":true,\"sagemaker_instance_type\":\"ml.p3.16xlarge\"}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_ddp\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=64\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-057716757052/cifar10-ddp-2021-07-09-08-48-04-181/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_distributed_dataparallel_custom_mpi_options\":\"\",\"sagemaker_distributed_dataparallel_enabled\":true,\"sagemaker_instance_type\":\"ml.p3.16xlarge\"},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"batch-size\":128,\"epochs\":20,\"lr\":0.01},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"cifar10-ddp-2021-07-09-08-48-04-181\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-057716757052/cifar10-ddp-2021-07-09-08-48-04-181/source/sourcedir.tar.gz\",\"module_name\":\"train_ddp\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_ddp.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"128\",\"--epochs\",\"20\",\"--lr\",\"0.01\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=128\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.01\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=20\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34mmpirun --host algo-1:8,algo-2:8 -np 16 --allow-run-as-root --tag-output --oversubscribe -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -mca btl_vader_single_copy_mechanism none -mca plm_rsh_num_concurrent 2 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x SMDATAPARALLEL_USE_HOMOGENEOUS=1 -x FI_PROVIDER=efa -x RDMAV_FORK_SAFE=1 -x LD_PRELOAD=/opt/conda/lib/python3.6/site-packages/gethostname.cpython-36m-x86_64-linux-gnu.so -x SMDATAPARALLEL_SERVER_ADDR=algo-1 -x SMDATAPARALLEL_SERVER_PORT=7592 -x SAGEMAKER_INSTANCE_TYPE=ml.p3.16xlarge smddprun /opt/conda/bin/python3.6 -m mpi4py train_ddp.py --batch-size 128 --epochs 20 --lr 0.01\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Bootstrap : Using [0]eth0:10.0.202.80<0>\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Bootstrap : Using [0]eth0:10.0.250.66<0>\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.250.66<0>\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:NCCL version 2.7.8+cuda11.1\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.202.80<0>\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:NCCL version 2.7.8+cuda11.1\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Bootstrap : Using [0]eth0:10.0.250.66<0>\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO Bootstrap : Using [0]eth0:10.0.250.66<0>\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Bootstrap : Using [0]eth0:10.0.250.66<0>\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO NET/Socket : Using [0]eth0:10.0.250.66<0>\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO NET/Socket : Using [0]eth0:10.0.250.66<0>\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO NET/Socket : Using [0]eth0:10.0.250.66<0>\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO Bootstrap : Using [0]eth0:10.0.202.80<0>\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Bootstrap : Using [0]eth0:10.0.202.80<0>\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Bootstrap : Using [0]eth0:10.0.202.80<0>\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO NET/Socket : Using [0]eth0:10.0.202.80<0>\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO NET/Socket : Using [0]eth0:10.0.202.80<0>\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO NET/Socket : Using [0]eth0:10.0.202.80<0>\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO Bootstrap : Using [0]eth0:10.0.250.66<0>\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO Bootstrap : Using [0]eth0:10.0.250.66<0>\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO Bootstrap : Using [0]eth0:10.0.250.66<0>\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Bootstrap : Using [0]eth0:10.0.250.66<0>\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO NET/Socket : Using [0]eth0:10.0.250.66<0>\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO NET/Socket : Using [0]eth0:10.0.250.66<0>\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO NET/Socket : Using [0]eth0:10.0.250.66<0>\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO NET/Socket : Using [0]eth0:10.0.250.66<0>\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO Bootstrap : Using [0]eth0:10.0.202.80<0>\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO Bootstrap : Using [0]eth0:10.0.202.80<0>\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO Bootstrap : Using [0]eth0:10.0.202.80<0>\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO Bootstrap : Using [0]eth0:10.0.202.80<0>\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO NET/Socket : Using [0]eth0:10.0.202.80<0>\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO NET/Socket : Using [0]eth0:10.0.202.80<0>\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO NET/Socket : Using [0]eth0:10.0.202.80<0>\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO NET/Socket : Using [0]eth0:10.0.202.80<0>\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO Trees [0] 5/-1/-1->1->2|2->1->5/-1/-1 [1] 5/-1/-1->1->2|2->1->5/-1/-1 [2] 2/-1/-1->1->5|5->1->2/-1/-1 [3] 2/-1/-1->1->5|5->1->2/-1/-1 [4] 3/-1/-1->1->0|0->1->3/-1/-1 [5] -1/-1/-1->1->3|3->1->-1/-1/-1 [6] 5/-1/-1->1->2|2->1->5/-1/-1 [7] 5/-1/-1->1->2|2->1->5/-1/-1 [8] 2/-1/-1->1->5|5->1->2/-1/-1 [9] 2/-1/-1->1->5|5->1->2/-1/-1 [10] 3/-1/-1->1->0|0->1->3/-1/-1 [11] -1/-1/-1->1->3|3->1->-1/-1/-1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 00/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 01/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 02/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 03/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 04/12 :    0   1   3   7   5   4   6   2\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 05/12 :    0   2   6   4   5   7   3   1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 06/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 07/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 08/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Trees [0] 1/-1/-1->2->3|3->2->1/-1/-1 [1] 1/-1/-1->2->3|3->2->1/-1/-1 [2] 3/-1/-1->2->1|1->2->3/-1/-1 [3] 3/-1/-1->2->1|1->2->3/-1/-1 [4] -1/-1/-1->2->6|6->2->-1/-1/-1 [5] 6/-1/-1->2->0|0->2->6/-1/-1 [6] 1/-1/-1->2->3|3->2->1/-1/-1 [7] 1/-1/-1->2->3|3->2->1/-1/-1 [8] 3/-1/-1->2->1|1->2->3/-1/-1 [9] 3/-1/-1->2->1|1->2->3/-1/-1 [10] -1/-1/-1->2->6|6->2->-1/-1/-1 [11] 6/-1/-1->2->0|0->2->6/-1/-1\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Trees [0] 4/-1/-1->7->6|6->7->4/-1/-1 [1] 4/-1/-1->7->6|6->7->4/-1/-1 [2] 6/-1/-1->7->4|4->7->6/-1/-1 [3] 6/-1/-1->7->4|4->7->6/-1/-1 [4] 5/-1/-1->7->3|3->7->5/-1/-1 [5] 3/-1/-1->7->5|5->7->3/-1/-1 [6] 4/-1/-1->7->6|6->7->4/-1/-1 [7] 4/-1/-1->7->6|6->7->4/-1/-1 [8] 6/-1/-1->7->4|4->7->6/-1/-1 [9] 6/-1/-1->7->4|4->7->6/-1/-1 [10] 5/-1/-1->7->3|3->7->5/-1/-1 [11] 3/-1/-1->7->5|5->7->3/-1/-1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 09/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 10/12 :    0   1   3   7   5   4   6   2\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 11/12 :    0   2   6   4   5   7   3   1\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Trees [0] 2/-1/-1->3->0|0->3->2/-1/-1 [1] 2/-1/-1->3->0|0->3->2/-1/-1 [2] -1/-1/-1->3->2|2->3->-1/-1/-1 [3] -1/-1/-1->3->2|2->3->-1/-1/-1 [4] 7/-1/-1->3->1|1->3->7/-1/-1 [5] 1/-1/-1->3->7|7->3->1/-1/-1 [6] 2/-1/-1->3->0|0->3->2/-1/-1 [7] 2/-1/-1->3->0|0->3->2/-1/-1 [8] -1/-1/-1->3->2|2->3->-1/-1/-1 [9] -1/-1/-1->3->2|2->3->-1/-1/-1 [10] 7/-1/-1->3->1|1->3->7/-1/-1 [11] 1/-1/-1->3->7|7->3->1/-1/-1\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO Trees [0] -1/-1/-1->4->7|7->4->-1/-1/-1 [1] -1/-1/-1->4->7|7->4->-1/-1/-1 [2] 7/-1/-1->4->0|0->4->7/-1/-1 [3] 7/-1/-1->4->0|0->4->7/-1/-1 [4] 6/-1/-1->4->5|5->4->6/-1/-1 [5] 5/-1/-1->4->6|6->4->5/-1/-1 [6] -1/-1/-1->4->7|7->4->-1/-1/-1 [7] -1/-1/-1->4->7|7->4->-1/-1/-1 [8] 7/-1/-1->4->0|0->4->7/-1/-1 [9] 7/-1/-1->4->0|0->4->7/-1/-1 [10] 6/-1/-1->4->5|5->4->6/-1/-1 [11] 5/-1/-1->4->6|6->4->5/-1/-1\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO Trees [0] 7/-1/-1->6->5|5->6->7/-1/-1 [1] 7/-1/-1->6->5|5->6->7/-1/-1 [2] 5/-1/-1->6->7|7->6->5/-1/-1 [3] 5/-1/-1->6->7|7->6->5/-1/-1 [4] 2/-1/-1->6->4|4->6->2/-1/-1 [5] 4/-1/-1->6->2|2->6->4/-1/-1 [6] 7/-1/-1->6->5|5->6->7/-1/-1 [7] 7/-1/-1->6->5|5->6->7/-1/-1 [8] 5/-1/-1->6->7|7->6->5/-1/-1 [9] 5/-1/-1->6->7|7->6->5/-1/-1 [10] 2/-1/-1->6->4|4->6->2/-1/-1 [11] 4/-1/-1->6->2|2->6->4/-1/-1\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO Trees [0] 6/-1/-1->5->1|1->5->6/-1/-1 [1] 6/-1/-1->5->1|1->5->6/-1/-1 [2] 1/-1/-1->5->6|6->5->1/-1/-1 [3] 1/-1/-1->5->6|6->5->1/-1/-1 [4] 4/-1/-1->5->7|7->5->4/-1/-1 [5] 7/-1/-1->5->4|4->5->7/-1/-1 [6] 6/-1/-1->5->1|1->5->6/-1/-1 [7] 6/-1/-1->5->1|1->5->6/-1/-1 [8] 1/-1/-1->5->6|6->5->1/-1/-1 [9] 1/-1/-1->5->6|6->5->1/-1/-1 [10] 4/-1/-1->5->7|7->5->4/-1/-1 [11] 7/-1/-1->5->4|4->5->7/-1/-1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Trees [0] 3/-1/-1->0->-1|-1->0->3/-1/-1 [1] 3/-1/-1->0->-1|-1->0->3/-1/-1 [2] 4/-1/-1->0->-1|-1->0->4/-1/-1 [3] 4/-1/-1->0->-1|-1->0->4/-1/-1 [4] 1/-1/-1->0->-1|-1->0->1/-1/-1 [5] 2/-1/-1->0->-1|-1->0->2/-1/-1 [6] 3/-1/-1->0->-1|-1->0->3/-1/-1 [7] 3/-1/-1->0->-1|-1->0->3/-1/-1 [8] 4/-1/-1->0->-1|-1->0->4/-1/-1 [9] 4/-1/-1->0->-1|-1->0->4/-1/-1 [10] 1/-1/-1->0->-1|-1->0->1/-1/-1 [11] 2/-1/-1->0->-1|-1->0->2/-1/-1\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 00 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO Channel 00 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 00 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Channel 00 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO Channel 00 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO Channel 00 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO Channel 00 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 00 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO Channel 00 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 00 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO Channel 00 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 00 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Channel 00 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO Channel 00 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO Channel 00 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO Channel 01 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 01 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 01 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO Channel 01 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 01 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Channel 01 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO Channel 01 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO Channel 01 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO Channel 01 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 01 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO Channel 01 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO Channel 01 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Channel 01 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 01 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO Channel 01 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO Channel 02 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 02 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 02 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO Channel 02 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Trees [0] 1/-1/-1->2->3|3->2->1/-1/-1 [1] 1/-1/-1->2->3|3->2->1/-1/-1 [2] 3/-1/-1->2->1|1->2->3/-1/-1 [3] 3/-1/-1->2->1|1->2->3/-1/-1 [4] -1/-1/-1->2->6|6->2->-1/-1/-1 [5] 6/-1/-1->2->0|0->2->6/-1/-1 [6] 1/-1/-1->2->3|3->2->1/-1/-1 [7] 1/-1/-1->2->3|3->2->1/-1/-1 [8] 3/-1/-1->2->1|1->2->3/-1/-1 [9] 3/-1/-1->2->1|1->2->3/-1/-1 [10] -1/-1/-1->2->6|6->2->-1/-1/-1 [11] 6/-1/-1->2->0|0->2->6/-1/-1\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Trees [0] 2/-1/-1->3->0|0->3->2/-1/-1 [1] 2/-1/-1->3->0|0->3->2/-1/-1 [2] -1/-1/-1->3->2|2->3->-1/-1/-1 [3] -1/-1/-1->3->2|2->3->-1/-1/-1 [4] 7/-1/-1->3->1|1->3->7/-1/-1 [5] 1/-1/-1->3->7|7->3->1/-1/-1 [6] 2/-1/-1->3->0|0->3->2/-1/-1 [7] 2/-1/-1->3->0|0->3->2/-1/-1 [8] -1/-1/-1->3->2|2->3->-1/-1/-1 [9] -1/-1/-1->3->2|2->3->-1/-1/-1 [10] 7/-1/-1->3->1|1->3->7/-1/-1 [11] 1/-1/-1->3->7|7->3->1/-1/-1\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO Trees [0] -1/-1/-1->4->7|7->4->-1/-1/-1 [1] -1/-1/-1->4->7|7->4->-1/-1/-1 [2] 7/-1/-1->4->0|0->4->7/-1/-1 [3] 7/-1/-1->4->0|0->4->7/-1/-1 [4] 6/-1/-1->4->5|5->4->6/-1/-1 [5] 5/-1/-1->4->6|6->4->5/-1/-1 [6] -1/-1/-1->4->7|7->4->-1/-1/-1 [7] -1/-1/-1->4->7|7->4->-1/-1/-1 [8] 7/-1/-1->4->0|0->4->7/-1/-1 [9] 7/-1/-1->4->0|0->4->7/-1/-1 [10] 6/-1/-1->4->5|5->4->6/-1/-1 [11] 5/-1/-1->4->6|6->4->5/-1/-1\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO Trees [0] 6/-1/-1->5->1|1->5->6/-1/-1 [1] 6/-1/-1->5->1|1->5->6/-1/-1 [2] 1/-1/-1->5->6|6->5->1/-1/-1 [3] 1/-1/-1->5->6|6->5->1/-1/-1 [4] 4/-1/-1->5->7|7->5->4/-1/-1 [5] 7/-1/-1->5->4|4->5->7/-1/-1 [6] 6/-1/-1->5->1|1->5->6/-1/-1 [7] 6/-1/-1->5->1|1->5->6/-1/-1 [8] 1/-1/-1->5->6|6->5->1/-1/-1 [9] 1/-1/-1->5->6|6->5->1/-1/-1 [10] 4/-1/-1->5->7|7->5->4/-1/-1 [11] 7/-1/-1->5->4|4->5->7/-1/-1\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO Trees [0] 7/-1/-1->6->5|5->6->7/-1/-1 [1] 7/-1/-1->6->5|5->6->7/-1/-1 [2] 5/-1/-1->6->7|7->6->5/-1/-1 [3] 5/-1/-1->6->7|7->6->5/-1/-1 [4] 2/-1/-1->6->4|4->6->2/-1/-1 [5] 4/-1/-1->6->2|2->6->4/-1/-1 [6] 7/-1/-1->6->5|5->6->7/-1/-1 [7] 7/-1/-1->6->5|5->6->7/-1/-1 [8] 5/-1/-1->6->7|7->6->5/-1/-1 [9] 5/-1/-1->6->7|7->6->5/-1/-1 [10] 2/-1/-1->6->4|4->6->2/-1/-1 [11] 4/-1/-1->6->2|2->6->4/-1/-1\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 00/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO Trees [0] 4/-1/-1->7->6|6->7->4/-1/-1 [1] 4/-1/-1->7->6|6->7->4/-1/-1 [2] 6/-1/-1->7->4|4->7->6/-1/-1 [3] 6/-1/-1->7->4|4->7->6/-1/-1 [4] 5/-1/-1->7->3|3->7->5/-1/-1 [5] 3/-1/-1->7->5|5->7->3/-1/-1 [6] 4/-1/-1->7->6|6->7->4/-1/-1 [7] 4/-1/-1->7->6|6->7->4/-1/-1 [8] 6/-1/-1->7->4|4->7->6/-1/-1 [9] 6/-1/-1->7->4|4->7->6/-1/-1 [10] 5/-1/-1->7->3|3->7->5/-1/-1 [11] 3/-1/-1->7->5|5->7->3/-1/-1\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 01/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 02/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 03/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 04/12 :    0   1   3   7   5   4   6   2\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO Trees [0] 5/-1/-1->1->2|2->1->5/-1/-1 [1] 5/-1/-1->1->2|2->1->5/-1/-1 [2] 2/-1/-1->1->5|5->1->2/-1/-1 [3] 2/-1/-1->1->5|5->1->2/-1/-1 [4] 3/-1/-1->1->0|0->1->3/-1/-1 [5] -1/-1/-1->1->3|3->1->-1/-1/-1 [6] 5/-1/-1->1->2|2->1->5/-1/-1 [7] 5/-1/-1->1->2|2->1->5/-1/-1 [8] 2/-1/-1->1->5|5->1->2/-1/-1 [9] 2/-1/-1->1->5|5->1->2/-1/-1 [10] 3/-1/-1->1->0|0->1->3/-1/-1 [11] -1/-1/-1->1->3|3->1->-1/-1/-1\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 05/12 :    0   2   6   4   5   7   3   1\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 06/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 07/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 08/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 09/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 10/12 :    0   1   3   7   5   4   6   2\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 11/12 :    0   2   6   4   5   7   3   1\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Trees [0] 3/-1/-1->0->-1|-1->0->3/-1/-1 [1] 3/-1/-1->0->-1|-1->0->3/-1/-1 [2] 4/-1/-1->0->-1|-1->0->4/-1/-1 [3] 4/-1/-1->0->-1|-1->0->4/-1/-1 [4] 1/-1/-1->0->-1|-1->0->1/-1/-1 [5] 2/-1/-1->0->-1|-1->0->2/-1/-1 [6] 3/-1/-1->0->-1|-1->0->3/-1/-1 [7] 3/-1/-1->0->-1|-1->0->3/-1/-1 [8] 4/-1/-1->0->-1|-1->0->4/-1/-1 [9] 4/-1/-1->0->-1|-1->0->4/-1/-1 [10] 1/-1/-1->0->-1|-1->0->1/-1/-1 [11] 2/-1/-1->0->-1|-1->0->2/-1/-1\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 02 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Channel 02 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO Channel 02 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO Channel 02 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 00 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Channel 00 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO Channel 00 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO Channel 00 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO Channel 00 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO Channel 00 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO Channel 00 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 00 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO Channel 02 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Channel 02 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 02 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO Channel 02 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 02 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO Channel 02 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO Channel 02 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO Channel 00 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 03 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 00 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Channel 00 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO Channel 00 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Channel 03 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO Channel 00 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO Channel 00 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO Channel 00 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO Channel 03 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 03 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO Channel 03 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 03 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO Channel 03 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO Channel 03 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO Channel 01 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 01 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 01 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Channel 01 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO Channel 01 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO Channel 01 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO Channel 01 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO Channel 01 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Channel 03 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO Channel 03 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 03 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO Channel 03 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 03 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO Channel 03 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO Channel 03 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO Channel 01 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 01 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Channel 01 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO Channel 01 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO Channel 01 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO Channel 01 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO Channel 01 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Channel 04 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 04 : 0[170] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO Channel 04 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 04 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO Channel 04 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 04 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO Channel 04 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO Channel 02 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO Channel 04 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 02 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 02 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Channel 02 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO Channel 02 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO Channel 02 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO Channel 02 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO Channel 02 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Channel 04 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 04 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO Channel 04 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 04 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO Channel 04 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Channel 02 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO Channel 04 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO Channel 04 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO Channel 02 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 02 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO Channel 02 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO Channel 02 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO Channel 02 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO Channel 02 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 05 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Channel 05 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 05 : 0[170] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Channel 03 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO Channel 05 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 03 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 05 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO Channel 05 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO Channel 05 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO Channel 05 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO Channel 03 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 03 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO Channel 03 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO Channel 03 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO Channel 03 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO Channel 03 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO Channel 05 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Channel 03 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Channel 05 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 05 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO Channel 05 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 05 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO Channel 05 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO Channel 03 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 03 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO Channel 05 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO Channel 03 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO Channel 03 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO Channel 03 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO Channel 03 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO Channel 06 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 06 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Channel 04 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Channel 06 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 04 : 0[170] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 06 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO Channel 06 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 06 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO Channel 06 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO Channel 04 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 04 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO Channel 04 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO Channel 06 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO Channel 04 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO Channel 04 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO Channel 04 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO Channel 06 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO Channel 06 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Channel 06 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 06 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 06 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO Channel 06 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 04 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO Channel 06 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Channel 04 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO Channel 04 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO Channel 04 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO Channel 04 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO Channel 04 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO Channel 04 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO Channel 07 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 07 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Channel 07 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO Channel 07 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 05 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 07 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 07 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO Channel 07 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO Channel 07 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO Channel 05 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 05 : 0[170] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Channel 05 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO Channel 05 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO Channel 05 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO Channel 05 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO Channel 05 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO Channel 07 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Channel 07 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO Channel 07 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 07 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 07 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO Channel 07 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 05 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO Channel 07 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO Channel 05 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO Channel 05 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Channel 05 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO Channel 05 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO Channel 05 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO Channel 05 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO Channel 08 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 08 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Channel 08 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO Channel 08 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 08 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 06 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 08 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO Channel 06 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO Channel 08 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO Channel 08 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 06 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO Channel 06 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Channel 06 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO Channel 06 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO Channel 06 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO Channel 06 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Channel 08 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO Channel 08 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO Channel 08 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 08 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 08 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO Channel 08 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO Channel 06 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO Channel 06 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO Channel 08 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 06 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Channel 06 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO Channel 06 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO Channel 06 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO Channel 06 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 09 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Channel 09 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO Channel 09 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO Channel 09 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 09 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 09 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO Channel 07 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO Channel 09 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 07 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO Channel 09 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO Channel 07 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 07 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Channel 07 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO Channel 07 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO Channel 07 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Channel 09 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO Channel 07 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO Channel 09 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO Channel 09 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 09 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 09 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO Channel 09 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO Channel 09 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO Channel 07 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 07 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO Channel 07 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Channel 10 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Channel 07 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO Channel 07 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO Channel 07 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 10 : 0[170] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO Channel 07 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO Channel 10 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO Channel 10 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 10 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 10 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO Channel 10 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO Channel 10 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO Channel 08 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 08 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 08 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO Channel 08 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Channel 08 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO Channel 08 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO Channel 08 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO Channel 08 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 10 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Channel 10 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO Channel 10 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO Channel 10 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 10 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO Channel 10 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO Channel 10 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Channel 08 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO Channel 08 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 08 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO Channel 08 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO Channel 08 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO Channel 08 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 11 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO Channel 08 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 11 : 0[170] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Channel 11 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO Channel 11 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO Channel 11 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 11 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Channel 09 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO Channel 11 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO Channel 11 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 09 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 09 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO Channel 09 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO Channel 09 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO Channel 09 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO Channel 09 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO Channel 11 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO Channel 09 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Channel 11 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 11 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 11 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO Channel 11 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Channel 09 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO Channel 11 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO Channel 11 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO comm 0x55f561c90d40 rank 1 nranks 8 cudaDev 1 busId 180 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 09 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO Channel 09 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO comm 0x556889bb1170 rank 0 nranks 8 cudaDev 0 busId 170 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO Channel 09 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO comm 0x55f16a551e10 rank 3 nranks 8 cudaDev 3 busId 1a0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO Channel 09 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO comm 0x55613cb18200 rank 2 nranks 8 cudaDev 2 busId 190 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO Channel 09 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO comm 0x55b678f2af30 rank 4 nranks 8 cudaDev 4 busId 1b0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO comm 0x55a31f0dd0c0 rank 7 nranks 8 cudaDev 7 busId 1e0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO comm 0x55cd80164880 rank 5 nranks 8 cudaDev 5 busId 1c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO comm 0x55c74d400dd0 rank 6 nranks 8 cudaDev 6 busId 1d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO Channel 09 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Channel 10 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 10 : 0[170] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO Channel 10 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 10 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO Channel 10 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO Channel 10 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO Channel 10 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO Channel 10 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 10 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Channel 10 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO Channel 10 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO Channel 10 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO Channel 10 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO Channel 10 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO Channel 10 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 11 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 11 : 0[170] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO Channel 11 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Channel 11 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO Channel 11 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO Channel 11 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO Channel 11 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO Channel 11 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO Channel 11 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 11 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO Channel 11 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Channel 11 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO Channel 11 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO Channel 11 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO comm 0x55c8059d0c80 rank 1 nranks 8 cudaDev 1 busId 180 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO Channel 11 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO comm 0x564f34e9f6d0 rank 0 nranks 8 cudaDev 0 busId 170 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO comm 0x56059c02e000 rank 2 nranks 8 cudaDev 2 busId 190 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO comm 0x55d6890352b0 rank 4 nranks 8 cudaDev 4 busId 1b0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO comm 0x55e30e431d20 rank 3 nranks 8 cudaDev 3 busId 1a0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO comm 0x559a886478a0 rank 5 nranks 8 cudaDev 5 busId 1c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO comm 0x55c13c9dca00 rank 6 nranks 8 cudaDev 6 busId 1d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO comm 0x55fef6756890 rank 7 nranks 8 cudaDev 7 busId 1e0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Trees [0] 1/-1/-1->2->3|3->2->1/-1/-1 [1] 1/-1/-1->2->3|3->2->1/-1/-1\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Trees [0] 2/8/-1->3->0|0->3->2/8/-1 [1] 2/-1/-1->3->0|0->3->2/-1/-1\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Trees [0] 4/-1/-1->7->6|6->7->4/-1/-1 [1] 4/-1/-1->7->6|6->7->4/-1/-1\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO Trees [0] 6/-1/-1->5->1|1->5->6/-1/-1 [1] 6/-1/-1->5->1|1->5->6/-1/-1\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO Trees [0] -1/-1/-1->4->7|7->4->-1/-1/-1 [1] -1/-1/-1->4->7|7->4->-1/-1/-1\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO Trees [0] 7/-1/-1->6->5|5->6->7/-1/-1 [1] 7/-1/-1->6->5|5->6->7/-1/-1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 00/02 :    0   3   2   1   5   6   7   4   8  11  10   9  13  14  15  12\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 01/02 :    0   3   2   1   5   6   7   4   8  11  10   9  13  14  15  12\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO Trees [0] 5/-1/-1->1->2|2->1->5/-1/-1 [1] 5/-1/-1->1->2|2->1->5/-1/-1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Trees [0] 3/-1/-1->0->-1|-1->0->3/-1/-1 [1] 3/-1/-1->0->11|11->0->3/-1/-1\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO Trees [0] 14/-1/-1->13->9|9->13->14/-1/-1 [1] 14/-1/-1->13->9|9->13->14/-1/-1\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Trees [0] 11/-1/-1->8->3|3->8->11/-1/-1 [1] 11/-1/-1->8->-1|-1->8->11/-1/-1\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO Trees [0] 13/-1/-1->9->10|10->9->13/-1/-1 [1] 13/-1/-1->9->10|10->9->13/-1/-1\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO Trees [0] 15/-1/-1->14->13|13->14->15/-1/-1 [1] 15/-1/-1->14->13|13->14->15/-1/-1\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO Trees [0] -1/-1/-1->12->15|15->12->-1/-1/-1 [1] -1/-1/-1->12->15|15->12->-1/-1/-1\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Trees [0] 9/-1/-1->10->11|11->10->9/-1/-1 [1] 9/-1/-1->10->11|11->10->9/-1/-1\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Trees [0] 10/-1/-1->11->8|8->11->10/-1/-1 [1] 10/0/-1->11->8|8->11->10/0/-1\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO Trees [0] 12/-1/-1->15->14|14->15->12/-1/-1 [1] 12/-1/-1->15->14|14->15->12/-1/-1\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO Channel 00 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 00 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Channel 00 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO Channel 00 : 14[1d0] -> 15[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO Channel 00 : 13[1c0] -> 14[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO Channel 00 : 9[180] -> 13[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 00 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 00 : 10[190] -> 9[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Channel 00 : 11[1a0] -> 10[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO Channel 00 : 15[1e0] -> 12[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO Channel 00 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO Channel 00 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 00 : 4[1b0] -> 8[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 00 : 12[1b0] -> 0[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO Channel 00 : 12[1b0] -> 0[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO Channel 00 : 4[1b0] -> 8[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 00 : 8[170] -> 11[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 00 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO Channel 00 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO Channel 00 : 14[1d0] -> 13[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO Channel 00 : 13[1c0] -> 9[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 00 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 00 : 10[190] -> 11[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO Channel 00 : 9[180] -> 10[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO Channel 00 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 00 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO Channel 00 : 15[1e0] -> 14[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO Channel 00 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO Channel 00 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Channel 00 : 11[1a0] -> 8[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO Channel 00 : 12[1b0] -> 15[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Channel 00 : 8[170] -> 3[1a0] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 00 : 8[170] -> 3[1a0] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO Channel 01 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 01 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO Channel 01 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Channel 00 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO Channel 01 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO Channel 01 : 13[1c0] -> 14[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO Channel 01 : 14[1d0] -> 15[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO Channel 01 : 9[180] -> 13[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 01 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 01 : 10[190] -> 9[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO Channel 01 : 15[1e0] -> 12[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Channel 01 : 11[1a0] -> 10[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO Channel 01 : 4[1b0] -> 8[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO Channel 01 : 12[1b0] -> 0[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO Channel 01 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 01 : 12[1b0] -> 0[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO Channel 01 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO Channel 01 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 01 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO Channel 01 : 14[1d0] -> 13[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO Channel 01 : 13[1c0] -> 9[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO Channel 01 : 9[180] -> 10[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:108:108 [5] NCCL INFO comm 0x55cd82e375e0 rank 5 nranks 16 cudaDev 5 busId 1c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Channel 00 : 3[1a0] -> 8[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 01 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:101:101 [6] NCCL INFO comm 0x55c7500d3b30 rank 6 nranks 16 cudaDev 6 busId 1d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO Channel 01 : 15[1e0] -> 14[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 00 : 3[1a0] -> 8[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 01 : 10[190] -> 11[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:108:108 [6] NCCL INFO comm 0x55c13f6af760 rank 14 nranks 16 cudaDev 6 busId 1d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:113:113 [5] NCCL INFO comm 0x559a8b31a600 rank 13 nranks 16 cudaDev 5 busId 1c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:112:112 [1] NCCL INFO comm 0x55c8086a39e0 rank 9 nranks 16 cudaDev 1 busId 180 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO Channel 01 : 12[1b0] -> 15[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:117:117 [7] NCCL INFO comm 0x55fef94295f0 rank 15 nranks 16 cudaDev 7 busId 1e0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:114:114 [4] NCCL INFO comm 0x55d68910a6e0 rank 12 nranks 16 cudaDev 4 busId 1b0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Channel 01 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 01 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO Channel 01 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:106:106 [1] NCCL INFO comm 0x55f564963aa0 rank 1 nranks 16 cudaDev 1 busId 180 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 01 : 4[1b0] -> 8[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 01 : 8[170] -> 11[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO comm 0x55613f7eaf60 rank 2 nranks 16 cudaDev 2 busId 190 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:102:102 [3] NCCL INFO comm 0x55f16d224b70 rank 3 nranks 16 cudaDev 3 busId 1a0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 01 : 0[170] -> 11[1a0] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO Channel 01 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO comm 0x56059ed00d60 rank 10 nranks 16 cudaDev 2 busId 190 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:107:107 [4] NCCL INFO comm 0x55b67bbfdc90 rank 4 nranks 16 cudaDev 4 busId 1b0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO comm 0x55a321dafe20 rank 7 nranks 16 cudaDev 7 busId 1e0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Channel 01 : 0[170] -> 11[1a0] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Channel 01 : 11[1a0] -> 8[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO comm 0x564f37b72430 rank 8 nranks 16 cudaDev 0 busId 170 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO Channel 01 : 11[1a0] -> 0[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 01 : 11[1a0] -> 0[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:115:115 [3] NCCL INFO comm 0x55e311104a80 rank 11 nranks 16 cudaDev 3 busId 1a0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO comm 0x556889c865a0 rank 0 nranks 16 cudaDev 0 busId 170 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Running smdistributed.dataparallel v1.2.0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:################################\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Global batch size: 128\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:batch_size: 8\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:local_rank: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Get train data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:batch_size: 8\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:batch_size: 8\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:batch_size: 8\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:batch_size: 8\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:batch_size: 8\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:batch_size: 8\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:local_rank: 2\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Get train data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:batch_size: 8\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:batch_size: 8\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:batch_size: 8\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:batch_size: 8\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:batch_size: 8\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:batch_size: 8\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:batch_size: 8\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:local_rank: 7\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:Get train data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:local_rank: 7\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Get train data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:local_rank: 1\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:Get train data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:batch_size: 8\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:local_rank: 3\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Get train data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:local_rank: 5\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Get train data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:local_rank: 1\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Get train data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:batch_size: 8\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:local_rank: 6\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Get train data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:local_rank: 4\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Get train data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:local_rank: 4\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:Get train data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:local_rank: 2\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:Get train data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:local_rank: 0\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:Get train data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:local_rank: 3\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:Get train data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:local_rank: 5\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:Get train data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:local_rank: 6\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:Get train data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Get test data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Get test data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Get test data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Get test data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Get test data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Get test data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Get test data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Get test data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:Get test data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:Get test data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:Get test data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:Get test data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:Get test data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:Get test data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:Get test data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:Get test data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Processes 3125/50000 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Processes 625/10000 (6%) of test data\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:785 [0] NCCL INFO Launch mode Parallel\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Processes 3125/50000 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Processes 625/10000 (6%) of test data\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Processes 3125/50000 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Processes 625/10000 (6%) of test data\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Processes 3125/50000 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Processes 625/10000 (6%) of test data\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Processes 3125/50000 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Processes 625/10000 (6%) of test data\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Processes 3125/50000 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Processes 625/10000 (6%) of test data\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Processes 3125/50000 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Processes 625/10000 (6%) of test data\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Processes 3125/50000 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Processes 625/10000 (6%) of test data\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Model loaded\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Model loaded\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Model loaded\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Model loaded\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Model loaded\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Model loaded\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Model loaded\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Model loaded\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:Processes 3125/50000 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:Processes 625/10000 (6%) of test data\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:Processes 3125/50000 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:Processes 625/10000 (6%) of test data\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:Processes 3125/50000 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:Processes 3125/50000 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:Processes 625/10000 (6%) of test data\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:Processes 625/10000 (6%) of test data\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:Processes 3125/50000 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:Processes 625/10000 (6%) of test data\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:Processes 3125/50000 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:Processes 625/10000 (6%) of test data\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:Processes 3125/50000 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:Processes 625/10000 (6%) of test data\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:Model loaded\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:Processes 3125/50000 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:Processes 625/10000 (6%) of test data\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:Model loaded\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:Model loaded\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:Model loaded\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:Model loaded\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:Model loaded\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:Model loaded\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:Model loaded\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-07-09 08:55:27.357 algo-1:128 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-07-09 08:55:27.357 algo-1:101 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-07-09 08:55:27.357 algo-1:100 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-07-09 08:55:27.357 algo-1:107 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-07-09 08:55:27.357 algo-1:106 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-07-09 08:55:27.357 algo-1:108 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-07-09 08:55:27.367 algo-1:102 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-07-09 08:55:27.371 algo-1:103 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-07-09 08:55:27.485 algo-1:102 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-07-09 08:55:27.485 algo-1:101 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-07-09 08:55:27.485 algo-1:108 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-07-09 08:55:27.485 algo-1:106 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-07-09 08:55:27.485 algo-1:100 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-07-09 08:55:27.485 algo-1:107 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-07-09 08:55:27.485 algo-1:103 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-07-09 08:55:27.486 algo-1:128 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:[2021-07-09 08:55:27.503 algo-2:116 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:[2021-07-09 08:55:27.503 algo-2:108 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:[2021-07-09 08:55:27.503 algo-2:113 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:[2021-07-09 08:55:27.503 algo-2:117 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:[2021-07-09 08:55:27.504 algo-2:137 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:[2021-07-09 08:55:27.504 algo-2:112 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:[2021-07-09 08:55:27.505 algo-2:114 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:[2021-07-09 08:55:27.508 algo-2:115 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:[2021-07-09 08:55:27.642 algo-2:112 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:[2021-07-09 08:55:27.642 algo-2:116 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:[2021-07-09 08:55:27.642 algo-2:108 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:[2021-07-09 08:55:27.642 algo-2:137 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:[2021-07-09 08:55:27.642 algo-2:113 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:[2021-07-09 08:55:27.642 algo-2:117 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:[2021-07-09 08:55:27.642 algo-2:114 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:[2021-07-09 08:55:27.642 algo-2:115 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [0/50000 (0%)]#011Loss: 2.309280\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:825 [0] NCCL INFO Launch mode Parallel\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:777 [0] NCCL INFO Launch mode Parallel\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [1280/50000 (3%)]#011Loss: 2.375188\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [2560/50000 (5%)]#011Loss: 2.386925\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [3840/50000 (8%)]#011Loss: 2.295150\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [5120/50000 (10%)]#011Loss: 2.361810\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [6400/50000 (13%)]#011Loss: 2.317005\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [7680/50000 (15%)]#011Loss: 2.365971\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [8960/50000 (18%)]#011Loss: 2.318067\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [10240/50000 (20%)]#011Loss: 2.309573\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [11520/50000 (23%)]#011Loss: 2.339546\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [12800/50000 (26%)]#011Loss: 2.287778\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [14080/50000 (28%)]#011Loss: 2.253170\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [15360/50000 (31%)]#011Loss: 2.273126\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [16640/50000 (33%)]#011Loss: 2.287140\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [17920/50000 (36%)]#011Loss: 2.260282\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [19200/50000 (38%)]#011Loss: 2.315595\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [20480/50000 (41%)]#011Loss: 2.337311\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [21760/50000 (43%)]#011Loss: 2.329583\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [23040/50000 (46%)]#011Loss: 2.271230\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [24320/50000 (49%)]#011Loss: 2.347714\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [25600/50000 (51%)]#011Loss: 2.245025\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [26880/50000 (54%)]#011Loss: 2.318072\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [28160/50000 (56%)]#011Loss: 2.348383\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [29440/50000 (59%)]#011Loss: 2.320436\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [30720/50000 (61%)]#011Loss: 2.270523\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [32000/50000 (64%)]#011Loss: 2.319732\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [33280/50000 (66%)]#011Loss: 2.294626\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [34560/50000 (69%)]#011Loss: 2.280396\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [35840/50000 (72%)]#011Loss: 2.294762\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [37120/50000 (74%)]#011Loss: 2.286262\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [38400/50000 (77%)]#011Loss: 2.339117\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [39680/50000 (79%)]#011Loss: 2.350320\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [40960/50000 (82%)]#011Loss: 2.309353\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [42240/50000 (84%)]#011Loss: 2.327050\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [43520/50000 (87%)]#011Loss: 2.287620\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [44800/50000 (90%)]#011Loss: 2.213836\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [46080/50000 (92%)]#011Loss: 2.310930\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [47360/50000 (95%)]#011Loss: 2.364243\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [48640/50000 (97%)]#011Loss: 2.276335\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [31200/50000 (100%)]#011Loss: 2.339746\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.1438, Accuracy: 102/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [0/50000 (0%)]#011Loss: 2.244432\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [1280/50000 (3%)]#011Loss: 2.301793\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [2560/50000 (5%)]#011Loss: 2.339016\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [3840/50000 (8%)]#011Loss: 2.277189\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [5120/50000 (10%)]#011Loss: 2.326490\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [6400/50000 (13%)]#011Loss: 2.321973\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [7680/50000 (15%)]#011Loss: 2.312419\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [8960/50000 (18%)]#011Loss: 2.303522\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [10240/50000 (20%)]#011Loss: 2.263404\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [11520/50000 (23%)]#011Loss: 2.331626\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [12800/50000 (26%)]#011Loss: 2.280041\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [14080/50000 (28%)]#011Loss: 2.263782\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [15360/50000 (31%)]#011Loss: 2.299835\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [16640/50000 (33%)]#011Loss: 2.246431\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [17920/50000 (36%)]#011Loss: 2.301024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [19200/50000 (38%)]#011Loss: 2.329124\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [20480/50000 (41%)]#011Loss: 2.296563\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [21760/50000 (43%)]#011Loss: 2.282887\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [23040/50000 (46%)]#011Loss: 2.264965\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [24320/50000 (49%)]#011Loss: 2.316088\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [25600/50000 (51%)]#011Loss: 2.265349\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [26880/50000 (54%)]#011Loss: 2.270800\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [28160/50000 (56%)]#011Loss: 2.358726\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [29440/50000 (59%)]#011Loss: 2.254370\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [30720/50000 (61%)]#011Loss: 2.281723\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [32000/50000 (64%)]#011Loss: 2.307391\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [33280/50000 (66%)]#011Loss: 2.308756\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [34560/50000 (69%)]#011Loss: 2.299010\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [35840/50000 (72%)]#011Loss: 2.285400\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [37120/50000 (74%)]#011Loss: 2.304484\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [38400/50000 (77%)]#011Loss: 2.309630\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [39680/50000 (79%)]#011Loss: 2.280949\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [40960/50000 (82%)]#011Loss: 2.268949\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [42240/50000 (84%)]#011Loss: 2.260283\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [43520/50000 (87%)]#011Loss: 2.285179\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [44800/50000 (90%)]#011Loss: 2.284746\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [46080/50000 (92%)]#011Loss: 2.284576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [47360/50000 (95%)]#011Loss: 2.348008\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [48640/50000 (97%)]#011Loss: 2.256117\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [31200/50000 (100%)]#011Loss: 2.298104\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.1434, Accuracy: 119/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [0/50000 (0%)]#011Loss: 2.265274\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [1280/50000 (3%)]#011Loss: 2.346612\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [2560/50000 (5%)]#011Loss: 2.328682\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [3840/50000 (8%)]#011Loss: 2.306139\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [5120/50000 (10%)]#011Loss: 2.329917\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [6400/50000 (13%)]#011Loss: 2.328688\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [7680/50000 (15%)]#011Loss: 2.290720\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [8960/50000 (18%)]#011Loss: 2.288853\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [10240/50000 (20%)]#011Loss: 2.306523\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [11520/50000 (23%)]#011Loss: 2.325088\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [12800/50000 (26%)]#011Loss: 2.269770\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [14080/50000 (28%)]#011Loss: 2.273766\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [15360/50000 (31%)]#011Loss: 2.281616\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [16640/50000 (33%)]#011Loss: 2.246942\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [17920/50000 (36%)]#011Loss: 2.280568\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [19200/50000 (38%)]#011Loss: 2.291712\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [20480/50000 (41%)]#011Loss: 2.294734\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [21760/50000 (43%)]#011Loss: 2.273203\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [23040/50000 (46%)]#011Loss: 2.301069\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [24320/50000 (49%)]#011Loss: 2.303939\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [25600/50000 (51%)]#011Loss: 2.284617\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [26880/50000 (54%)]#011Loss: 2.267323\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [28160/50000 (56%)]#011Loss: 2.288976\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [29440/50000 (59%)]#011Loss: 2.301309\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [30720/50000 (61%)]#011Loss: 2.302325\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [32000/50000 (64%)]#011Loss: 2.297966\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [33280/50000 (66%)]#011Loss: 2.227080\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [34560/50000 (69%)]#011Loss: 2.289728\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [35840/50000 (72%)]#011Loss: 2.331572\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [37120/50000 (74%)]#011Loss: 2.290019\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [38400/50000 (77%)]#011Loss: 2.329436\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [39680/50000 (79%)]#011Loss: 2.320792\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [40960/50000 (82%)]#011Loss: 2.303878\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [42240/50000 (84%)]#011Loss: 2.304521\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [43520/50000 (87%)]#011Loss: 2.309747\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [44800/50000 (90%)]#011Loss: 2.276351\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [46080/50000 (92%)]#011Loss: 2.307133\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [47360/50000 (95%)]#011Loss: 2.357577\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [48640/50000 (97%)]#011Loss: 2.278214\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [31200/50000 (100%)]#011Loss: 2.324356\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.1428, Accuracy: 134/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [0/50000 (0%)]#011Loss: 2.226378\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [1280/50000 (3%)]#011Loss: 2.310214\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [2560/50000 (5%)]#011Loss: 2.277835\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [3840/50000 (8%)]#011Loss: 2.283806\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [5120/50000 (10%)]#011Loss: 2.302955\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [6400/50000 (13%)]#011Loss: 2.268844\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [7680/50000 (15%)]#011Loss: 2.316723\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [8960/50000 (18%)]#011Loss: 2.304974\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [10240/50000 (20%)]#011Loss: 2.297568\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [11520/50000 (23%)]#011Loss: 2.284631\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [12800/50000 (26%)]#011Loss: 2.247095\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [14080/50000 (28%)]#011Loss: 2.289262\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [15360/50000 (31%)]#011Loss: 2.234786\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [16640/50000 (33%)]#011Loss: 2.253049\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [17920/50000 (36%)]#011Loss: 2.271221\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [19200/50000 (38%)]#011Loss: 2.324212\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [20480/50000 (41%)]#011Loss: 2.308259\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [21760/50000 (43%)]#011Loss: 2.257300\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [23040/50000 (46%)]#011Loss: 2.258615\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [24320/50000 (49%)]#011Loss: 2.323746\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [25600/50000 (51%)]#011Loss: 2.234184\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [26880/50000 (54%)]#011Loss: 2.278308\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [28160/50000 (56%)]#011Loss: 2.277549\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [29440/50000 (59%)]#011Loss: 2.285670\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [30720/50000 (61%)]#011Loss: 2.200101\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [32000/50000 (64%)]#011Loss: 2.326072\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [33280/50000 (66%)]#011Loss: 2.288242\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [34560/50000 (69%)]#011Loss: 2.266931\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [35840/50000 (72%)]#011Loss: 2.320183\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [37120/50000 (74%)]#011Loss: 2.221423\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [38400/50000 (77%)]#011Loss: 2.309393\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [39680/50000 (79%)]#011Loss: 2.328040\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [40960/50000 (82%)]#011Loss: 2.348009\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [42240/50000 (84%)]#011Loss: 2.214195\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [43520/50000 (87%)]#011Loss: 2.299900\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [44800/50000 (90%)]#011Loss: 2.295627\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [46080/50000 (92%)]#011Loss: 2.270000\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [47360/50000 (95%)]#011Loss: 2.324529\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [48640/50000 (97%)]#011Loss: 2.294321\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [31200/50000 (100%)]#011Loss: 2.341557\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.1421, Accuracy: 127/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [0/50000 (0%)]#011Loss: 2.190214\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [1280/50000 (3%)]#011Loss: 2.307185\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [2560/50000 (5%)]#011Loss: 2.294112\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [3840/50000 (8%)]#011Loss: 2.218232\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [5120/50000 (10%)]#011Loss: 2.240645\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [6400/50000 (13%)]#011Loss: 2.330055\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [7680/50000 (15%)]#011Loss: 2.285911\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [8960/50000 (18%)]#011Loss: 2.319524\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [10240/50000 (20%)]#011Loss: 2.282997\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [11520/50000 (23%)]#011Loss: 2.289168\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [12800/50000 (26%)]#011Loss: 2.296767\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [14080/50000 (28%)]#011Loss: 2.232813\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [15360/50000 (31%)]#011Loss: 2.186329\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [16640/50000 (33%)]#011Loss: 2.264010\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [17920/50000 (36%)]#011Loss: 2.212243\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [19200/50000 (38%)]#011Loss: 2.261555\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [20480/50000 (41%)]#011Loss: 2.285245\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [21760/50000 (43%)]#011Loss: 2.286736\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [23040/50000 (46%)]#011Loss: 2.194706\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [24320/50000 (49%)]#011Loss: 2.360010\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [25600/50000 (51%)]#011Loss: 2.309069\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [26880/50000 (54%)]#011Loss: 2.218038\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [28160/50000 (56%)]#011Loss: 2.305021\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [29440/50000 (59%)]#011Loss: 2.265485\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [30720/50000 (61%)]#011Loss: 2.285554\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [32000/50000 (64%)]#011Loss: 2.285096\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [33280/50000 (66%)]#011Loss: 2.204545\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [34560/50000 (69%)]#011Loss: 2.251742\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [35840/50000 (72%)]#011Loss: 2.295178\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [37120/50000 (74%)]#011Loss: 2.236089\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [38400/50000 (77%)]#011Loss: 2.321369\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [39680/50000 (79%)]#011Loss: 2.270857\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [40960/50000 (82%)]#011Loss: 2.358436\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [42240/50000 (84%)]#011Loss: 2.152992\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [43520/50000 (87%)]#011Loss: 2.299778\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [44800/50000 (90%)]#011Loss: 2.172885\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [46080/50000 (92%)]#011Loss: 2.224624\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [47360/50000 (95%)]#011Loss: 2.335837\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [48640/50000 (97%)]#011Loss: 2.197064\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [31200/50000 (100%)]#011Loss: 2.288422\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.1414, Accuracy: 119/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [0/50000 (0%)]#011Loss: 2.158909\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [1280/50000 (3%)]#011Loss: 2.305267\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [2560/50000 (5%)]#011Loss: 2.299582\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [3840/50000 (8%)]#011Loss: 2.282914\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [5120/50000 (10%)]#011Loss: 2.293464\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [6400/50000 (13%)]#011Loss: 2.340408\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [7680/50000 (15%)]#011Loss: 2.253933\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [8960/50000 (18%)]#011Loss: 2.316000\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [10240/50000 (20%)]#011Loss: 2.273932\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [11520/50000 (23%)]#011Loss: 2.302497\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [12800/50000 (26%)]#011Loss: 2.316547\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [14080/50000 (28%)]#011Loss: 2.240951\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [15360/50000 (31%)]#011Loss: 2.176044\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [16640/50000 (33%)]#011Loss: 2.252481\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [17920/50000 (36%)]#011Loss: 2.196985\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [19200/50000 (38%)]#011Loss: 2.236140\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [20480/50000 (41%)]#011Loss: 2.306554\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [21760/50000 (43%)]#011Loss: 2.279115\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [23040/50000 (46%)]#011Loss: 2.232770\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [24320/50000 (49%)]#011Loss: 2.311880\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [25600/50000 (51%)]#011Loss: 2.176647\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [26880/50000 (54%)]#011Loss: 2.231023\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [28160/50000 (56%)]#011Loss: 2.305314\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [29440/50000 (59%)]#011Loss: 2.253231\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [30720/50000 (61%)]#011Loss: 2.222102\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [32000/50000 (64%)]#011Loss: 2.297698\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [33280/50000 (66%)]#011Loss: 2.268919\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [34560/50000 (69%)]#011Loss: 2.279849\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [35840/50000 (72%)]#011Loss: 2.256212\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [37120/50000 (74%)]#011Loss: 2.302216\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [38400/50000 (77%)]#011Loss: 2.258318\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [39680/50000 (79%)]#011Loss: 2.251677\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [40960/50000 (82%)]#011Loss: 2.218727\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [42240/50000 (84%)]#011Loss: 2.243580\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [43520/50000 (87%)]#011Loss: 2.209085\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [44800/50000 (90%)]#011Loss: 2.223037\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [46080/50000 (92%)]#011Loss: 2.201958\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [47360/50000 (95%)]#011Loss: 2.338341\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [48640/50000 (97%)]#011Loss: 2.253317\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [31200/50000 (100%)]#011Loss: 2.285152\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.1408, Accuracy: 123/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [0/50000 (0%)]#011Loss: 2.180658\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [1280/50000 (3%)]#011Loss: 2.239466\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [2560/50000 (5%)]#011Loss: 2.214306\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [3840/50000 (8%)]#011Loss: 2.271218\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [5120/50000 (10%)]#011Loss: 2.208391\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [6400/50000 (13%)]#011Loss: 2.203347\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [7680/50000 (15%)]#011Loss: 2.280392\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [8960/50000 (18%)]#011Loss: 2.252720\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [10240/50000 (20%)]#011Loss: 2.169814\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [11520/50000 (23%)]#011Loss: 2.241107\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [12800/50000 (26%)]#011Loss: 2.210544\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [14080/50000 (28%)]#011Loss: 2.237935\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [15360/50000 (31%)]#011Loss: 2.275603\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [16640/50000 (33%)]#011Loss: 2.256155\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [17920/50000 (36%)]#011Loss: 2.203958\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [19200/50000 (38%)]#011Loss: 2.356773\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [20480/50000 (41%)]#011Loss: 2.258839\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [21760/50000 (43%)]#011Loss: 2.253198\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [23040/50000 (46%)]#011Loss: 2.252137\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [24320/50000 (49%)]#011Loss: 2.342676\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [25600/50000 (51%)]#011Loss: 2.190227\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [26880/50000 (54%)]#011Loss: 2.222614\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [28160/50000 (56%)]#011Loss: 2.314969\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [29440/50000 (59%)]#011Loss: 2.306874\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [30720/50000 (61%)]#011Loss: 2.164877\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [32000/50000 (64%)]#011Loss: 2.203938\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [33280/50000 (66%)]#011Loss: 2.258037\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [34560/50000 (69%)]#011Loss: 2.177155\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [35840/50000 (72%)]#011Loss: 2.232068\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [37120/50000 (74%)]#011Loss: 2.339163\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [38400/50000 (77%)]#011Loss: 2.288759\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [39680/50000 (79%)]#011Loss: 2.336425\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [40960/50000 (82%)]#011Loss: 2.294929\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [42240/50000 (84%)]#011Loss: 2.171074\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [43520/50000 (87%)]#011Loss: 2.280807\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [44800/50000 (90%)]#011Loss: 2.256211\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [46080/50000 (92%)]#011Loss: 2.143069\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [47360/50000 (95%)]#011Loss: 2.302522\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [48640/50000 (97%)]#011Loss: 2.202839\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [31200/50000 (100%)]#011Loss: 2.228567\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.1404, Accuracy: 133/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [0/50000 (0%)]#011Loss: 2.166882\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [1280/50000 (3%)]#011Loss: 2.216733\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [2560/50000 (5%)]#011Loss: 2.228989\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [3840/50000 (8%)]#011Loss: 2.221295\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [5120/50000 (10%)]#011Loss: 2.280756\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [6400/50000 (13%)]#011Loss: 2.241046\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [7680/50000 (15%)]#011Loss: 2.227692\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [8960/50000 (18%)]#011Loss: 2.227309\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [10240/50000 (20%)]#011Loss: 2.208980\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [11520/50000 (23%)]#011Loss: 2.252295\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [12800/50000 (26%)]#011Loss: 2.271822\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [14080/50000 (28%)]#011Loss: 2.236505\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [15360/50000 (31%)]#011Loss: 2.211421\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [16640/50000 (33%)]#011Loss: 2.210621\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [17920/50000 (36%)]#011Loss: 2.232284\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [19200/50000 (38%)]#011Loss: 2.260023\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [20480/50000 (41%)]#011Loss: 2.291411\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [21760/50000 (43%)]#011Loss: 2.293269\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [23040/50000 (46%)]#011Loss: 2.154439\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [24320/50000 (49%)]#011Loss: 2.397784\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [25600/50000 (51%)]#011Loss: 2.282764\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [26880/50000 (54%)]#011Loss: 2.218129\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [28160/50000 (56%)]#011Loss: 2.305541\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [29440/50000 (59%)]#011Loss: 2.267273\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [30720/50000 (61%)]#011Loss: 2.251478\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [32000/50000 (64%)]#011Loss: 2.245330\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [33280/50000 (66%)]#011Loss: 2.194605\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [34560/50000 (69%)]#011Loss: 2.309441\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [35840/50000 (72%)]#011Loss: 2.253311\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [37120/50000 (74%)]#011Loss: 2.238734\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [38400/50000 (77%)]#011Loss: 2.253769\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [39680/50000 (79%)]#011Loss: 2.294432\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [40960/50000 (82%)]#011Loss: 2.305452\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [42240/50000 (84%)]#011Loss: 2.224184\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [43520/50000 (87%)]#011Loss: 2.294552\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [44800/50000 (90%)]#011Loss: 2.228491\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [46080/50000 (92%)]#011Loss: 2.221990\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [47360/50000 (95%)]#011Loss: 2.263775\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [48640/50000 (97%)]#011Loss: 2.305854\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [31200/50000 (100%)]#011Loss: 2.301632\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.1400, Accuracy: 140/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [0/50000 (0%)]#011Loss: 2.234796\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [1280/50000 (3%)]#011Loss: 2.234118\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [2560/50000 (5%)]#011Loss: 2.231661\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [3840/50000 (8%)]#011Loss: 2.183989\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [5120/50000 (10%)]#011Loss: 2.294673\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [6400/50000 (13%)]#011Loss: 2.250122\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [7680/50000 (15%)]#011Loss: 2.213522\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [8960/50000 (18%)]#011Loss: 2.155436\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [10240/50000 (20%)]#011Loss: 2.291801\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [11520/50000 (23%)]#011Loss: 2.304262\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [12800/50000 (26%)]#011Loss: 2.182616\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [14080/50000 (28%)]#011Loss: 2.253745\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [15360/50000 (31%)]#011Loss: 2.137543\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [16640/50000 (33%)]#011Loss: 2.195278\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [17920/50000 (36%)]#011Loss: 2.181152\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [19200/50000 (38%)]#011Loss: 2.334971\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [20480/50000 (41%)]#011Loss: 2.292357\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [21760/50000 (43%)]#011Loss: 2.251850\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [23040/50000 (46%)]#011Loss: 2.228322\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [24320/50000 (49%)]#011Loss: 2.434546\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [25600/50000 (51%)]#011Loss: 2.331168\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [26880/50000 (54%)]#011Loss: 2.193599\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [28160/50000 (56%)]#011Loss: 2.262741\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [29440/50000 (59%)]#011Loss: 2.295414\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [30720/50000 (61%)]#011Loss: 2.147636\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [32000/50000 (64%)]#011Loss: 2.206307\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [33280/50000 (66%)]#011Loss: 2.254293\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [34560/50000 (69%)]#011Loss: 2.162487\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [35840/50000 (72%)]#011Loss: 2.254518\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [37120/50000 (74%)]#011Loss: 2.245801\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [38400/50000 (77%)]#011Loss: 2.221331\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [39680/50000 (79%)]#011Loss: 2.216061\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [40960/50000 (82%)]#011Loss: 2.199311\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [42240/50000 (84%)]#011Loss: 2.153436\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [43520/50000 (87%)]#011Loss: 2.161250\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [44800/50000 (90%)]#011Loss: 2.189855\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [46080/50000 (92%)]#011Loss: 2.169424\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [47360/50000 (95%)]#011Loss: 2.232094\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [48640/50000 (97%)]#011Loss: 2.286355\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [31200/50000 (100%)]#011Loss: 2.203410\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.1398, Accuracy: 140/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [0/50000 (0%)]#011Loss: 2.193847\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [1280/50000 (3%)]#011Loss: 2.331908\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [2560/50000 (5%)]#011Loss: 2.154891\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [3840/50000 (8%)]#011Loss: 2.231539\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [5120/50000 (10%)]#011Loss: 2.243145\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [6400/50000 (13%)]#011Loss: 2.241864\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [7680/50000 (15%)]#011Loss: 2.213539\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [8960/50000 (18%)]#011Loss: 2.234748\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [10240/50000 (20%)]#011Loss: 2.197044\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [11520/50000 (23%)]#011Loss: 2.268613\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [12800/50000 (26%)]#011Loss: 2.234980\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [14080/50000 (28%)]#011Loss: 2.240032\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [15360/50000 (31%)]#011Loss: 2.145921\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [16640/50000 (33%)]#011Loss: 2.142428\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [17920/50000 (36%)]#011Loss: 2.152382\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [19200/50000 (38%)]#011Loss: 2.242361\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [20480/50000 (41%)]#011Loss: 2.310776\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [21760/50000 (43%)]#011Loss: 2.252908\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [23040/50000 (46%)]#011Loss: 2.139306\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [24320/50000 (49%)]#011Loss: 2.315183\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [25600/50000 (51%)]#011Loss: 2.296441\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [26880/50000 (54%)]#011Loss: 2.247467\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [28160/50000 (56%)]#011Loss: 2.280847\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [29440/50000 (59%)]#011Loss: 2.292475\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [30720/50000 (61%)]#011Loss: 2.087845\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [32000/50000 (64%)]#011Loss: 2.257055\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [33280/50000 (66%)]#011Loss: 2.232861\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [34560/50000 (69%)]#011Loss: 2.236391\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [35840/50000 (72%)]#011Loss: 2.332897\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [37120/50000 (74%)]#011Loss: 2.176898\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [38400/50000 (77%)]#011Loss: 2.228766\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [39680/50000 (79%)]#011Loss: 2.269968\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [40960/50000 (82%)]#011Loss: 2.272421\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [42240/50000 (84%)]#011Loss: 2.293013\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [43520/50000 (87%)]#011Loss: 2.312827\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [44800/50000 (90%)]#011Loss: 2.318191\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [46080/50000 (92%)]#011Loss: 2.086203\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [47360/50000 (95%)]#011Loss: 2.304931\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [48640/50000 (97%)]#011Loss: 2.286440\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [31200/50000 (100%)]#011Loss: 2.181667\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.1396, Accuracy: 141/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [0/50000 (0%)]#011Loss: 2.154511\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [1280/50000 (3%)]#011Loss: 2.338906\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [2560/50000 (5%)]#011Loss: 2.221264\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [3840/50000 (8%)]#011Loss: 2.175234\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [5120/50000 (10%)]#011Loss: 2.236941\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [6400/50000 (13%)]#011Loss: 2.130169\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [7680/50000 (15%)]#011Loss: 2.232104\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [8960/50000 (18%)]#011Loss: 2.174266\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [10240/50000 (20%)]#011Loss: 2.195553\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [11520/50000 (23%)]#011Loss: 2.204371\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [12800/50000 (26%)]#011Loss: 2.222358\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [14080/50000 (28%)]#011Loss: 2.309969\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [15360/50000 (31%)]#011Loss: 2.240619\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [16640/50000 (33%)]#011Loss: 2.302690\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [17920/50000 (36%)]#011Loss: 2.256066\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [19200/50000 (38%)]#011Loss: 2.320062\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [20480/50000 (41%)]#011Loss: 2.296285\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [21760/50000 (43%)]#011Loss: 2.199808\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [23040/50000 (46%)]#011Loss: 2.135134\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [24320/50000 (49%)]#011Loss: 2.408050\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [25600/50000 (51%)]#011Loss: 2.263453\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [26880/50000 (54%)]#011Loss: 2.185503\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [28160/50000 (56%)]#011Loss: 2.283672\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [29440/50000 (59%)]#011Loss: 2.250131\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [30720/50000 (61%)]#011Loss: 2.163064\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [32000/50000 (64%)]#011Loss: 2.237819\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [33280/50000 (66%)]#011Loss: 2.274211\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [34560/50000 (69%)]#011Loss: 2.188589\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [35840/50000 (72%)]#011Loss: 2.239346\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [37120/50000 (74%)]#011Loss: 2.147304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [38400/50000 (77%)]#011Loss: 2.264705\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [39680/50000 (79%)]#011Loss: 2.142779\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [40960/50000 (82%)]#011Loss: 2.209477\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [42240/50000 (84%)]#011Loss: 2.095347\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [43520/50000 (87%)]#011Loss: 2.242170\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [44800/50000 (90%)]#011Loss: 2.195963\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [46080/50000 (92%)]#011Loss: 2.235111\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [47360/50000 (95%)]#011Loss: 2.268913\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [48640/50000 (97%)]#011Loss: 2.278119\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [31200/50000 (100%)]#011Loss: 2.258615\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.1395, Accuracy: 142/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [0/50000 (0%)]#011Loss: 2.195409\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [1280/50000 (3%)]#011Loss: 2.312041\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [2560/50000 (5%)]#011Loss: 2.141621\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [3840/50000 (8%)]#011Loss: 2.161500\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [5120/50000 (10%)]#011Loss: 2.216173\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [6400/50000 (13%)]#011Loss: 2.153771\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [7680/50000 (15%)]#011Loss: 2.208954\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [8960/50000 (18%)]#011Loss: 2.232007\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [10240/50000 (20%)]#011Loss: 2.302767\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [11520/50000 (23%)]#011Loss: 2.208785\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [12800/50000 (26%)]#011Loss: 2.165463\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [14080/50000 (28%)]#011Loss: 2.166581\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [15360/50000 (31%)]#011Loss: 2.144994\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [16640/50000 (33%)]#011Loss: 2.215017\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [17920/50000 (36%)]#011Loss: 2.169463\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [19200/50000 (38%)]#011Loss: 2.306814\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [20480/50000 (41%)]#011Loss: 2.300503\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [21760/50000 (43%)]#011Loss: 2.222842\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [23040/50000 (46%)]#011Loss: 2.290071\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [24320/50000 (49%)]#011Loss: 2.354118\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [25600/50000 (51%)]#011Loss: 2.137700\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [26880/50000 (54%)]#011Loss: 2.117194\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [28160/50000 (56%)]#011Loss: 2.310966\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [29440/50000 (59%)]#011Loss: 2.315650\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [30720/50000 (61%)]#011Loss: 2.215609\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [32000/50000 (64%)]#011Loss: 2.216521\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [33280/50000 (66%)]#011Loss: 2.220436\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [34560/50000 (69%)]#011Loss: 2.163029\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [35840/50000 (72%)]#011Loss: 2.312927\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [37120/50000 (74%)]#011Loss: 2.299753\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [38400/50000 (77%)]#011Loss: 2.249761\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [39680/50000 (79%)]#011Loss: 2.232802\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [40960/50000 (82%)]#011Loss: 2.309873\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [42240/50000 (84%)]#011Loss: 2.179189\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [43520/50000 (87%)]#011Loss: 2.251521\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [44800/50000 (90%)]#011Loss: 2.209254\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [46080/50000 (92%)]#011Loss: 2.228574\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [47360/50000 (95%)]#011Loss: 2.232257\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [48640/50000 (97%)]#011Loss: 2.265883\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [31200/50000 (100%)]#011Loss: 2.303546\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.1394, Accuracy: 143/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [0/50000 (0%)]#011Loss: 2.215455\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [1280/50000 (3%)]#011Loss: 2.249074\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [2560/50000 (5%)]#011Loss: 2.168457\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [3840/50000 (8%)]#011Loss: 2.157773\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [5120/50000 (10%)]#011Loss: 2.320039\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [6400/50000 (13%)]#011Loss: 2.261491\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [7680/50000 (15%)]#011Loss: 2.232757\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [8960/50000 (18%)]#011Loss: 2.273911\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [10240/50000 (20%)]#011Loss: 2.254205\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [11520/50000 (23%)]#011Loss: 2.295998\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [12800/50000 (26%)]#011Loss: 2.093285\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [14080/50000 (28%)]#011Loss: 2.220779\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [15360/50000 (31%)]#011Loss: 2.238004\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [16640/50000 (33%)]#011Loss: 2.291416\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [17920/50000 (36%)]#011Loss: 2.184052\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [19200/50000 (38%)]#011Loss: 2.310658\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [20480/50000 (41%)]#011Loss: 2.251192\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [21760/50000 (43%)]#011Loss: 2.306671\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [23040/50000 (46%)]#011Loss: 2.185603\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [24320/50000 (49%)]#011Loss: 2.351686\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [25600/50000 (51%)]#011Loss: 2.140919\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [26880/50000 (54%)]#011Loss: 2.243554\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [28160/50000 (56%)]#011Loss: 2.312881\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [29440/50000 (59%)]#011Loss: 2.258786\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [30720/50000 (61%)]#011Loss: 2.153040\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [32000/50000 (64%)]#011Loss: 2.172589\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [33280/50000 (66%)]#011Loss: 2.240462\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [34560/50000 (69%)]#011Loss: 2.195635\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [35840/50000 (72%)]#011Loss: 2.231318\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [37120/50000 (74%)]#011Loss: 2.143918\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [38400/50000 (77%)]#011Loss: 2.289389\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [39680/50000 (79%)]#011Loss: 2.183534\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [40960/50000 (82%)]#011Loss: 2.348860\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [42240/50000 (84%)]#011Loss: 2.134390\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [43520/50000 (87%)]#011Loss: 2.167381\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [44800/50000 (90%)]#011Loss: 2.146505\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [46080/50000 (92%)]#011Loss: 2.169380\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [47360/50000 (95%)]#011Loss: 2.351660\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [48640/50000 (97%)]#011Loss: 2.235581\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [31200/50000 (100%)]#011Loss: 2.329893\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.1393, Accuracy: 144/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [0/50000 (0%)]#011Loss: 2.169880\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [1280/50000 (3%)]#011Loss: 2.133014\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [2560/50000 (5%)]#011Loss: 2.189390\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [3840/50000 (8%)]#011Loss: 2.284050\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [5120/50000 (10%)]#011Loss: 2.288895\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [6400/50000 (13%)]#011Loss: 2.225338\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [7680/50000 (15%)]#011Loss: 2.268267\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [8960/50000 (18%)]#011Loss: 2.247833\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [10240/50000 (20%)]#011Loss: 2.291332\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [11520/50000 (23%)]#011Loss: 2.183691\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [12800/50000 (26%)]#011Loss: 2.305416\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [14080/50000 (28%)]#011Loss: 2.197367\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [15360/50000 (31%)]#011Loss: 2.218477\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [16640/50000 (33%)]#011Loss: 2.226493\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [17920/50000 (36%)]#011Loss: 2.266440\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [19200/50000 (38%)]#011Loss: 2.338971\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [20480/50000 (41%)]#011Loss: 2.277328\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [21760/50000 (43%)]#011Loss: 2.214591\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [23040/50000 (46%)]#011Loss: 2.160580\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [24320/50000 (49%)]#011Loss: 2.305566\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [25600/50000 (51%)]#011Loss: 2.265418\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [26880/50000 (54%)]#011Loss: 2.249975\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [28160/50000 (56%)]#011Loss: 2.262303\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [29440/50000 (59%)]#011Loss: 2.222227\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [30720/50000 (61%)]#011Loss: 2.165587\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [32000/50000 (64%)]#011Loss: 2.294874\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [33280/50000 (66%)]#011Loss: 2.260352\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [34560/50000 (69%)]#011Loss: 2.231523\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [35840/50000 (72%)]#011Loss: 2.250310\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [37120/50000 (74%)]#011Loss: 2.202101\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [38400/50000 (77%)]#011Loss: 2.225761\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [39680/50000 (79%)]#011Loss: 2.224343\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [40960/50000 (82%)]#011Loss: 2.246942\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [42240/50000 (84%)]#011Loss: 2.281842\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [43520/50000 (87%)]#011Loss: 2.360580\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [44800/50000 (90%)]#011Loss: 2.247473\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [46080/50000 (92%)]#011Loss: 2.248076\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [47360/50000 (95%)]#011Loss: 2.306188\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [48640/50000 (97%)]#011Loss: 2.181679\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [31200/50000 (100%)]#011Loss: 2.199979\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.1393, Accuracy: 144/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [0/50000 (0%)]#011Loss: 2.273840\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [1280/50000 (3%)]#011Loss: 2.206487\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [2560/50000 (5%)]#011Loss: 2.206237\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [3840/50000 (8%)]#011Loss: 2.204227\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [5120/50000 (10%)]#011Loss: 2.303395\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [6400/50000 (13%)]#011Loss: 2.159091\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [7680/50000 (15%)]#011Loss: 2.302570\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [8960/50000 (18%)]#011Loss: 2.161495\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [10240/50000 (20%)]#011Loss: 2.243448\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [11520/50000 (23%)]#011Loss: 2.287833\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [12800/50000 (26%)]#011Loss: 2.270424\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [14080/50000 (28%)]#011Loss: 2.244644\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [15360/50000 (31%)]#011Loss: 2.223618\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [16640/50000 (33%)]#011Loss: 2.189867\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [17920/50000 (36%)]#011Loss: 2.233558\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [19200/50000 (38%)]#011Loss: 2.347018\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [20480/50000 (41%)]#011Loss: 2.265677\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [21760/50000 (43%)]#011Loss: 2.214785\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [23040/50000 (46%)]#011Loss: 2.323562\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [24320/50000 (49%)]#011Loss: 2.336868\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [25600/50000 (51%)]#011Loss: 2.110087\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [26880/50000 (54%)]#011Loss: 2.256911\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [28160/50000 (56%)]#011Loss: 2.274712\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [29440/50000 (59%)]#011Loss: 2.210686\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [30720/50000 (61%)]#011Loss: 2.143495\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [32000/50000 (64%)]#011Loss: 2.243023\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [33280/50000 (66%)]#011Loss: 2.223819\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [34560/50000 (69%)]#011Loss: 2.257129\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [35840/50000 (72%)]#011Loss: 2.216287\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [37120/50000 (74%)]#011Loss: 2.151129\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [38400/50000 (77%)]#011Loss: 2.213998\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [39680/50000 (79%)]#011Loss: 2.229906\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [40960/50000 (82%)]#011Loss: 2.204322\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [42240/50000 (84%)]#011Loss: 2.217005\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [43520/50000 (87%)]#011Loss: 2.219643\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [44800/50000 (90%)]#011Loss: 2.222301\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [46080/50000 (92%)]#011Loss: 2.069781\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [47360/50000 (95%)]#011Loss: 2.327077\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [48640/50000 (97%)]#011Loss: 2.277628\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [31200/50000 (100%)]#011Loss: 2.250014\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.1392, Accuracy: 143/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [0/50000 (0%)]#011Loss: 2.186654\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [1280/50000 (3%)]#011Loss: 2.121469\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [2560/50000 (5%)]#011Loss: 2.136406\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [3840/50000 (8%)]#011Loss: 2.139863\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [5120/50000 (10%)]#011Loss: 2.329215\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [6400/50000 (13%)]#011Loss: 2.159600\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [7680/50000 (15%)]#011Loss: 2.198038\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [8960/50000 (18%)]#011Loss: 2.231637\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [10240/50000 (20%)]#011Loss: 2.218770\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [11520/50000 (23%)]#011Loss: 2.262803\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [12800/50000 (26%)]#011Loss: 2.221122\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [14080/50000 (28%)]#011Loss: 2.168643\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [15360/50000 (31%)]#011Loss: 2.270213\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [16640/50000 (33%)]#011Loss: 2.222003\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [17920/50000 (36%)]#011Loss: 2.193662\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [19200/50000 (38%)]#011Loss: 2.287271\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [20480/50000 (41%)]#011Loss: 2.271717\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [21760/50000 (43%)]#011Loss: 2.283177\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [23040/50000 (46%)]#011Loss: 2.161792\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [24320/50000 (49%)]#011Loss: 2.441847\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [25600/50000 (51%)]#011Loss: 2.254296\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [26880/50000 (54%)]#011Loss: 2.274927\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [28160/50000 (56%)]#011Loss: 2.282788\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [29440/50000 (59%)]#011Loss: 2.218335\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [30720/50000 (61%)]#011Loss: 2.160940\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [32000/50000 (64%)]#011Loss: 2.153774\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [33280/50000 (66%)]#011Loss: 2.197640\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [34560/50000 (69%)]#011Loss: 2.181062\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [35840/50000 (72%)]#011Loss: 2.254096\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [37120/50000 (74%)]#011Loss: 2.232855\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [38400/50000 (77%)]#011Loss: 2.270106\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [39680/50000 (79%)]#011Loss: 2.257751\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [40960/50000 (82%)]#011Loss: 2.126205\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [42240/50000 (84%)]#011Loss: 2.065933\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [43520/50000 (87%)]#011Loss: 2.333725\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [44800/50000 (90%)]#011Loss: 2.190983\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [46080/50000 (92%)]#011Loss: 2.141181\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [47360/50000 (95%)]#011Loss: 2.295414\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [48640/50000 (97%)]#011Loss: 2.183119\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [31200/50000 (100%)]#011Loss: 2.218012\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.1392, Accuracy: 142/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [0/50000 (0%)]#011Loss: 2.158457\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [1280/50000 (3%)]#011Loss: 2.298412\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [2560/50000 (5%)]#011Loss: 2.271797\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [3840/50000 (8%)]#011Loss: 2.192883\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [5120/50000 (10%)]#011Loss: 2.291760\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [6400/50000 (13%)]#011Loss: 2.233504\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [7680/50000 (15%)]#011Loss: 2.199457\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [8960/50000 (18%)]#011Loss: 2.199670\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [10240/50000 (20%)]#011Loss: 2.320055\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [11520/50000 (23%)]#011Loss: 2.305472\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [12800/50000 (26%)]#011Loss: 2.268662\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [14080/50000 (28%)]#011Loss: 2.192783\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [15360/50000 (31%)]#011Loss: 2.187017\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [16640/50000 (33%)]#011Loss: 2.186920\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [17920/50000 (36%)]#011Loss: 2.168945\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [19200/50000 (38%)]#011Loss: 2.262551\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [20480/50000 (41%)]#011Loss: 2.334075\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [21760/50000 (43%)]#011Loss: 2.293511\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [23040/50000 (46%)]#011Loss: 2.186563\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [24320/50000 (49%)]#011Loss: 2.404175\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [25600/50000 (51%)]#011Loss: 2.210522\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [26880/50000 (54%)]#011Loss: 2.212900\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [28160/50000 (56%)]#011Loss: 2.264296\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [29440/50000 (59%)]#011Loss: 2.313088\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [30720/50000 (61%)]#011Loss: 2.145327\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [32000/50000 (64%)]#011Loss: 2.206469\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [33280/50000 (66%)]#011Loss: 2.189684\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [34560/50000 (69%)]#011Loss: 2.203367\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [35840/50000 (72%)]#011Loss: 2.212047\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [37120/50000 (74%)]#011Loss: 2.227732\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [38400/50000 (77%)]#011Loss: 2.316213\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [39680/50000 (79%)]#011Loss: 2.205582\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [40960/50000 (82%)]#011Loss: 2.224788\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [42240/50000 (84%)]#011Loss: 2.182765\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [43520/50000 (87%)]#011Loss: 2.321457\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [44800/50000 (90%)]#011Loss: 2.124936\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [46080/50000 (92%)]#011Loss: 2.180647\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [47360/50000 (95%)]#011Loss: 2.252532\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [48640/50000 (97%)]#011Loss: 2.302097\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [31200/50000 (100%)]#011Loss: 2.231955\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.1392, Accuracy: 142/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [0/50000 (0%)]#011Loss: 2.040294\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [1280/50000 (3%)]#011Loss: 2.161365\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [2560/50000 (5%)]#011Loss: 2.294687\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [3840/50000 (8%)]#011Loss: 2.258157\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [5120/50000 (10%)]#011Loss: 2.324526\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [6400/50000 (13%)]#011Loss: 2.200540\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [7680/50000 (15%)]#011Loss: 2.204561\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [8960/50000 (18%)]#011Loss: 2.149809\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [10240/50000 (20%)]#011Loss: 2.188729\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [11520/50000 (23%)]#011Loss: 2.251089\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [12800/50000 (26%)]#011Loss: 2.172061\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [14080/50000 (28%)]#011Loss: 2.164785\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [15360/50000 (31%)]#011Loss: 2.368081\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [16640/50000 (33%)]#011Loss: 2.207232\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [17920/50000 (36%)]#011Loss: 2.160582\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [19200/50000 (38%)]#011Loss: 2.299978\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [20480/50000 (41%)]#011Loss: 2.255361\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [21760/50000 (43%)]#011Loss: 2.308347\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [23040/50000 (46%)]#011Loss: 2.029094\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [24320/50000 (49%)]#011Loss: 2.359069\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [25600/50000 (51%)]#011Loss: 2.317401\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [26880/50000 (54%)]#011Loss: 2.161686\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [28160/50000 (56%)]#011Loss: 2.297063\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [29440/50000 (59%)]#011Loss: 2.203236\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [30720/50000 (61%)]#011Loss: 2.200333\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [32000/50000 (64%)]#011Loss: 2.265713\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [33280/50000 (66%)]#011Loss: 2.113127\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [34560/50000 (69%)]#011Loss: 2.214520\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [35840/50000 (72%)]#011Loss: 2.321433\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [37120/50000 (74%)]#011Loss: 2.161107\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [38400/50000 (77%)]#011Loss: 2.314206\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [39680/50000 (79%)]#011Loss: 2.290479\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [40960/50000 (82%)]#011Loss: 2.100609\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [42240/50000 (84%)]#011Loss: 2.203935\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [43520/50000 (87%)]#011Loss: 2.179245\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [44800/50000 (90%)]#011Loss: 2.187859\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [46080/50000 (92%)]#011Loss: 2.072765\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [47360/50000 (95%)]#011Loss: 2.307246\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [48640/50000 (97%)]#011Loss: 2.270886\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [31200/50000 (100%)]#011Loss: 2.298109\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.1392, Accuracy: 142/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [0/50000 (0%)]#011Loss: 2.206341\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [1280/50000 (3%)]#011Loss: 2.234771\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [2560/50000 (5%)]#011Loss: 2.262235\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [3840/50000 (8%)]#011Loss: 2.136456\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [5120/50000 (10%)]#011Loss: 2.315814\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [6400/50000 (13%)]#011Loss: 2.261226\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [7680/50000 (15%)]#011Loss: 2.278450\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [8960/50000 (18%)]#011Loss: 2.198931\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [10240/50000 (20%)]#011Loss: 2.180342\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [11520/50000 (23%)]#011Loss: 2.271942\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [12800/50000 (26%)]#011Loss: 2.230167\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [14080/50000 (28%)]#011Loss: 2.229541\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [15360/50000 (31%)]#011Loss: 2.101788\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [16640/50000 (33%)]#011Loss: 2.152122\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [17920/50000 (36%)]#011Loss: 2.177576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [19200/50000 (38%)]#011Loss: 2.257589\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [20480/50000 (41%)]#011Loss: 2.274321\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [21760/50000 (43%)]#011Loss: 2.283192\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [23040/50000 (46%)]#011Loss: 2.115815\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [24320/50000 (49%)]#011Loss: 2.330133\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [25600/50000 (51%)]#011Loss: 2.235975\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [26880/50000 (54%)]#011Loss: 2.153818\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [28160/50000 (56%)]#011Loss: 2.274471\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [29440/50000 (59%)]#011Loss: 2.340159\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [30720/50000 (61%)]#011Loss: 2.175798\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [32000/50000 (64%)]#011Loss: 2.214424\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [33280/50000 (66%)]#011Loss: 2.269411\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [34560/50000 (69%)]#011Loss: 2.253158\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [35840/50000 (72%)]#011Loss: 2.234381\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [37120/50000 (74%)]#011Loss: 2.284543\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [38400/50000 (77%)]#011Loss: 2.233623\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [39680/50000 (79%)]#011Loss: 2.216587\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [40960/50000 (82%)]#011Loss: 2.269968\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [42240/50000 (84%)]#011Loss: 2.050605\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [43520/50000 (87%)]#011Loss: 2.295295\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [44800/50000 (90%)]#011Loss: 2.174204\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [46080/50000 (92%)]#011Loss: 2.083892\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [47360/50000 (95%)]#011Loss: 2.231570\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [48640/50000 (97%)]#011Loss: 2.196512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [31200/50000 (100%)]#011Loss: 2.160117\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.1392, Accuracy: 142/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [0/50000 (0%)]#011Loss: 2.105133\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [1280/50000 (3%)]#011Loss: 2.191561\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [2560/50000 (5%)]#011Loss: 2.252204\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [3840/50000 (8%)]#011Loss: 2.197934\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [5120/50000 (10%)]#011Loss: 2.319840\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [6400/50000 (13%)]#011Loss: 2.278493\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [7680/50000 (15%)]#011Loss: 2.198585\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [8960/50000 (18%)]#011Loss: 2.198642\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [10240/50000 (20%)]#011Loss: 2.251057\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [11520/50000 (23%)]#011Loss: 2.312696\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [12800/50000 (26%)]#011Loss: 2.099835\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [14080/50000 (28%)]#011Loss: 2.220720\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [15360/50000 (31%)]#011Loss: 2.199662\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [16640/50000 (33%)]#011Loss: 2.171465\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [17920/50000 (36%)]#011Loss: 2.215924\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [19200/50000 (38%)]#011Loss: 2.310562\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [20480/50000 (41%)]#011Loss: 2.308152\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [21760/50000 (43%)]#011Loss: 2.182757\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [23040/50000 (46%)]#011Loss: 2.189666\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [24320/50000 (49%)]#011Loss: 2.344018\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [25600/50000 (51%)]#011Loss: 2.239774\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [26880/50000 (54%)]#011Loss: 2.260185\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [28160/50000 (56%)]#011Loss: 2.268053\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [29440/50000 (59%)]#011Loss: 2.206801\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [30720/50000 (61%)]#011Loss: 2.196711\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [32000/50000 (64%)]#011Loss: 2.145728\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [33280/50000 (66%)]#011Loss: 2.292578\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [34560/50000 (69%)]#011Loss: 2.216094\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [35840/50000 (72%)]#011Loss: 2.130334\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [37120/50000 (74%)]#011Loss: 2.302748\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [38400/50000 (77%)]#011Loss: 2.288687\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [39680/50000 (79%)]#011Loss: 2.232713\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [40960/50000 (82%)]#011Loss: 2.191216\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [42240/50000 (84%)]#011Loss: 2.129806\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [43520/50000 (87%)]#011Loss: 2.256109\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [44800/50000 (90%)]#011Loss: 2.258450\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [46080/50000 (92%)]#011Loss: 2.131635\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [47360/50000 (95%)]#011Loss: 2.272162\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [48640/50000 (97%)]#011Loss: 2.167691\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [31200/50000 (100%)]#011Loss: 2.299355\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Training is finished\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:Training is finished\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Training is finished\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:Training is finished\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:Training is finished\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Training is finished\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Training is finished\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Training is finished\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:Training is finished\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:Training is finished\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:Training is finished\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Training is finished\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Training is finished\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:Training is finished\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:Training is finished\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.1392, Accuracy: 142/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Training is finished\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Saving the model.\u001b[0m\n",
      "\u001b[35m2021-07-09 08:57:26,962 sagemaker-training-toolkit INFO     Orted process exited\u001b[0m\n",
      "\u001b[34mWarning: Permanently added 'algo-2,10.0.202.80' (ECDSA) to the list of known hosts.#015\n",
      "\u001b[0m\n",
      "\u001b[34m2021-07-09 08:57:26,933 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-07-09 08:58:11 Uploading - Uploading generated training model\n",
      "2021-07-09 08:58:11 Completed - Training job completed\n",
      "\u001b[35m2021-07-09 08:57:56,970 sagemaker-training-toolkit INFO     MPI process finished.\u001b[0m\n",
      "\u001b[35m2021-07-09 08:57:56,971 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 800\n",
      "Billable seconds: 800\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "job_name ='cifar10-ddp'\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"train_ddp.py\",    \n",
    "    source_dir='source',    \n",
    "    base_job_name = job_name,\n",
    "    role=role,\n",
    "    framework_version=\"1.8.1\",\n",
    "    py_version=\"py36\",\n",
    "    # For training with multinode distributed training, set this count. Example: 2\n",
    "    instance_count= instance_count,\n",
    "    # For training with p3dn instance use - ml.p3dn.24xlarge, with p4dn instance use - ml.p4d.24xlarge\n",
    "    instance_type= instance_type,\n",
    "    sagemaker_session= sess,\n",
    "    # Training using SMDataParallel Distributed Training Framework\n",
    "    distribution={\"smdistributed\": {\"dataparallel\": {\"enabled\": True}}},\n",
    "    hyperparameters=hyperparameters,    \n",
    "    debugger_hook_config=False,\n",
    ")\n",
    "estimator.fit({\"training\" : inputs})\n",
    "#estimator.fit({\"training\" : \"file://../data\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ddp_artifact_path:  s3://sagemaker-us-east-1-057716757052/cifar10-ddp-2021-07-09-08-40-36-084/model.tar.gz\n",
      "Stored 'ddp_artifact_path' (str)\n"
     ]
    }
   ],
   "source": [
    "ddp_artifact_path = estimator.model_data\n",
    "print(\"ddp_artifact_path: \", ddp_artifact_path)\n",
    "\n",
    "\n",
    "%store ddp_artifact_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-09 07:44:46     230809 cifar10-ddp-2021-07-09-07-36-44-829/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "! aws s3 ls {ddp_artifact_path} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
