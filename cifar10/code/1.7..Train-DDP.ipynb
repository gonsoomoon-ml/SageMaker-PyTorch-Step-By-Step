{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 1.7] SageMaker DDP 모델 훈련\n",
    "\n",
    "### 본 워크샵의 모든 노트북은 `conda_python3` 여기에서 작업 합니다.\n",
    "\n",
    "이 노트북은 아래와 같은 작업을 합니다.\n",
    "- 준비 작업을 걸쳐서 현재의 노트북 인스턴스에서 로컬 모드로 호로보드로 모델 훈련\n",
    "- 호스트 모드에서 2개의 인스턴스로 호로보드 모델 훈련\n",
    "- 훈련된 모델 아티펙트 저장\n",
    "\n",
    "## 참고:\n",
    "- [파이토치 호로보드 공식 예시](https://github.com/aws/amazon-sagemaker-examples/tree/master/sagemaker-python-sdk/pytorch_horovod_mnist)\n",
    "- 세이지 메이커로 파이토치 사용 --> [Use PyTorch with the SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 기본 세팅\n",
    "사용하는 패키지는 import 시점에 다시 재로딩 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"sagemaker/DEMO-pytorch-cnn-cifar10\"\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 데이터 세트를 S3에 업로드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3 inputs:  s3://sagemaker-us-east-1-189546603447/data/cifar10\n"
     ]
    }
   ],
   "source": [
    "s3_inputs = sagemaker_session.upload_data(path=\"../data\", bucket=bucket, key_prefix=\"data/cifar10\")\n",
    "print(\"s3 inputs: \", s3_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 모델 훈련 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시스템의 이전 도커 컨테이너 삭제\n",
    "- 아래와 같은 명령어를 사용하여 저장 공간을 확보 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 도커 컨테이너 모두 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "devtmpfs        241G   80K  241G   1% /dev\n",
      "tmpfs           241G  320K  241G   1% /dev/shm\n",
      "/dev/xvda1      109G   95G   14G  88% /\n",
      "/dev/xvdf       492G  1.3G  465G   1% /home/ec2-user/SageMaker\n",
      "Total reclaimed space: 0B\n",
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "devtmpfs        241G   80K  241G   1% /dev\n",
      "tmpfs           241G  320K  241G   1% /dev/shm\n",
      "/dev/xvda1      109G   95G   14G  88% /\n",
      "/dev/xvdf       492G  1.3G  465G   1% /home/ec2-user/SageMaker\n"
     ]
    }
   ],
   "source": [
    "! df -h\n",
    "! docker container prune -f \n",
    "! df -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 도커 이미지 모두 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "devtmpfs        241G   80K  241G   1% /dev\n",
      "tmpfs           241G  320K  241G   1% /dev/shm\n",
      "/dev/xvda1      109G   95G   14G  88% /\n",
      "/dev/xvdf       492G  1.3G  465G   1% /home/ec2-user/SageMaker\n",
      "Total reclaimed space: 0B\n",
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "devtmpfs        241G   80K  241G   1% /dev\n",
      "tmpfs           241G  320K  241G   1% /dev/shm\n",
      "/dev/xvda1      109G   95G   14G  88% /\n",
      "/dev/xvdf       492G  1.3G  465G   1% /home/ec2-user/SageMaker\n"
     ]
    }
   ],
   "source": [
    "! df -h\n",
    "! docker image prune -f --all\n",
    "! df -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추가 용량 확보\n",
    "\n",
    "추가적인 용량 삭제가 필요하면 아래를 실행 하세요\n",
    "```\n",
    "rm -rf /tmp/tmp*\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 로컬모드로 훈련 \n",
    "- 현 실행 노트북 인스턴스에서 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type = \"local_gpu\"\n",
    "sess = sagemaker.local.LocalSession()\n",
    "inputs = 'file://../data'    \n",
    "instance_count = 1\n",
    "hyperparameters={\"epochs\": 2, \n",
    "                 'batch-size': 128,                     \n",
    "                 'lr': 0.01,\n",
    "                }    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 1d90cppl4s-algo-1-6o5j2 ... \n",
      "Creating 1d90cppl4s-algo-1-6o5j2 ... done\n",
      "Attaching to 1d90cppl4s-algo-1-6o5j2\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m 2022-03-06 12:12:36,808 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m 2022-03-06 12:12:36,887 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m 2022-03-06 12:12:36,890 sagemaker_pytorch_container.training INFO     Invoking SMDataParallel\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m 2022-03-06 12:12:36,890 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m 2022-03-06 12:12:37,113 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m /opt/conda/bin/python3.6 -m pip install -r requirements.txt\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m Requirement already satisfied: torch==1.8.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (1.8.1)\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m Requirement already satisfied: torchvision==0.9.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (0.9.1)\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m Collecting torchsummary==1.5.1\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m   Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from torch==1.8.1->-r requirements.txt (line 1)) (0.8)\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from torch==1.8.1->-r requirements.txt (line 1)) (3.10.0.2)\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torch==1.8.1->-r requirements.txt (line 1)) (1.19.1)\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.6/site-packages (from torchvision==0.9.1->-r requirements.txt (line 2)) (8.3.2)\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m Installing collected packages: torchsummary\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m Successfully installed torchsummary-1.5.1\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m \n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m 2022-03-06 12:12:39,811 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m 2022-03-06 12:12:39,811 sagemaker-training-toolkit INFO     Creating SSH daemon.\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m 2022-03-06 12:12:39,813 sagemaker-training-toolkit INFO     Waiting for MPI workers to establish their SSH connections\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m 2022-03-06 12:12:39,814 sagemaker-training-toolkit INFO     Network interface name: eth0\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m 2022-03-06 12:12:39,814 sagemaker-training-toolkit INFO     Host: ['algo-1-6o5j2']\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m 2022-03-06 12:12:39,815 sagemaker-training-toolkit INFO     instance type: local_gpu\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m 2022-03-06 12:12:39,892 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m \n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m Training Env:\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m \n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m {\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m     \"additional_framework_parameters\": {\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m         \"sagemaker_distributed_dataparallel_enabled\": true,\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m         \"sagemaker_instance_type\": \"local_gpu\",\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m         \"sagemaker_distributed_dataparallel_custom_mpi_options\": \"\"\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m     },\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m         \"training\": \"/opt/ml/input/data/training\"\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m     },\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m     \"current_host\": \"algo-1-6o5j2\",\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m     \"hosts\": [\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m         \"algo-1-6o5j2\"\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m     ],\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m         \"epochs\": 2,\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m         \"batch-size\": 128,\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m         \"lr\": 0.01\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m     },\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m         \"training\": {\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m         }\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m     },\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m     \"job_name\": \"cifar10-sm-local-ddp-2022-03-06-12-07-30-086\",\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m     \"master_hostname\": \"algo-1-6o5j2\",\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-189546603447/cifar10-sm-local-ddp-2022-03-06-12-07-30-086/source/sourcedir.tar.gz\",\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m     \"module_name\": \"train_ddp\",\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m     \"num_cpus\": 64,\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m     \"num_gpus\": 8,\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m         \"current_host\": \"algo-1-6o5j2\",\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m         \"hosts\": [\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m             \"algo-1-6o5j2\"\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m         ]\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m     },\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m     \"user_entry_point\": \"train_ddp.py\"\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m }\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m \n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m Environment variables:\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m \n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m SM_HOSTS=[\"algo-1-6o5j2\"]\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m SM_HPS={\"batch-size\":128,\"epochs\":2,\"lr\":0.01}\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m SM_USER_ENTRY_POINT=train_ddp.py\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m SM_FRAMEWORK_PARAMS={\"sagemaker_distributed_dataparallel_custom_mpi_options\":\"\",\"sagemaker_distributed_dataparallel_enabled\":true,\"sagemaker_instance_type\":\"local_gpu\"}\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-6o5j2\",\"hosts\":[\"algo-1-6o5j2\"]}\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m SM_INPUT_DATA_CONFIG={\"training\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m SM_CHANNELS=[\"training\"]\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m SM_CURRENT_HOST=algo-1-6o5j2\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m SM_MODULE_NAME=train_ddp\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m SM_NUM_CPUS=64\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m SM_NUM_GPUS=8\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-189546603447/cifar10-sm-local-ddp-2022-03-06-12-07-30-086/source/sourcedir.tar.gz\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_distributed_dataparallel_custom_mpi_options\":\"\",\"sagemaker_distributed_dataparallel_enabled\":true,\"sagemaker_instance_type\":\"local_gpu\"},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-6o5j2\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-6o5j2\"],\"hyperparameters\":{\"batch-size\":128,\"epochs\":2,\"lr\":0.01},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"cifar10-sm-local-ddp-2022-03-06-12-07-30-086\",\"log_level\":20,\"master_hostname\":\"algo-1-6o5j2\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-189546603447/cifar10-sm-local-ddp-2022-03-06-12-07-30-086/source/sourcedir.tar.gz\",\"module_name\":\"train_ddp\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-6o5j2\",\"hosts\":[\"algo-1-6o5j2\"]},\"user_entry_point\":\"train_ddp.py\"}\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m SM_USER_ARGS=[\"--batch-size\",\"128\",\"--epochs\",\"2\",\"--lr\",\"0.01\"]\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m SM_HP_EPOCHS=2\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m SM_HP_BATCH-SIZE=128\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m SM_HP_LR=0.01\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m \n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m \n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m mpirun --host algo-1-6o5j2 -np 8 --allow-run-as-root --tag-output --oversubscribe -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -mca btl_vader_single_copy_mechanism none -mca plm_rsh_num_concurrent 1 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x SMDATAPARALLEL_USE_SINGLENODE=1 -x FI_PROVIDER=efa -x RDMAV_FORK_SAFE=1 -x LD_PRELOAD=/opt/conda/lib/python3.6/site-packages/gethostname.cpython-36m-x86_64-linux-gnu.so smddprun /opt/conda/bin/python3.6 -m mpi4py train_ddp.py --batch-size 128 --epochs 2 --lr 0.01\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m \n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m \n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Bootstrap : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Using network Socket\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:NCCL version 2.7.8+cuda11.1\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Bootstrap : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Bootstrap : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Bootstrap : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Bootstrap : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Bootstrap : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Bootstrap : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Bootstrap : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Using network Socket\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Using network Socket\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Using network Socket\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Using network Socket\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Using network Socket\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Using network Socket\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Using network Socket\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Trees [0] -1/-1/-1->4->7|7->4->-1/-1/-1 [1] -1/-1/-1->4->7|7->4->-1/-1/-1 [2] 7/-1/-1->4->0|0->4->7/-1/-1 [3] 7/-1/-1->4->0|0->4->7/-1/-1 [4] 6/-1/-1->4->5|5->4->6/-1/-1 [5] 5/-1/-1->4->6|6->4->5/-1/-1 [6] -1/-1/-1->4->7|7->4->-1/-1/-1 [7] -1/-1/-1->4->7|7->4->-1/-1/-1 [8] 7/-1/-1->4->0|0->4->7/-1/-1 [9] 7/-1/-1->4->0|0->4->7/-1/-1 [10] 6/-1/-1->4->5|5->4->6/-1/-1 [11] 5/-1/-1->4->6|6->4->5/-1/-1\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Trees [0] 6/-1/-1->5->1|1->5->6/-1/-1 [1] 6/-1/-1->5->1|1->5->6/-1/-1 [2] 1/-1/-1->5->6|6->5->1/-1/-1 [3] 1/-1/-1->5->6|6->5->1/-1/-1 [4] 4/-1/-1->5->7|7->5->4/-1/-1 [5] 7/-1/-1->5->4|4->5->7/-1/-1 [6] 6/-1/-1->5->1|1->5->6/-1/-1 [7] 6/-1/-1->5->1|1->5->6/-1/-1 [8] 1/-1/-1->5->6|6->5->1/-1/-1 [9] 1/-1/-1->5->6|6->5->1/-1/-1 [10] 4/-1/-1->5->7|7->5->4/-1/-1 [11] 7/-1/-1->5->4|4->5->7/-1/-1\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Trees [0] 2/-1/-1->3->0|0->3->2/-1/-1 [1] 2/-1/-1->3->0|0->3->2/-1/-1 [2] -1/-1/-1->3->2|2->3->-1/-1/-1 [3] -1/-1/-1->3->2|2->3->-1/-1/-1 [4] 7/-1/-1->3->1|1->3->7/-1/-1 [5] 1/-1/-1->3->7|7->3->1/-1/-1 [6] 2/-1/-1->3->0|0->3->2/-1/-1 [7] 2/-1/-1->3->0|0->3->2/-1/-1 [8] -1/-1/-1->3->2|2->3->-1/-1/-1 [9] -1/-1/-1->3->2|2->3->-1/-1/-1 [10] 7/-1/-1->3->1|1->3->7/-1/-1 [11] 1/-1/-1->3->7|7->3->1/-1/-1\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Trees [0] 7/-1/-1->6->5|5->6->7/-1/-1 [1] 7/-1/-1->6->5|5->6->7/-1/-1 [2] 5/-1/-1->6->7|7->6->5/-1/-1 [3] 5/-1/-1->6->7|7->6->5/-1/-1 [4] 2/-1/-1->6->4|4->6->2/-1/-1 [5] 4/-1/-1->6->2|2->6->4/-1/-1 [6] 7/-1/-1->6->5|5->6->7/-1/-1 [7] 7/-1/-1->6->5|5->6->7/-1/-1 [8] 5/-1/-1->6->7|7->6->5/-1/-1 [9] 5/-1/-1->6->7|7->6->5/-1/-1 [10] 2/-1/-1->6->4|4->6->2/-1/-1 [11] 4/-1/-1->6->2|2->6->4/-1/-1\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Trees [0] 4/-1/-1->7->6|6->7->4/-1/-1 [1] 4/-1/-1->7->6|6->7->4/-1/-1 [2] 6/-1/-1->7->4|4->7->6/-1/-1 [3] 6/-1/-1->7->4|4->7->6/-1/-1 [4] 5/-1/-1->7->3|3->7->5/-1/-1 [5] 3/-1/-1->7->5|5->7->3/-1/-1 [6] 4/-1/-1->7->6|6->7->4/-1/-1 [7] 4/-1/-1->7->6|6->7->4/-1/-1 [8] 6/-1/-1->7->4|4->7->6/-1/-1 [9] 6/-1/-1->7->4|4->7->6/-1/-1 [10] 5/-1/-1->7->3|3->7->5/-1/-1 [11] 3/-1/-1->7->5|5->7->3/-1/-1\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 00/12 :    0   3   2   1   5   6   7   4\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 01/12 :    0   3   2   1   5   6   7   4\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 02/12 :    0   4   7   6   5   1   2   3\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 03/12 :    0   4   7   6   5   1   2   3\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 04/12 :    0   1   3   7   5   4   6   2\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Trees [0] 5/-1/-1->1->2|2->1->5/-1/-1 [1] 5/-1/-1->1->2|2->1->5/-1/-1 [2] 2/-1/-1->1->5|5->1->2/-1/-1 [3] 2/-1/-1->1->5|5->1->2/-1/-1 [4] 3/-1/-1->1->0|0->1->3/-1/-1 [5] -1/-1/-1->1->3|3->1->-1/-1/-1 [6] 5/-1/-1->1->2|2->1->5/-1/-1 [7] 5/-1/-1->1->2|2->1->5/-1/-1 [8] 2/-1/-1->1->5|5->1->2/-1/-1 [9] 2/-1/-1->1->5|5->1->2/-1/-1 [10] 3/-1/-1->1->0|0->1->3/-1/-1 [11] -1/-1/-1->1->3|3->1->-1/-1/-1\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 05/12 :    0   2   6   4   5   7   3   1\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 06/12 :    0   3   2   1   5   6   7   4\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 07/12 :    0   3   2   1   5   6   7   4\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 08/12 :    0   4   7   6   5   1   2   3\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 09/12 :    0   4   7   6   5   1   2   3\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Trees [0] 1/-1/-1->2->3|3->2->1/-1/-1 [1] 1/-1/-1->2->3|3->2->1/-1/-1 [2] 3/-1/-1->2->1|1->2->3/-1/-1 [3] 3/-1/-1->2->1|1->2->3/-1/-1 [4] -1/-1/-1->2->6|6->2->-1/-1/-1 [5] 6/-1/-1->2->0|0->2->6/-1/-1 [6] 1/-1/-1->2->3|3->2->1/-1/-1 [7] 1/-1/-1->2->3|3->2->1/-1/-1 [8] 3/-1/-1->2->1|1->2->3/-1/-1 [9] 3/-1/-1->2->1|1->2->3/-1/-1 [10] -1/-1/-1->2->6|6->2->-1/-1/-1 [11] 6/-1/-1->2->0|0->2->6/-1/-1\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 10/12 :    0   1   3   7   5   4   6   2\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 11/12 :    0   2   6   4   5   7   3   1\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Trees [0] 3/-1/-1->0->-1|-1->0->3/-1/-1 [1] 3/-1/-1->0->-1|-1->0->3/-1/-1 [2] 4/-1/-1->0->-1|-1->0->4/-1/-1 [3] 4/-1/-1->0->-1|-1->0->4/-1/-1 [4] 1/-1/-1->0->-1|-1->0->1/-1/-1 [5] 2/-1/-1->0->-1|-1->0->2/-1/-1 [6] 3/-1/-1->0->-1|-1->0->3/-1/-1 [7] 3/-1/-1->0->-1|-1->0->3/-1/-1 [8] 4/-1/-1->0->-1|-1->0->4/-1/-1 [9] 4/-1/-1->0->-1|-1->0->4/-1/-1 [10] 1/-1/-1->0->-1|-1->0->1/-1/-1 [11] 2/-1/-1->0->-1|-1->0->2/-1/-1\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 00 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 00 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 00 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 00 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 00 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 00 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 00 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 00 : 0[170] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 00 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 00 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 00 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 00 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 00 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 00 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 00 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 01 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 01 : 0[170] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 01 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 01 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 01 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 01 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 01 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 01 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 01 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 01 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 01 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 01 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 01 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 01 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 01 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 02 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 02 : 0[170] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 02 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 02 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 02 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 02 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 02 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 02 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 02 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 02 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 02 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 02 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 02 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 02 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 02 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 03 : 0[170] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 03 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 03 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 03 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 03 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 03 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 03 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 03 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 03 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 03 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 03 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 03 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 03 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 03 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 03 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 04 : 3[1a0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 04 : 0[170] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 04 : 4[1b0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 04 : 5[1c0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 04 : 6[1d0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 04 : 1[180] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 04 : 7[1e0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 04 : 2[190] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 04 : 3[1a0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 04 : 2[190] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 04 : 4[1b0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 04 : 5[1c0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 04 : 6[1d0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 04 : 1[180] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 04 : 7[1e0] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 05 : 2[190] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 05 : 0[170] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 05 : 3[1a0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 05 : 4[1b0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 05 : 5[1c0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 05 : 6[1d0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 05 : 1[180] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 05 : 7[1e0] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 05 : 2[190] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 05 : 1[180] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 05 : 3[1a0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 05 : 4[1b0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 05 : 5[1c0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 05 : 6[1d0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 05 : 7[1e0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 06 : 0[170] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 06 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 06 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 06 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 06 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 06 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 06 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 06 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 06 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 06 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 06 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 06 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 06 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 06 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 06 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 07 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 07 : 0[170] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 07 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 07 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 07 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 07 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 07 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 07 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 07 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 07 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 07 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 07 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 07 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 07 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 07 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 08 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 08 : 0[170] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 08 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 08 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 08 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 08 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 08 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 08 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 08 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 08 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 08 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 08 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 08 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 08 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 08 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 09 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 09 : 0[170] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 09 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 09 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 09 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 09 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 09 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 09 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 09 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 09 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 09 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 09 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 09 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 09 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 09 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 10 : 3[1a0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 10 : 0[170] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 10 : 1[180] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 10 : 2[190] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 10 : 4[1b0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 10 : 5[1c0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 10 : 6[1d0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 10 : 7[1e0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 10 : 2[190] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 10 : 1[180] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 10 : 3[1a0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 10 : 4[1b0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 10 : 5[1c0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 10 : 6[1d0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 10 : 7[1e0] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 11 : 2[190] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 11 : 0[170] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 11 : 1[180] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 11 : 4[1b0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 11 : 3[1a0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 11 : 5[1c0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 11 : 6[1d0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 11 : 7[1e0] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 11 : 1[180] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 11 : 2[190] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 11 : 4[1b0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 11 : 3[1a0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 11 : 5[1c0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 11 : 6[1d0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO comm 0x56045239de40 rank 1 nranks 8 cudaDev 1 busId 180 - Init COMPLETE\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 11 : 7[1e0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO comm 0x5572158f8280 rank 0 nranks 8 cudaDev 0 busId 170 - Init COMPLETE\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO comm 0x561ffa4f9460 rank 2 nranks 8 cudaDev 2 busId 190 - Init COMPLETE\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO comm 0x55d820a76880 rank 4 nranks 8 cudaDev 4 busId 1b0 - Init COMPLETE\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO comm 0x556e194b8a40 rank 3 nranks 8 cudaDev 3 busId 1a0 - Init COMPLETE\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO comm 0x55fcca63dc10 rank 5 nranks 8 cudaDev 5 busId 1c0 - Init COMPLETE\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO comm 0x55e483e09020 rank 6 nranks 8 cudaDev 6 busId 1d0 - Init COMPLETE\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO comm 0x561a65a26cb0 rank 7 nranks 8 cudaDev 7 busId 1e0 - Init COMPLETE\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 00/12 :    0   3   2   1   5   6   7   4\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 01/12 :    0   3   2   1   5   6   7   4\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 02/12 :    0   4   7   6   5   1   2   3\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 03/12 :    0   4   7   6   5   1   2   3\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 04/12 :    0   1   3   7   5   4   6   2\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 05/12 :    0   2   6   4   5   7   3   1\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 06/12 :    0   3   2   1   5   6   7   4\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 07/12 :    0   3   2   1   5   6   7   4\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 08/12 :    0   4   7   6   5   1   2   3\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 09/12 :    0   4   7   6   5   1   2   3\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 10/12 :    0   1   3   7   5   4   6   2\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 11/12 :    0   2   6   4   5   7   3   1\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Trees [0] 1/-1/-1->2->3|3->2->1/-1/-1 [1] 1/-1/-1->2->3|3->2->1/-1/-1 [2] 3/-1/-1->2->1|1->2->3/-1/-1 [3] 3/-1/-1->2->1|1->2->3/-1/-1 [4] -1/-1/-1->2->6|6->2->-1/-1/-1 [5] 6/-1/-1->2->0|0->2->6/-1/-1 [6] 1/-1/-1->2->3|3->2->1/-1/-1 [7] 1/-1/-1->2->3|3->2->1/-1/-1 [8] 3/-1/-1->2->1|1->2->3/-1/-1 [9] 3/-1/-1->2->1|1->2->3/-1/-1 [10] -1/-1/-1->2->6|6->2->-1/-1/-1 [11] 6/-1/-1->2->0|0->2->6/-1/-1\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Trees [0] 5/-1/-1->1->2|2->1->5/-1/-1 [1] 5/-1/-1->1->2|2->1->5/-1/-1 [2] 2/-1/-1->1->5|5->1->2/-1/-1 [3] 2/-1/-1->1->5|5->1->2/-1/-1 [4] 3/-1/-1->1->0|0->1->3/-1/-1 [5] -1/-1/-1->1->3|3->1->-1/-1/-1 [6] 5/-1/-1->1->2|2->1->5/-1/-1 [7] 5/-1/-1->1->2|2->1->5/-1/-1 [8] 2/-1/-1->1->5|5->1->2/-1/-1 [9] 2/-1/-1->1->5|5->1->2/-1/-1 [10] 3/-1/-1->1->0|0->1->3/-1/-1 [11] -1/-1/-1->1->3|3->1->-1/-1/-1\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Trees [0] 2/-1/-1->3->0|0->3->2/-1/-1 [1] 2/-1/-1->3->0|0->3->2/-1/-1 [2] -1/-1/-1->3->2|2->3->-1/-1/-1 [3] -1/-1/-1->3->2|2->3->-1/-1/-1 [4] 7/-1/-1->3->1|1->3->7/-1/-1 [5] 1/-1/-1->3->7|7->3->1/-1/-1 [6] 2/-1/-1->3->0|0->3->2/-1/-1 [7] 2/-1/-1->3->0|0->3->2/-1/-1 [8] -1/-1/-1->3->2|2->3->-1/-1/-1 [9] -1/-1/-1->3->2|2->3->-1/-1/-1 [10] 7/-1/-1->3->1|1->3->7/-1/-1 [11] 1/-1/-1->3->7|7->3->1/-1/-1\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Trees [0] -1/-1/-1->4->7|7->4->-1/-1/-1 [1] -1/-1/-1->4->7|7->4->-1/-1/-1 [2] 7/-1/-1->4->0|0->4->7/-1/-1 [3] 7/-1/-1->4->0|0->4->7/-1/-1 [4] 6/-1/-1->4->5|5->4->6/-1/-1 [5] 5/-1/-1->4->6|6->4->5/-1/-1 [6] -1/-1/-1->4->7|7->4->-1/-1/-1 [7] -1/-1/-1->4->7|7->4->-1/-1/-1 [8] 7/-1/-1->4->0|0->4->7/-1/-1 [9] 7/-1/-1->4->0|0->4->7/-1/-1 [10] 6/-1/-1->4->5|5->4->6/-1/-1 [11] 5/-1/-1->4->6|6->4->5/-1/-1\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Trees [0] 6/-1/-1->5->1|1->5->6/-1/-1 [1] 6/-1/-1->5->1|1->5->6/-1/-1 [2] 1/-1/-1->5->6|6->5->1/-1/-1 [3] 1/-1/-1->5->6|6->5->1/-1/-1 [4] 4/-1/-1->5->7|7->5->4/-1/-1 [5] 7/-1/-1->5->4|4->5->7/-1/-1 [6] 6/-1/-1->5->1|1->5->6/-1/-1 [7] 6/-1/-1->5->1|1->5->6/-1/-1 [8] 1/-1/-1->5->6|6->5->1/-1/-1 [9] 1/-1/-1->5->6|6->5->1/-1/-1 [10] 4/-1/-1->5->7|7->5->4/-1/-1 [11] 7/-1/-1->5->4|4->5->7/-1/-1\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Trees [0] 3/-1/-1->0->-1|-1->0->3/-1/-1 [1] 3/-1/-1->0->-1|-1->0->3/-1/-1 [2] 4/-1/-1->0->-1|-1->0->4/-1/-1 [3] 4/-1/-1->0->-1|-1->0->4/-1/-1 [4] 1/-1/-1->0->-1|-1->0->1/-1/-1 [5] 2/-1/-1->0->-1|-1->0->2/-1/-1 [6] 3/-1/-1->0->-1|-1->0->3/-1/-1 [7] 3/-1/-1->0->-1|-1->0->3/-1/-1 [8] 4/-1/-1->0->-1|-1->0->4/-1/-1 [9] 4/-1/-1->0->-1|-1->0->4/-1/-1 [10] 1/-1/-1->0->-1|-1->0->1/-1/-1 [11] 2/-1/-1->0->-1|-1->0->2/-1/-1\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Trees [0] 7/-1/-1->6->5|5->6->7/-1/-1 [1] 7/-1/-1->6->5|5->6->7/-1/-1 [2] 5/-1/-1->6->7|7->6->5/-1/-1 [3] 5/-1/-1->6->7|7->6->5/-1/-1 [4] 2/-1/-1->6->4|4->6->2/-1/-1 [5] 4/-1/-1->6->2|2->6->4/-1/-1 [6] 7/-1/-1->6->5|5->6->7/-1/-1 [7] 7/-1/-1->6->5|5->6->7/-1/-1 [8] 5/-1/-1->6->7|7->6->5/-1/-1 [9] 5/-1/-1->6->7|7->6->5/-1/-1 [10] 2/-1/-1->6->4|4->6->2/-1/-1 [11] 4/-1/-1->6->2|2->6->4/-1/-1\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Trees [0] 4/-1/-1->7->6|6->7->4/-1/-1 [1] 4/-1/-1->7->6|6->7->4/-1/-1 [2] 6/-1/-1->7->4|4->7->6/-1/-1 [3] 6/-1/-1->7->4|4->7->6/-1/-1 [4] 5/-1/-1->7->3|3->7->5/-1/-1 [5] 3/-1/-1->7->5|5->7->3/-1/-1 [6] 4/-1/-1->7->6|6->7->4/-1/-1 [7] 4/-1/-1->7->6|6->7->4/-1/-1 [8] 6/-1/-1->7->4|4->7->6/-1/-1 [9] 6/-1/-1->7->4|4->7->6/-1/-1 [10] 5/-1/-1->7->3|3->7->5/-1/-1 [11] 3/-1/-1->7->5|5->7->3/-1/-1\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 00 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 00 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 00 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 00 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 00 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 00 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 00 : 0[170] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 00 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 00 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 00 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 00 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 00 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 00 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 00 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 00 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 01 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 01 : 0[170] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 01 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 01 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 01 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 01 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 01 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 01 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 01 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 01 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 01 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 01 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 01 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 01 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 01 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 02 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 02 : 0[170] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 02 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 02 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 02 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 02 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 02 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 02 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 02 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 02 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 02 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 02 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 02 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 02 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 02 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 03 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 03 : 0[170] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 03 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 03 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 03 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 03 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 03 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 03 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 03 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 03 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 03 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 03 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 03 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 03 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 03 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 04 : 3[1a0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 04 : 0[170] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 04 : 4[1b0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 04 : 1[180] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 04 : 2[190] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 04 : 6[1d0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 04 : 5[1c0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 04 : 7[1e0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 04 : 2[190] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 04 : 3[1a0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 04 : 4[1b0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 04 : 1[180] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 04 : 5[1c0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 04 : 6[1d0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 04 : 7[1e0] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 05 : 2[190] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 05 : 0[170] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 05 : 3[1a0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 05 : 4[1b0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 05 : 1[180] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 05 : 5[1c0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 05 : 6[1d0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 05 : 7[1e0] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 05 : 1[180] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 05 : 2[190] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 05 : 4[1b0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 05 : 3[1a0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 05 : 6[1d0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 05 : 5[1c0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 05 : 7[1e0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 06 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 06 : 0[170] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 06 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 06 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 06 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 06 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 06 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 06 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 06 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 06 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 06 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 06 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 06 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 06 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 06 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 07 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 07 : 0[170] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 07 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 07 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 07 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 07 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 07 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 07 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 07 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 07 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 07 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 07 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 07 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 07 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 07 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 08 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 08 : 0[170] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 08 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 08 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 08 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 08 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 08 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 08 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 08 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 08 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 08 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 08 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 08 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 08 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 08 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 09 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 09 : 0[170] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 09 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 09 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 09 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 09 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 09 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 09 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 09 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 09 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 09 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 09 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 09 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 09 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 09 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 10 : 3[1a0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 10 : 0[170] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 10 : 1[180] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 10 : 4[1b0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 10 : 2[190] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 10 : 6[1d0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 10 : 7[1e0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 10 : 5[1c0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 10 : 2[190] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 10 : 3[1a0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 10 : 4[1b0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 10 : 1[180] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 10 : 6[1d0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 10 : 7[1e0] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 10 : 5[1c0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 11 : 2[190] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO Channel 11 : 0[170] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 11 : 1[180] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 11 : 3[1a0] -> 1[180] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 11 : 4[1b0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 11 : 6[1d0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 11 : 7[1e0] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 11 : 5[1c0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO Channel 11 : 1[180] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO Channel 11 : 2[190] -> 0[170] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO Channel 11 : 3[1a0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO Channel 11 : 4[1b0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO Channel 11 : 6[1d0] -> 2[190] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO Channel 11 : 7[1e0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:algo-1-6o5j2:45:45 [1] NCCL INFO comm 0x560455070ba0 rank 1 nranks 8 cudaDev 1 busId 180 - Init COMPLETE\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO Channel 11 : 5[1c0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:543 [0] NCCL INFO comm 0x5572185cafe0 rank 0 nranks 8 cudaDev 0 busId 170 - Init COMPLETE\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:algo-1-6o5j2:47:47 [2] NCCL INFO comm 0x561ffd1cc1c0 rank 2 nranks 8 cudaDev 2 busId 190 - Init COMPLETE\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:algo-1-6o5j2:49:49 [3] NCCL INFO comm 0x556e1c18b7a0 rank 3 nranks 8 cudaDev 3 busId 1a0 - Init COMPLETE\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:algo-1-6o5j2:52:52 [4] NCCL INFO comm 0x55d8237495e0 rank 4 nranks 8 cudaDev 4 busId 1b0 - Init COMPLETE\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:algo-1-6o5j2:54:54 [6] NCCL INFO comm 0x55e486adbd80 rank 6 nranks 8 cudaDev 6 busId 1d0 - Init COMPLETE\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:algo-1-6o5j2:55:55 [7] NCCL INFO comm 0x561a686f9a10 rank 7 nranks 8 cudaDev 7 busId 1e0 - Init COMPLETE\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:algo-1-6o5j2:53:53 [5] NCCL INFO comm 0x55fccd310970 rank 5 nranks 8 cudaDev 5 busId 1c0 - Init COMPLETE\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:batch_size: 16\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:batch_size: 16\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:batch_size: 16\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:local_rank: 1\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:Get train data sampler and data loader\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:batch_size: 16\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:local_rank: 6\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:Get train data sampler and data loader\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:batch_size: 16\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:local_rank: 7\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:Get train data sampler and data loader\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:batch_size: 16\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:local_rank: 2\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:Get train data sampler and data loader\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Running smdistributed.dataparallel v1.2.3\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:################################\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Global batch size: 128\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:batch_size: 16\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:batch_size: 16\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:local_rank: 4\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:Get train data sampler and data loader\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:local_rank: 5\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:Get train data sampler and data loader\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:local_rank: 0\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Get train data sampler and data loader\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:local_rank: 3\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:Get train data sampler and data loader\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:Get test data sampler and data loader\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:Get test data sampler and data loader\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:Get test data sampler and data loader\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:Get test data sampler and data loader\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:Get test data sampler and data loader\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:Get test data sampler and data loader\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:Get test data sampler and data loader\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Get test data sampler and data loader\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:Processes 6250/50000 (12%) of train data\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:Processes 1250/10000 (12%) of test data\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:Processes 6250/50000 (12%) of train data\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:Processes 1250/10000 (12%) of test data\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:Processes 6250/50000 (12%) of train data\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:Processes 1250/10000 (12%) of test data\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:Processes 6250/50000 (12%) of train data\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:Processes 1250/10000 (12%) of test data\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:Processes 6250/50000 (12%) of train data\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:Processes 1250/10000 (12%) of test data\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:Processes 6250/50000 (12%) of train data\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:Processes 1250/10000 (12%) of test data\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:Processes 6250/50000 (12%) of train data\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:Processes 1250/10000 (12%) of test data\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Processes 6250/50000 (12%) of train data\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Processes 1250/10000 (12%) of test data\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:algo-1-6o5j2:543:757 [0] NCCL INFO Launch mode Parallel\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Model loaded\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:Model loaded\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:Model loaded\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:Model loaded\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:Model loaded\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:Model loaded\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:Model loaded\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:Model loaded\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:[2022-03-06 12:12:50.340 algo-1-6o5j2:55 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:[2022-03-06 12:12:50.343 algo-1-6o5j2:52 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:[2022-03-06 12:12:50.345 algo-1-6o5j2:45 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:[2022-03-06 12:12:50.349 algo-1-6o5j2:47 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:[2022-03-06 12:12:50.352 algo-1-6o5j2:54 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:[2022-03-06 12:12:50.353 algo-1-6o5j2:543 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:[2022-03-06 12:12:50.353 algo-1-6o5j2:53 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:[2022-03-06 12:12:50.360 algo-1-6o5j2:49 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:[2022-03-06 12:12:50.390 algo-1-6o5j2:52 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:[2022-03-06 12:12:50.390 algo-1-6o5j2:55 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:[2022-03-06 12:12:50.391 algo-1-6o5j2:45 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:[2022-03-06 12:12:50.397 algo-1-6o5j2:47 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:[2022-03-06 12:12:50.397 algo-1-6o5j2:54 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:[2022-03-06 12:12:50.398 algo-1-6o5j2:543 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:[2022-03-06 12:12:50.399 algo-1-6o5j2:53 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:[2022-03-06 12:12:50.409 algo-1-6o5j2:49 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.279840\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [1280/50000 (3%)]\tLoss: 2.336585\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [2560/50000 (5%)]\tLoss: 2.325633\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [3840/50000 (8%)]\tLoss: 2.305236\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [5120/50000 (10%)]\tLoss: 2.308415\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [6400/50000 (13%)]\tLoss: 2.313547\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [7680/50000 (15%)]\tLoss: 2.295692\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [8960/50000 (18%)]\tLoss: 2.321579\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [10240/50000 (20%)]\tLoss: 2.273313\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [11520/50000 (23%)]\tLoss: 2.334323\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [12800/50000 (26%)]\tLoss: 2.299960\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [14080/50000 (28%)]\tLoss: 2.276617\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [15360/50000 (31%)]\tLoss: 2.317211\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [16640/50000 (33%)]\tLoss: 2.274218\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [17920/50000 (36%)]\tLoss: 2.279405\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [19200/50000 (38%)]\tLoss: 2.293290\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [20480/50000 (41%)]\tLoss: 2.342976\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [21760/50000 (43%)]\tLoss: 2.280474\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [23040/50000 (46%)]\tLoss: 2.268249\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [24320/50000 (49%)]\tLoss: 2.339765\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [25600/50000 (51%)]\tLoss: 2.269370\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [26880/50000 (54%)]\tLoss: 2.291870\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [28160/50000 (56%)]\tLoss: 2.320926\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [29440/50000 (59%)]\tLoss: 2.291456\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [30720/50000 (61%)]\tLoss: 2.277325\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [32000/50000 (64%)]\tLoss: 2.312714\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [33280/50000 (66%)]\tLoss: 2.286045\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [34560/50000 (69%)]\tLoss: 2.318759\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [35840/50000 (72%)]\tLoss: 2.296728\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [37120/50000 (74%)]\tLoss: 2.292701\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [38400/50000 (77%)]\tLoss: 2.289097\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [39680/50000 (79%)]\tLoss: 2.299811\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [40960/50000 (82%)]\tLoss: 2.315225\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [42240/50000 (84%)]\tLoss: 2.309803\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [43520/50000 (87%)]\tLoss: 2.303248\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [44800/50000 (90%)]\tLoss: 2.271668\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [46080/50000 (92%)]\tLoss: 2.294409\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [47360/50000 (95%)]\tLoss: 2.324147\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [48640/50000 (97%)]\tLoss: 2.290001\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 1 [31200/50000 (100%)]\tLoss: 2.303318\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Test set: Average loss: -0.0043, Accuracy: 195/10000 (2%)\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [0/50000 (0%)]\tLoss: 2.277301\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [1280/50000 (3%)]\tLoss: 2.330997\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [2560/50000 (5%)]\tLoss: 2.314680\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [3840/50000 (8%)]\tLoss: 2.302020\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [5120/50000 (10%)]\tLoss: 2.304744\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [6400/50000 (13%)]\tLoss: 2.307970\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [7680/50000 (15%)]\tLoss: 2.289053\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [8960/50000 (18%)]\tLoss: 2.317713\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [10240/50000 (20%)]\tLoss: 2.267552\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [11520/50000 (23%)]\tLoss: 2.322700\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [12800/50000 (26%)]\tLoss: 2.296237\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [14080/50000 (28%)]\tLoss: 2.272704\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [15360/50000 (31%)]\tLoss: 2.305745\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [16640/50000 (33%)]\tLoss: 2.272580\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [17920/50000 (36%)]\tLoss: 2.274465\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [19200/50000 (38%)]\tLoss: 2.291039\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [20480/50000 (41%)]\tLoss: 2.333749\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [21760/50000 (43%)]\tLoss: 2.277700\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [23040/50000 (46%)]\tLoss: 2.266602\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [24320/50000 (49%)]\tLoss: 2.333269\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [25600/50000 (51%)]\tLoss: 2.269156\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [26880/50000 (54%)]\tLoss: 2.283602\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [28160/50000 (56%)]\tLoss: 2.310388\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [29440/50000 (59%)]\tLoss: 2.290602\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [30720/50000 (61%)]\tLoss: 2.267511\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [32000/50000 (64%)]\tLoss: 2.303711\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [33280/50000 (66%)]\tLoss: 2.276746\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [34560/50000 (69%)]\tLoss: 2.311191\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [35840/50000 (72%)]\tLoss: 2.294297\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [37120/50000 (74%)]\tLoss: 2.289915\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [38400/50000 (77%)]\tLoss: 2.285372\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [39680/50000 (79%)]\tLoss: 2.291688\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [40960/50000 (82%)]\tLoss: 2.313080\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [42240/50000 (84%)]\tLoss: 2.294959\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [43520/50000 (87%)]\tLoss: 2.296270\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [44800/50000 (90%)]\tLoss: 2.264710\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [46080/50000 (92%)]\tLoss: 2.284438\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [47360/50000 (95%)]\tLoss: 2.321103\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [48640/50000 (97%)]\tLoss: 2.277993\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Train Epoch: 2 [31200/50000 (100%)]\tLoss: 2.298898\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,4]<stdout>:Training is finished\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,1]<stdout>:Training is finished\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,3]<stdout>:Training is finished\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,5]<stdout>:Training is finished\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,7]<stdout>:Training is finished\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,6]<stdout>:Training is finished\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,2]<stdout>:Training is finished\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Test set: Average loss: -0.0059, Accuracy: 225/10000 (2%)\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Training is finished\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m [1,0]<stdout>:Saving the model.\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m \n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 |\u001b[0m 2022-03-06 12:13:03,906 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\u001b[36m1d90cppl4s-algo-1-6o5j2 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "job_name ='cifar10-sm-local-ddp'\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"train_ddp.py\",    \n",
    "#     source_dir='source/ddp',    \n",
    "    source_dir='source',        \n",
    "    base_job_name = job_name,\n",
    "    role=role,\n",
    "    framework_version=\"1.8.1\",\n",
    "    py_version=\"py36\",\n",
    "    instance_count= instance_count,\n",
    "    instance_type= instance_type,\n",
    "    sagemaker_session= sess,\n",
    "    # Training using SMDataParallel Distributed Training Framework\n",
    "    distribution={\"smdistributed\": {\"dataparallel\": {\"enabled\": True}}},\n",
    "    hyperparameters=hyperparameters,    \n",
    "    debugger_hook_config=False,\n",
    ")\n",
    "estimator.fit({\"training\" : inputs}, wait=False)\n",
    "#estimator.fit({\"training\" : \"file://../data\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 로컬모드에서 도커 이미지 다운로드 된 것을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY                                                      TAG                 IMAGE ID            CREATED             SIZE\n",
      "763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training   1.8.1-gpu-py36      b4191cf0b8c9        2 months ago        13.3GB\n"
     ]
    }
   ],
   "source": [
    "! docker image ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 호스트 모드로 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "job_name ='cifar10-sm-ddp'\n",
    "instance_type=\"ml.p3.16xlarge\"\n",
    "\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "inputs = s3_inputs\n",
    "instance_count = 2\n",
    "hyperparameters={\"epochs\": 20, \n",
    "                 'batch-size': 128,                     \n",
    "                 'lr': 0.01,\n",
    "                }        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "job_name ='cifar10-ddp'\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"train_ddp.py\",    \n",
    "    source_dir='source',    \n",
    "    base_job_name = job_name,\n",
    "    role=role,\n",
    "    framework_version=\"1.8.1\",\n",
    "    py_version=\"py36\",\n",
    "    # For training with multinode distributed training, set this count. Example: 2\n",
    "    instance_count= instance_count,\n",
    "    # For training with p3dn instance use - ml.p3dn.24xlarge, with p4dn instance use - ml.p4d.24xlarge\n",
    "    instance_type= instance_type,\n",
    "    sagemaker_session= sess,\n",
    "    # Training using SMDataParallel Distributed Training Framework\n",
    "    distribution={\"smdistributed\": {\"dataparallel\": {\"enabled\": True}}},\n",
    "    hyperparameters=hyperparameters,    \n",
    "    debugger_hook_config=False,\n",
    ")\n",
    "estimator.fit({\"training\" : inputs}, wait=False)\n",
    "#estimator.fit({\"training\" : \"file://../data\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-27 14:04:34 Starting - Starting the training job...\n",
      "2021-09-27 14:04:56 Starting - Launching requested ML instancesProfilerReport-1632751472: InProgress\n",
      ".........\n",
      "2021-09-27 14:06:26 Starting - Preparing the instances for training.........\n",
      "2021-09-27 14:08:04 Downloading - Downloading input data...\n",
      "2021-09-27 14:08:18 Training - Downloading the training image......................\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[35mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[35mbash: no job control in this shell\u001b[0m\n",
      "\u001b[35m2021-09-27 14:12:05,497 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[35m2021-09-27 14:12:05,574 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[35m2021-09-27 14:12:08,604 sagemaker_pytorch_container.training INFO     Invoking SMDataParallel\u001b[0m\n",
      "\u001b[35m2021-09-27 14:12:08,604 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-09-27 14:12:08,854 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-09-27 14:12:08,931 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2021-09-27 14:12:08,943 sagemaker_pytorch_container.training INFO     Invoking SMDataParallel\u001b[0m\n",
      "\u001b[34m2021-09-27 14:12:08,943 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[35m2021-09-27 14:12:09,131 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[35m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34m2021-09-27 14:12:09,371 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: torch==1.8.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (1.8.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: torchvision==0.9.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (0.9.1)\u001b[0m\n",
      "\u001b[35mCollecting torchsummary==1.5.1\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from torch==1.8.1->-r requirements.txt (line 1)) (0.8)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torch==1.8.1->-r requirements.txt (line 1)) (1.19.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from torch==1.8.1->-r requirements.txt (line 1)) (3.10.0.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.6/site-packages (from torchvision==0.9.1->-r requirements.txt (line 4)) (8.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch==1.8.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (1.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torchvision==0.9.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (0.9.1)\u001b[0m\n",
      "\u001b[34mCollecting torchsummary==1.5.1\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torch==1.8.1->-r requirements.txt (line 1)) (1.19.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from torch==1.8.1->-r requirements.txt (line 1)) (0.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from torch==1.8.1->-r requirements.txt (line 1)) (3.10.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.6/site-packages (from torchvision==0.9.1->-r requirements.txt (line 4)) (8.3.1)\u001b[0m\n",
      "\u001b[35mInstalling collected packages: torchsummary\u001b[0m\n",
      "\u001b[35mSuccessfully installed torchsummary-1.5.1\u001b[0m\n",
      "\u001b[35mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\n",
      "\u001b[35m2021-09-27 14:12:11,556 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[35m2021-09-27 14:12:11,556 sagemaker-training-toolkit INFO     Waiting for MPI Master to create SSH daemon.\u001b[0m\n",
      "\u001b[35m2021-09-27 14:12:11,558 sagemaker-training-toolkit INFO     Cannot connect to host algo-1\u001b[0m\n",
      "\u001b[35m2021-09-27 14:12:11,558 sagemaker-training-toolkit INFO     Connection failed with exception: \n",
      " [Errno None] Unable to connect to port 22 on 10.2.228.127\u001b[0m\n",
      "\u001b[34mInstalling collected packages: torchsummary\u001b[0m\n",
      "\u001b[34mSuccessfully installed torchsummary-1.5.1\u001b[0m\n",
      "\u001b[35m2021-09-27 14:12:12,566 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[35m2021-09-27 14:12:12,641 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[35m2021-09-27 14:12:12,641 sagemaker-training-toolkit INFO     Can connect to host algo-1\u001b[0m\n",
      "\u001b[35m2021-09-27 14:12:12,641 sagemaker-training-toolkit INFO     MPI Master online, creating SSH daemon.\u001b[0m\n",
      "\u001b[35m2021-09-27 14:12:12,641 sagemaker-training-toolkit INFO     Writing environment variables to /etc/environment for the MPI process.\u001b[0m\n",
      "\u001b[35m2021-09-27 14:12:12,645 sagemaker-training-toolkit INFO     Waiting for MPI process to finish.\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\n",
      "\u001b[34m2021-09-27 14:12:12,198 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[34m2021-09-27 14:12:12,198 sagemaker-training-toolkit INFO     Creating SSH daemon.\u001b[0m\n",
      "\u001b[34m2021-09-27 14:12:12,202 sagemaker-training-toolkit INFO     Waiting for MPI workers to establish their SSH connections\u001b[0m\n",
      "\u001b[34m2021-09-27 14:12:12,203 sagemaker-training-toolkit INFO     Cannot connect to host algo-2 at port 22. Retrying...\u001b[0m\n",
      "\u001b[34m2021-09-27 14:12:12,203 sagemaker-training-toolkit INFO     Connection closed\u001b[0m\n",
      "\u001b[34m2021-09-27 14:12:13,212 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[34m2021-09-27 14:12:13,285 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34m2021-09-27 14:12:13,285 sagemaker-training-toolkit INFO     Can connect to host algo-2 at port 22\u001b[0m\n",
      "\u001b[34m2021-09-27 14:12:13,285 sagemaker-training-toolkit INFO     Connection closed\u001b[0m\n",
      "\u001b[34m2021-09-27 14:12:13,285 sagemaker-training-toolkit INFO     Worker algo-2 available for communication\u001b[0m\n",
      "\u001b[34m2021-09-27 14:12:13,285 sagemaker-training-toolkit INFO     Network interface name: eth0\u001b[0m\n",
      "\u001b[34m2021-09-27 14:12:13,286 sagemaker-training-toolkit INFO     Host: ['algo-1', 'algo-2']\u001b[0m\n",
      "\u001b[34m2021-09-27 14:12:13,287 sagemaker-training-toolkit INFO     instance type: ml.p3.16xlarge\u001b[0m\n",
      "\u001b[34m2021-09-27 14:12:13,366 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_distributed_dataparallel_enabled\": true,\n",
      "        \"sagemaker_distributed_dataparallel_custom_mpi_options\": \"\",\n",
      "        \"sagemaker_instance_type\": \"ml.p3.16xlarge\"\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 128,\n",
      "        \"lr\": 0.01,\n",
      "        \"epochs\": 20\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"cifar10-ddp-2021-09-27-14-04-32-403\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-057716757052/cifar10-ddp-2021-09-27-14-04-32-403/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_ddp\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 64,\n",
      "    \"num_gpus\": 8,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_ddp.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":128,\"epochs\":20,\"lr\":0.01}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_ddp.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_distributed_dataparallel_custom_mpi_options\":\"\",\"sagemaker_distributed_dataparallel_enabled\":true,\"sagemaker_instance_type\":\"ml.p3.16xlarge\"}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_ddp\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=64\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-057716757052/cifar10-ddp-2021-09-27-14-04-32-403/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_distributed_dataparallel_custom_mpi_options\":\"\",\"sagemaker_distributed_dataparallel_enabled\":true,\"sagemaker_instance_type\":\"ml.p3.16xlarge\"},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"batch-size\":128,\"epochs\":20,\"lr\":0.01},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"cifar10-ddp-2021-09-27-14-04-32-403\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-057716757052/cifar10-ddp-2021-09-27-14-04-32-403/source/sourcedir.tar.gz\",\"module_name\":\"train_ddp\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_ddp.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"128\",\"--epochs\",\"20\",\"--lr\",\"0.01\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=128\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.01\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=20\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34mmpirun --host algo-1:8,algo-2:8 -np 16 --allow-run-as-root --tag-output --oversubscribe -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -mca btl_vader_single_copy_mechanism none -mca plm_rsh_num_concurrent 2 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x SMDATAPARALLEL_USE_HOMOGENEOUS=1 -x FI_PROVIDER=efa -x RDMAV_FORK_SAFE=1 -x LD_PRELOAD=/opt/conda/lib/python3.6/site-packages/gethostname.cpython-36m-x86_64-linux-gnu.so -x SMDATAPARALLEL_SERVER_ADDR=algo-1 -x SMDATAPARALLEL_SERVER_PORT=7592 -x SAGEMAKER_INSTANCE_TYPE=ml.p3.16xlarge smddprun /opt/conda/bin/python3.6 -m mpi4py train_ddp.py --batch-size 128 --epochs 20 --lr 0.01\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m2021-09-27 14:12:14,655 sagemaker-training-toolkit INFO     Process[es]: [psutil.Process(pid=57, name='orted', status='sleeping', started='14:12:14')]\u001b[0m\n",
      "\u001b[35m2021-09-27 14:12:14,656 sagemaker-training-toolkit INFO     Orted process found [psutil.Process(pid=57, name='orted', status='sleeping', started='14:12:14')]\u001b[0m\n",
      "\u001b[35m2021-09-27 14:12:14,656 sagemaker-training-toolkit INFO     Waiting for orted process [psutil.Process(pid=57, name='orted', status='sleeping', started='14:12:14')]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Bootstrap : Using [0]eth0:10.2.228.127<0>\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Bootstrap : Using [0]eth0:10.2.249.254<0>\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO NET/Socket : Using [0]eth0:10.2.249.254<0>\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:NCCL version 2.7.8+cuda11.1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO NET/Socket : Using [0]eth0:10.2.228.127<0>\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:NCCL version 2.7.8+cuda11.1\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO Bootstrap : Using [0]eth0:10.2.249.254<0>\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Bootstrap : Using [0]eth0:10.2.249.254<0>\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Bootstrap : Using [0]eth0:10.2.249.254<0>\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO NET/Socket : Using [0]eth0:10.2.249.254<0>\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO NET/Socket : Using [0]eth0:10.2.249.254<0>\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO NET/Socket : Using [0]eth0:10.2.249.254<0>\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO Bootstrap : Using [0]eth0:10.2.228.127<0>\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Bootstrap : Using [0]eth0:10.2.228.127<0>\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Bootstrap : Using [0]eth0:10.2.228.127<0>\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO NET/Socket : Using [0]eth0:10.2.228.127<0>\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO NET/Socket : Using [0]eth0:10.2.228.127<0>\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO NET/Socket : Using [0]eth0:10.2.228.127<0>\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO Bootstrap : Using [0]eth0:10.2.249.254<0>\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO Bootstrap : Using [0]eth0:10.2.249.254<0>\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO Bootstrap : Using [0]eth0:10.2.249.254<0>\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO Bootstrap : Using [0]eth0:10.2.249.254<0>\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO NET/Socket : Using [0]eth0:10.2.249.254<0>\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO NET/Socket : Using [0]eth0:10.2.249.254<0>\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO NET/Socket : Using [0]eth0:10.2.249.254<0>\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO NET/Socket : Using [0]eth0:10.2.249.254<0>\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO Bootstrap : Using [0]eth0:10.2.228.127<0>\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO Bootstrap : Using [0]eth0:10.2.228.127<0>\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO Bootstrap : Using [0]eth0:10.2.228.127<0>\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Bootstrap : Using [0]eth0:10.2.228.127<0>\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO NET/Socket : Using [0]eth0:10.2.228.127<0>\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO NET/Socket : Using [0]eth0:10.2.228.127<0>\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO NET/Socket : Using [0]eth0:10.2.228.127<0>\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO NET/Socket : Using [0]eth0:10.2.228.127<0>\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Trees [0] 1/-1/-1->2->3|3->2->1/-1/-1 [1] 1/-1/-1->2->3|3->2->1/-1/-1 [2] 3/-1/-1->2->1|1->2->3/-1/-1 [3] 3/-1/-1->2->1|1->2->3/-1/-1 [4] -1/-1/-1->2->6|6->2->-1/-1/-1 [5] 6/-1/-1->2->0|0->2->6/-1/-1 [6] 1/-1/-1->2->3|3->2->1/-1/-1 [7] 1/-1/-1->2->3|3->2->1/-1/-1 [8] 3/-1/-1->2->1|1->2->3/-1/-1 [9] 3/-1/-1->2->1|1->2->3/-1/-1 [10] -1/-1/-1->2->6|6->2->-1/-1/-1 [11] 6/-1/-1->2->0|0->2->6/-1/-1\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO Trees [0] 5/-1/-1->1->2|2->1->5/-1/-1 [1] 5/-1/-1->1->2|2->1->5/-1/-1 [2] 2/-1/-1->1->5|5->1->2/-1/-1 [3] 2/-1/-1->1->5|5->1->2/-1/-1 [4] 3/-1/-1->1->0|0->1->3/-1/-1 [5] -1/-1/-1->1->3|3->1->-1/-1/-1 [6] 5/-1/-1->1->2|2->1->5/-1/-1 [7] 5/-1/-1->1->2|2->1->5/-1/-1 [8] 2/-1/-1->1->5|5->1->2/-1/-1 [9] 2/-1/-1->1->5|5->1->2/-1/-1 [10] 3/-1/-1->1->0|0->1->3/-1/-1 [11] -1/-1/-1->1->3|3->1->-1/-1/-1\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Trees [0] 2/-1/-1->3->0|0->3->2/-1/-1 [1] 2/-1/-1->3->0|0->3->2/-1/-1 [2] -1/-1/-1->3->2|2->3->-1/-1/-1 [3] -1/-1/-1->3->2|2->3->-1/-1/-1 [4] 7/-1/-1->3->1|1->3->7/-1/-1 [5] 1/-1/-1->3->7|7->3->1/-1/-1 [6] 2/-1/-1->3->0|0->3->2/-1/-1 [7] 2/-1/-1->3->0|0->3->2/-1/-1 [8] -1/-1/-1->3->2|2->3->-1/-1/-1 [9] -1/-1/-1->3->2|2->3->-1/-1/-1 [10] 7/-1/-1->3->1|1->3->7/-1/-1 [11] 1/-1/-1->3->7|7->3->1/-1/-1\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO Trees [0] -1/-1/-1->4->7|7->4->-1/-1/-1 [1] -1/-1/-1->4->7|7->4->-1/-1/-1 [2] 7/-1/-1->4->0|0->4->7/-1/-1 [3] 7/-1/-1->4->0|0->4->7/-1/-1 [4] 6/-1/-1->4->5|5->4->6/-1/-1 [5] 5/-1/-1->4->6|6->4->5/-1/-1 [6] -1/-1/-1->4->7|7->4->-1/-1/-1 [7] -1/-1/-1->4->7|7->4->-1/-1/-1 [8] 7/-1/-1->4->0|0->4->7/-1/-1 [9] 7/-1/-1->4->0|0->4->7/-1/-1 [10] 6/-1/-1->4->5|5->4->6/-1/-1 [11] 5/-1/-1->4->6|6->4->5/-1/-1\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO Trees [0] 6/-1/-1->5->1|1->5->6/-1/-1 [1] 6/-1/-1->5->1|1->5->6/-1/-1 [2] 1/-1/-1->5->6|6->5->1/-1/-1 [3] 1/-1/-1->5->6|6->5->1/-1/-1 [4] 4/-1/-1->5->7|7->5->4/-1/-1 [5] 7/-1/-1->5->4|4->5->7/-1/-1 [6] 6/-1/-1->5->1|1->5->6/-1/-1 [7] 6/-1/-1->5->1|1->5->6/-1/-1 [8] 1/-1/-1->5->6|6->5->1/-1/-1 [9] 1/-1/-1->5->6|6->5->1/-1/-1 [10] 4/-1/-1->5->7|7->5->4/-1/-1 [11] 7/-1/-1->5->4|4->5->7/-1/-1\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO Trees [0] 7/-1/-1->6->5|5->6->7/-1/-1 [1] 7/-1/-1->6->5|5->6->7/-1/-1 [2] 5/-1/-1->6->7|7->6->5/-1/-1 [3] 5/-1/-1->6->7|7->6->5/-1/-1 [4] 2/-1/-1->6->4|4->6->2/-1/-1 [5] 4/-1/-1->6->2|2->6->4/-1/-1 [6] 7/-1/-1->6->5|5->6->7/-1/-1 [7] 7/-1/-1->6->5|5->6->7/-1/-1 [8] 5/-1/-1->6->7|7->6->5/-1/-1 [9] 5/-1/-1->6->7|7->6->5/-1/-1 [10] 2/-1/-1->6->4|4->6->2/-1/-1 [11] 4/-1/-1->6->2|2->6->4/-1/-1\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 00/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 01/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO Trees [0] 4/-1/-1->7->6|6->7->4/-1/-1 [1] 4/-1/-1->7->6|6->7->4/-1/-1 [2] 6/-1/-1->7->4|4->7->6/-1/-1 [3] 6/-1/-1->7->4|4->7->6/-1/-1 [4] 5/-1/-1->7->3|3->7->5/-1/-1 [5] 3/-1/-1->7->5|5->7->3/-1/-1 [6] 4/-1/-1->7->6|6->7->4/-1/-1 [7] 4/-1/-1->7->6|6->7->4/-1/-1 [8] 6/-1/-1->7->4|4->7->6/-1/-1 [9] 6/-1/-1->7->4|4->7->6/-1/-1 [10] 5/-1/-1->7->3|3->7->5/-1/-1 [11] 3/-1/-1->7->5|5->7->3/-1/-1\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 02/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 03/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 04/12 :    0   1   3   7   5   4   6   2\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 05/12 :    0   2   6   4   5   7   3   1\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 06/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 07/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 08/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 09/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 10/12 :    0   1   3   7   5   4   6   2\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 11/12 :    0   2   6   4   5   7   3   1\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Trees [0] 3/-1/-1->0->-1|-1->0->3/-1/-1 [1] 3/-1/-1->0->-1|-1->0->3/-1/-1 [2] 4/-1/-1->0->-1|-1->0->4/-1/-1 [3] 4/-1/-1->0->-1|-1->0->4/-1/-1 [4] 1/-1/-1->0->-1|-1->0->1/-1/-1 [5] 2/-1/-1->0->-1|-1->0->2/-1/-1 [6] 3/-1/-1->0->-1|-1->0->3/-1/-1 [7] 3/-1/-1->0->-1|-1->0->3/-1/-1 [8] 4/-1/-1->0->-1|-1->0->4/-1/-1 [9] 4/-1/-1->0->-1|-1->0->4/-1/-1 [10] 1/-1/-1->0->-1|-1->0->1/-1/-1 [11] 2/-1/-1->0->-1|-1->0->2/-1/-1\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 00 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO Channel 00 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO Channel 00 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO Channel 00 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Channel 00 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO Channel 00 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO Channel 00 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 00 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO Channel 00 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 00 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Channel 00 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO Channel 00 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO Channel 00 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO Channel 00 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO Channel 00 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO Channel 01 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 01 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 01 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Channel 01 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO Channel 01 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO Channel 01 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO Channel 01 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO Channel 01 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO Channel 01 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 01 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Channel 01 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO Channel 01 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO Channel 01 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO Channel 01 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO Channel 01 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO Channel 02 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 02 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 02 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Channel 02 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO Channel 02 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO Channel 02 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO Channel 02 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO Channel 02 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Channel 02 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO Channel 02 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 02 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO Channel 02 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO Channel 02 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO Channel 02 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO Channel 02 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Channel 03 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 03 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO Channel 03 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 03 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO Channel 03 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO Channel 03 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO Channel 03 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO Channel 03 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Channel 03 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO Channel 03 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 03 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO Channel 03 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO Channel 03 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO Channel 03 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO Channel 03 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Channel 04 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 04 : 0[170] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO Channel 04 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Trees [0] 1/-1/-1->2->3|3->2->1/-1/-1 [1] 1/-1/-1->2->3|3->2->1/-1/-1 [2] 3/-1/-1->2->1|1->2->3/-1/-1 [3] 3/-1/-1->2->1|1->2->3/-1/-1 [4] -1/-1/-1->2->6|6->2->-1/-1/-1 [5] 6/-1/-1->2->0|0->2->6/-1/-1 [6] 1/-1/-1->2->3|3->2->1/-1/-1 [7] 1/-1/-1->2->3|3->2->1/-1/-1 [8] 3/-1/-1->2->1|1->2->3/-1/-1 [9] 3/-1/-1->2->1|1->2->3/-1/-1 [10] -1/-1/-1->2->6|6->2->-1/-1/-1 [11] 6/-1/-1->2->0|0->2->6/-1/-1\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO Trees [0] 5/-1/-1->1->2|2->1->5/-1/-1 [1] 5/-1/-1->1->2|2->1->5/-1/-1 [2] 2/-1/-1->1->5|5->1->2/-1/-1 [3] 2/-1/-1->1->5|5->1->2/-1/-1 [4] 3/-1/-1->1->0|0->1->3/-1/-1 [5] -1/-1/-1->1->3|3->1->-1/-1/-1 [6] 5/-1/-1->1->2|2->1->5/-1/-1 [7] 5/-1/-1->1->2|2->1->5/-1/-1 [8] 2/-1/-1->1->5|5->1->2/-1/-1 [9] 2/-1/-1->1->5|5->1->2/-1/-1 [10] 3/-1/-1->1->0|0->1->3/-1/-1 [11] -1/-1/-1->1->3|3->1->-1/-1/-1\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Trees [0] 2/-1/-1->3->0|0->3->2/-1/-1 [1] 2/-1/-1->3->0|0->3->2/-1/-1 [2] -1/-1/-1->3->2|2->3->-1/-1/-1 [3] -1/-1/-1->3->2|2->3->-1/-1/-1 [4] 7/-1/-1->3->1|1->3->7/-1/-1 [5] 1/-1/-1->3->7|7->3->1/-1/-1 [6] 2/-1/-1->3->0|0->3->2/-1/-1 [7] 2/-1/-1->3->0|0->3->2/-1/-1 [8] -1/-1/-1->3->2|2->3->-1/-1/-1 [9] -1/-1/-1->3->2|2->3->-1/-1/-1 [10] 7/-1/-1->3->1|1->3->7/-1/-1 [11] 1/-1/-1->3->7|7->3->1/-1/-1\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 04 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO Trees [0] -1/-1/-1->4->7|7->4->-1/-1/-1 [1] -1/-1/-1->4->7|7->4->-1/-1/-1 [2] 7/-1/-1->4->0|0->4->7/-1/-1 [3] 7/-1/-1->4->0|0->4->7/-1/-1 [4] 6/-1/-1->4->5|5->4->6/-1/-1 [5] 5/-1/-1->4->6|6->4->5/-1/-1 [6] -1/-1/-1->4->7|7->4->-1/-1/-1 [7] -1/-1/-1->4->7|7->4->-1/-1/-1 [8] 7/-1/-1->4->0|0->4->7/-1/-1 [9] 7/-1/-1->4->0|0->4->7/-1/-1 [10] 6/-1/-1->4->5|5->4->6/-1/-1 [11] 5/-1/-1->4->6|6->4->5/-1/-1\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO Trees [0] 6/-1/-1->5->1|1->5->6/-1/-1 [1] 6/-1/-1->5->1|1->5->6/-1/-1 [2] 1/-1/-1->5->6|6->5->1/-1/-1 [3] 1/-1/-1->5->6|6->5->1/-1/-1 [4] 4/-1/-1->5->7|7->5->4/-1/-1 [5] 7/-1/-1->5->4|4->5->7/-1/-1 [6] 6/-1/-1->5->1|1->5->6/-1/-1 [7] 6/-1/-1->5->1|1->5->6/-1/-1 [8] 1/-1/-1->5->6|6->5->1/-1/-1 [9] 1/-1/-1->5->6|6->5->1/-1/-1 [10] 4/-1/-1->5->7|7->5->4/-1/-1 [11] 7/-1/-1->5->4|4->5->7/-1/-1\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Trees [0] 4/-1/-1->7->6|6->7->4/-1/-1 [1] 4/-1/-1->7->6|6->7->4/-1/-1 [2] 6/-1/-1->7->4|4->7->6/-1/-1 [3] 6/-1/-1->7->4|4->7->6/-1/-1 [4] 5/-1/-1->7->3|3->7->5/-1/-1 [5] 3/-1/-1->7->5|5->7->3/-1/-1 [6] 4/-1/-1->7->6|6->7->4/-1/-1 [7] 4/-1/-1->7->6|6->7->4/-1/-1 [8] 6/-1/-1->7->4|4->7->6/-1/-1 [9] 6/-1/-1->7->4|4->7->6/-1/-1 [10] 5/-1/-1->7->3|3->7->5/-1/-1 [11] 3/-1/-1->7->5|5->7->3/-1/-1\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO Trees [0] 7/-1/-1->6->5|5->6->7/-1/-1 [1] 7/-1/-1->6->5|5->6->7/-1/-1 [2] 5/-1/-1->6->7|7->6->5/-1/-1 [3] 5/-1/-1->6->7|7->6->5/-1/-1 [4] 2/-1/-1->6->4|4->6->2/-1/-1 [5] 4/-1/-1->6->2|2->6->4/-1/-1 [6] 7/-1/-1->6->5|5->6->7/-1/-1 [7] 7/-1/-1->6->5|5->6->7/-1/-1 [8] 5/-1/-1->6->7|7->6->5/-1/-1 [9] 5/-1/-1->6->7|7->6->5/-1/-1 [10] 2/-1/-1->6->4|4->6->2/-1/-1 [11] 4/-1/-1->6->2|2->6->4/-1/-1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 00/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 01/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 02/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 03/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 04/12 :    0   1   3   7   5   4   6   2\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 05/12 :    0   2   6   4   5   7   3   1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 06/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 07/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 08/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 09/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 10/12 :    0   1   3   7   5   4   6   2\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 11/12 :    0   2   6   4   5   7   3   1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Trees [0] 3/-1/-1->0->-1|-1->0->3/-1/-1 [1] 3/-1/-1->0->-1|-1->0->3/-1/-1 [2] 4/-1/-1->0->-1|-1->0->4/-1/-1 [3] 4/-1/-1->0->-1|-1->0->4/-1/-1 [4] 1/-1/-1->0->-1|-1->0->1/-1/-1 [5] 2/-1/-1->0->-1|-1->0->2/-1/-1 [6] 3/-1/-1->0->-1|-1->0->3/-1/-1 [7] 3/-1/-1->0->-1|-1->0->3/-1/-1 [8] 4/-1/-1->0->-1|-1->0->4/-1/-1 [9] 4/-1/-1->0->-1|-1->0->4/-1/-1 [10] 1/-1/-1->0->-1|-1->0->1/-1/-1 [11] 2/-1/-1->0->-1|-1->0->2/-1/-1\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO Channel 04 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO Channel 04 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO Channel 04 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO Channel 04 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO Channel 00 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 00 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Channel 00 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO Channel 00 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO Channel 00 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 00 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO Channel 00 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 00 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 04 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO Channel 04 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Channel 04 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO Channel 04 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO Channel 04 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO Channel 04 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO Channel 04 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO Channel 00 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 05 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO Channel 00 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 00 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Channel 00 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO Channel 00 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 00 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO Channel 00 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO Channel 05 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Channel 05 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 05 : 0[170] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO Channel 05 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO Channel 05 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO Channel 05 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO Channel 05 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO Channel 01 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 01 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO Channel 01 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 01 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO Channel 01 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Channel 01 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 01 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO Channel 01 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 05 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO Channel 05 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO Channel 05 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Channel 05 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO Channel 05 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO Channel 05 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO Channel 05 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO Channel 01 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO Channel 01 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 01 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 06 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Channel 01 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO Channel 01 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 01 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO Channel 01 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO Channel 06 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 06 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO Channel 06 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Channel 06 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO Channel 06 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO Channel 06 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO Channel 06 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO Channel 02 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 02 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO Channel 06 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO Channel 02 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 02 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO Channel 06 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Channel 02 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO Channel 02 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 02 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO Channel 02 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 06 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Channel 06 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO Channel 06 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO Channel 06 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO Channel 06 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO Channel 02 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Channel 02 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO Channel 07 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO Channel 02 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 07 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 02 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO Channel 02 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO Channel 07 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 02 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO Channel 02 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 07 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Channel 07 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO Channel 07 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO Channel 07 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO Channel 07 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 03 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Channel 03 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO Channel 07 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO Channel 03 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO Channel 03 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 03 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO Channel 07 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO Channel 03 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 07 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 03 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO Channel 03 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Channel 07 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO Channel 07 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO Channel 07 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO Channel 07 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Channel 03 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO Channel 03 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO Channel 08 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO Channel 03 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 03 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 08 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO Channel 03 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO Channel 08 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 03 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO Channel 03 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 08 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Channel 08 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO Channel 08 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO Channel 08 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO Channel 08 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Channel 04 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 04 : 0[170] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO Channel 04 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Channel 08 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO Channel 04 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 04 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO Channel 08 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO Channel 08 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO Channel 04 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 04 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 08 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO Channel 04 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO Channel 08 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO Channel 08 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO Channel 08 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Channel 09 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 09 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 04 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Channel 04 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO Channel 04 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO Channel 09 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 09 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO Channel 04 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO Channel 09 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO Channel 04 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 04 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO Channel 09 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO Channel 04 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO Channel 09 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO Channel 09 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Channel 09 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 05 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 05 : 0[170] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO Channel 09 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 09 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Channel 05 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO Channel 05 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO Channel 09 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO Channel 05 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO Channel 09 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO Channel 05 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO Channel 09 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 05 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO Channel 09 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO Channel 05 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Channel 10 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO Channel 05 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 10 : 0[170] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 10 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO Channel 10 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 05 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO Channel 10 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Channel 05 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO Channel 05 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO Channel 10 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO Channel 10 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO Channel 05 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 05 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO Channel 10 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO Channel 05 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO Channel 06 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 10 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 06 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Channel 10 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO Channel 10 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO Channel 10 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Channel 06 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 06 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO Channel 06 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO Channel 10 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO Channel 10 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO Channel 06 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 06 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO Channel 10 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO Channel 06 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 11 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 11 : 0[170] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO Channel 06 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO Channel 06 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO Channel 11 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Channel 06 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 06 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Channel 11 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO Channel 11 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO Channel 06 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO Channel 11 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO Channel 11 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 06 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO Channel 06 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO Channel 11 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO Channel 11 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO Channel 07 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 11 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 07 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO Channel 07 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Channel 07 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 07 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Channel 11 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO Channel 11 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO Channel 11 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO Channel 07 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO Channel 11 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO comm 0x5595f65cb8e0 rank 1 nranks 8 cudaDev 1 busId 180 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 07 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO Channel 11 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO Channel 07 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO comm 0x55c74c5eaad0 rank 0 nranks 8 cudaDev 0 busId 170 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO comm 0x55a5c7282520 rank 2 nranks 8 cudaDev 2 busId 190 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO comm 0x5561fb6d37d0 rank 3 nranks 8 cudaDev 3 busId 1a0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO comm 0x557248604030 rank 4 nranks 8 cudaDev 4 busId 1b0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO comm 0x565077439250 rank 5 nranks 8 cudaDev 5 busId 1c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO comm 0x55e61679acd0 rank 6 nranks 8 cudaDev 6 busId 1d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO comm 0x55ee6c09a950 rank 7 nranks 8 cudaDev 7 busId 1e0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO Channel 07 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO Channel 07 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 07 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Channel 07 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO Channel 07 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 07 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO Channel 07 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO Channel 08 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 08 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO Channel 08 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Channel 08 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 08 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO Channel 08 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 08 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO Channel 08 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Channel 08 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO Channel 08 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO Channel 08 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 08 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO Channel 08 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 08 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO Channel 08 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Channel 09 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 09 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO Channel 09 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO Channel 09 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 09 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO Channel 09 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 09 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO Channel 09 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Channel 09 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO Channel 09 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO Channel 09 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 09 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO Channel 09 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 09 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO Channel 09 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Channel 10 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 10 : 0[170] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO Channel 10 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO Channel 10 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 10 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO Channel 10 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 10 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO Channel 10 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 10 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Channel 10 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO Channel 10 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO Channel 10 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO Channel 10 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 10 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO Channel 10 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 11 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 11 : 0[170] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO Channel 11 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Channel 11 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO Channel 11 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO Channel 11 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 11 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO Channel 11 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO Channel 11 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 11 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Channel 11 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO Channel 11 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO Channel 11 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 11 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO Channel 11 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO comm 0x55a2a48d07c0 rank 1 nranks 8 cudaDev 1 busId 180 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO comm 0x555656073300 rank 0 nranks 8 cudaDev 0 busId 170 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO comm 0x5636ee46aab0 rank 3 nranks 8 cudaDev 3 busId 1a0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO comm 0x55bacbb91870 rank 4 nranks 8 cudaDev 4 busId 1b0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO comm 0x55ab35f53170 rank 2 nranks 8 cudaDev 2 busId 190 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO comm 0x55dab159b900 rank 5 nranks 8 cudaDev 5 busId 1c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO comm 0x564345f9e710 rank 7 nranks 8 cudaDev 7 busId 1e0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO comm 0x558809d6a030 rank 6 nranks 8 cudaDev 6 busId 1d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Trees [0] 4/-1/-1->7->6|6->7->4/-1/-1 [1] 4/-1/-1->7->6|6->7->4/-1/-1\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Trees [0] 1/-1/-1->2->3|3->2->1/-1/-1 [1] 1/-1/-1->2->3|3->2->1/-1/-1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 00/02 :    0   3   2   1   5   6   7   4   8  11  10   9  13  14  15  12\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 01/02 :    0   3   2   1   5   6   7   4   8  11  10   9  13  14  15  12\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO Trees [0] 5/-1/-1->1->2|2->1->5/-1/-1 [1] 5/-1/-1->1->2|2->1->5/-1/-1\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Trees [0] 2/8/-1->3->0|0->3->2/8/-1 [1] 2/-1/-1->3->0|0->3->2/-1/-1\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO Trees [0] -1/-1/-1->4->7|7->4->-1/-1/-1 [1] -1/-1/-1->4->7|7->4->-1/-1/-1\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO Trees [0] 6/-1/-1->5->1|1->5->6/-1/-1 [1] 6/-1/-1->5->1|1->5->6/-1/-1\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO Trees [0] 7/-1/-1->6->5|5->6->7/-1/-1 [1] 7/-1/-1->6->5|5->6->7/-1/-1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Trees [0] 3/-1/-1->0->-1|-1->0->3/-1/-1 [1] 3/-1/-1->0->11|11->0->3/-1/-1\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO Trees [0] 14/-1/-1->13->9|9->13->14/-1/-1 [1] 14/-1/-1->13->9|9->13->14/-1/-1\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO Trees [0] -1/-1/-1->12->15|15->12->-1/-1/-1 [1] -1/-1/-1->12->15|15->12->-1/-1/-1\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Trees [0] 9/-1/-1->10->11|11->10->9/-1/-1 [1] 9/-1/-1->10->11|11->10->9/-1/-1\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO Trees [0] 13/-1/-1->9->10|10->9->13/-1/-1 [1] 13/-1/-1->9->10|10->9->13/-1/-1\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Trees [0] 11/-1/-1->8->3|3->8->11/-1/-1 [1] 11/-1/-1->8->-1|-1->8->11/-1/-1\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO Trees [0] 15/-1/-1->14->13|13->14->15/-1/-1 [1] 15/-1/-1->14->13|13->14->15/-1/-1\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Trees [0] 10/-1/-1->11->8|8->11->10/-1/-1 [1] 10/0/-1->11->8|8->11->10/0/-1\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO Trees [0] 12/-1/-1->15->14|14->15->12/-1/-1 [1] 12/-1/-1->15->14|14->15->12/-1/-1\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 00 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO Channel 00 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 00 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO Channel 00 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO Channel 00 : 13[1c0] -> 14[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO Channel 00 : 14[1d0] -> 15[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Channel 00 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO Channel 00 : 15[1e0] -> 12[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO Channel 00 : 9[180] -> 13[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Channel 00 : 11[1a0] -> 10[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO Channel 00 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 00 : 10[190] -> 9[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 00 : 12[1b0] -> 0[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 00 : 4[1b0] -> 8[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO Channel 00 : 4[1b0] -> 8[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO Channel 00 : 12[1b0] -> 0[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 00 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 00 : 8[170] -> 11[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 00 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO Channel 00 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO Channel 00 : 13[1c0] -> 9[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 00 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO Channel 00 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO Channel 00 : 14[1d0] -> 13[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO Channel 00 : 9[180] -> 10[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO Channel 00 : 15[1e0] -> 14[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO Channel 00 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 00 : 10[190] -> 11[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO Channel 00 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO Channel 00 : 12[1b0] -> 15[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Channel 00 : 11[1a0] -> 8[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Channel 00 : 8[170] -> 3[1a0] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 00 : 8[170] -> 3[1a0] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 01 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO Channel 01 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO Channel 01 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 01 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Channel 00 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO Channel 01 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO Channel 01 : 13[1c0] -> 14[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO Channel 01 : 14[1d0] -> 15[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO Channel 01 : 9[180] -> 13[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO Channel 01 : 15[1e0] -> 12[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 01 : 10[190] -> 9[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO Channel 01 : 4[1b0] -> 8[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Channel 01 : 11[1a0] -> 10[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO Channel 01 : 12[1b0] -> 0[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO Channel 01 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO Channel 01 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO Channel 01 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO Channel 01 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 01 : 12[1b0] -> 0[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 00 : 3[1a0] -> 8[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO Channel 01 : 13[1c0] -> 9[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:104:104 [5] NCCL INFO comm 0x55dab426e660 rank 5 nranks 16 cudaDev 5 busId 1c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO Channel 01 : 14[1d0] -> 13[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 01 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO Channel 01 : 9[180] -> 10[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO Channel 01 : 15[1e0] -> 14[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:102:102 [6] NCCL INFO comm 0x55880ca3cd90 rank 6 nranks 16 cudaDev 6 busId 1d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Channel 00 : 3[1a0] -> 8[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO Channel 01 : 10[190] -> 11[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:algo-2:115:115 [5] NCCL INFO comm 0x56507a10bfb0 rank 13 nranks 16 cudaDev 5 busId 1c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:algo-2:110:110 [6] NCCL INFO comm 0x55e61946da30 rank 14 nranks 16 cudaDev 6 busId 1d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:algo-2:114:114 [1] NCCL INFO comm 0x5595f929e640 rank 9 nranks 16 cudaDev 1 busId 180 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO Channel 01 : 12[1b0] -> 15[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Channel 01 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:algo-2:111:111 [7] NCCL INFO comm 0x55ee6ed6d6b0 rank 15 nranks 16 cudaDev 7 busId 1e0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:algo-2:108:108 [4] NCCL INFO comm 0x5572486d9460 rank 12 nranks 16 cudaDev 4 busId 1b0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO Channel 01 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO Channel 01 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:101:101 [1] NCCL INFO comm 0x55a2a75a3520 rank 1 nranks 16 cudaDev 1 busId 180 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 01 : 4[1b0] -> 8[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:100:100 [2] NCCL INFO comm 0x55ab38c25ed0 rank 2 nranks 16 cudaDev 2 busId 190 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO Channel 01 : 8[170] -> 11[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:105:105 [3] NCCL INFO comm 0x5636f113d810 rank 3 nranks 16 cudaDev 3 busId 1a0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 01 : 0[170] -> 11[1a0] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO Channel 01 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:algo-2:116:116 [2] NCCL INFO comm 0x55a5c9f55280 rank 10 nranks 16 cudaDev 2 busId 190 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:103:103 [7] NCCL INFO comm 0x564348c71470 rank 7 nranks 16 cudaDev 7 busId 1e0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:106:106 [4] NCCL INFO comm 0x55bace8645d0 rank 4 nranks 16 cudaDev 4 busId 1b0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Channel 01 : 0[170] -> 11[1a0] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Channel 01 : 11[1a0] -> 8[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:137 [0] NCCL INFO comm 0x55c74f2bd830 rank 8 nranks 16 cudaDev 0 busId 170 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO Channel 01 : 11[1a0] -> 0[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO Channel 01 : 11[1a0] -> 0[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:128 [0] NCCL INFO comm 0x555656148730 rank 0 nranks 16 cudaDev 0 busId 170 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:algo-2:117:117 [3] NCCL INFO comm 0x5561fe3a6530 rank 11 nranks 16 cudaDev 3 busId 1a0 - Init COMPLETE\u001b[0m\n",
      "\n",
      "2021-09-27 14:12:19 Training - Training image download completed. Training in progress.\u001b[34m[1,10]<stdout>:batch_size: 8\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:batch_size: 8\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:batch_size: 8\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:batch_size: 8\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:batch_size: 8\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:local_rank: 2\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:Get train data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:local_rank: 6\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:Get train data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:batch_size: 8\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:batch_size: 8\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:batch_size: 8\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:batch_size: 8\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:local_rank: 5\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Get train data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:local_rank: 5\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:Get train data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:batch_size: 8\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:batch_size: 8\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:local_rank: 7\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:Get train data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:local_rank: 3\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:Get train data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:local_rank: 1\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:Get train data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:local_rank: 4\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:Get train data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:local_rank: 0\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:Get train data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Running smdistributed.dataparallel v1.2.0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:################################\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Global batch size: 128\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:batch_size: 8\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:local_rank: 7\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Get train data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:batch_size: 8\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:local_rank: 2\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Get train data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:batch_size: 8\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:batch_size: 8\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:local_rank: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Get train data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:local_rank: 1\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Get train data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:batch_size: 8\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:local_rank: 3\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Get train data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:local_rank: 6\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Get train data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:local_rank: 4\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Get train data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:Get test data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:Get test data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:Get test data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:Get test data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:Get test data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:Get test data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:Get test data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:Get test data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Get test data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Get test data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Get test data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Get test data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Get test data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Get test data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Get test data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Get test data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:Processes 3125/50000 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:Processes 625/10000 (6%) of test data\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:Processes 3125/50000 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:Processes 625/10000 (6%) of test data\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:Processes 3125/50000 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:Processes 625/10000 (6%) of test data\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:Processes 3125/50000 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:Processes 625/10000 (6%) of test data\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:Processes 3125/50000 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:Processes 625/10000 (6%) of test data\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:Processes 3125/50000 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:Processes 625/10000 (6%) of test data\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:Processes 3125/50000 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:Processes 625/10000 (6%) of test data\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:Processes 3125/50000 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:Processes 625/10000 (6%) of test data\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Processes 3125/50000 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Processes 625/10000 (6%) of test data\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:815 [0] NCCL INFO Launch mode Parallel\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Processes 3125/50000 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Processes 625/10000 (6%) of test data\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Processes 3125/50000 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Processes 625/10000 (6%) of test data\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Processes 3125/50000 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Processes 625/10000 (6%) of test data\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Processes 3125/50000 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Processes 625/10000 (6%) of test data\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Processes 3125/50000 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Processes 625/10000 (6%) of test data\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Processes 3125/50000 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Processes 625/10000 (6%) of test data\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Processes 3125/50000 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Processes 625/10000 (6%) of test data\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Model loaded\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Model loaded\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Model loaded\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Model loaded\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Model loaded\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Model loaded\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Model loaded\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Model loaded\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:Model loaded\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:Model loaded\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:Model loaded\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:Model loaded\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:Model loaded\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:Model loaded\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:Model loaded\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:Model loaded\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [0/50000 (0%)]#011Loss: 2.253693\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:algo-2:137:855 [0] NCCL INFO Launch mode Parallel\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:128:807 [0] NCCL INFO Launch mode Parallel\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [1280/50000 (3%)]#011Loss: 2.343857\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [2560/50000 (5%)]#011Loss: 2.366197\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [3840/50000 (8%)]#011Loss: 2.301844\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [5120/50000 (10%)]#011Loss: 2.329311\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [6400/50000 (13%)]#011Loss: 2.302205\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [7680/50000 (15%)]#011Loss: 2.313409\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [8960/50000 (18%)]#011Loss: 2.301315\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [10240/50000 (20%)]#011Loss: 2.272819\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [11520/50000 (23%)]#011Loss: 2.322852\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [12800/50000 (26%)]#011Loss: 2.300710\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [14080/50000 (28%)]#011Loss: 2.263649\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [15360/50000 (31%)]#011Loss: 2.313386\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [16640/50000 (33%)]#011Loss: 2.272738\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [17920/50000 (36%)]#011Loss: 2.266257\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [19200/50000 (38%)]#011Loss: 2.306643\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [20480/50000 (41%)]#011Loss: 2.323616\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [21760/50000 (43%)]#011Loss: 2.291470\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [23040/50000 (46%)]#011Loss: 2.267130\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [24320/50000 (49%)]#011Loss: 2.345048\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [25600/50000 (51%)]#011Loss: 2.258129\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [26880/50000 (54%)]#011Loss: 2.303110\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [28160/50000 (56%)]#011Loss: 2.325439\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [29440/50000 (59%)]#011Loss: 2.294759\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [30720/50000 (61%)]#011Loss: 2.268122\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [32000/50000 (64%)]#011Loss: 2.330220\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [33280/50000 (66%)]#011Loss: 2.280889\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [34560/50000 (69%)]#011Loss: 2.312458\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [35840/50000 (72%)]#011Loss: 2.294357\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [37120/50000 (74%)]#011Loss: 2.289084\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [38400/50000 (77%)]#011Loss: 2.304573\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [39680/50000 (79%)]#011Loss: 2.310912\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [40960/50000 (82%)]#011Loss: 2.307283\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [42240/50000 (84%)]#011Loss: 2.303876\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [43520/50000 (87%)]#011Loss: 2.280834\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [44800/50000 (90%)]#011Loss: 2.262415\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [46080/50000 (92%)]#011Loss: 2.304634\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [47360/50000 (95%)]#011Loss: 2.362291\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [48640/50000 (97%)]#011Loss: 2.268525\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [31200/50000 (100%)]#011Loss: 2.344420\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: -0.0022, Accuracy: 98/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [0/50000 (0%)]#011Loss: 2.254145\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [1280/50000 (3%)]#011Loss: 2.333709\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [2560/50000 (5%)]#011Loss: 2.348256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [3840/50000 (8%)]#011Loss: 2.296837\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [5120/50000 (10%)]#011Loss: 2.323070\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [6400/50000 (13%)]#011Loss: 2.298296\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [7680/50000 (15%)]#011Loss: 2.307587\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [8960/50000 (18%)]#011Loss: 2.297767\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [10240/50000 (20%)]#011Loss: 2.271079\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [11520/50000 (23%)]#011Loss: 2.314381\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [12800/50000 (26%)]#011Loss: 2.293828\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [14080/50000 (28%)]#011Loss: 2.262182\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [15360/50000 (31%)]#011Loss: 2.299406\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [16640/50000 (33%)]#011Loss: 2.273102\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [17920/50000 (36%)]#011Loss: 2.266506\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [19200/50000 (38%)]#011Loss: 2.307146\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [20480/50000 (41%)]#011Loss: 2.316753\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [21760/50000 (43%)]#011Loss: 2.284463\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [23040/50000 (46%)]#011Loss: 2.261146\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [24320/50000 (49%)]#011Loss: 2.342928\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [25600/50000 (51%)]#011Loss: 2.256443\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [26880/50000 (54%)]#011Loss: 2.294004\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [28160/50000 (56%)]#011Loss: 2.318116\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [29440/50000 (59%)]#011Loss: 2.293027\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [30720/50000 (61%)]#011Loss: 2.260551\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [32000/50000 (64%)]#011Loss: 2.319412\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [33280/50000 (66%)]#011Loss: 2.271881\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [34560/50000 (69%)]#011Loss: 2.302403\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [35840/50000 (72%)]#011Loss: 2.293130\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [37120/50000 (74%)]#011Loss: 2.288063\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [38400/50000 (77%)]#011Loss: 2.300904\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [39680/50000 (79%)]#011Loss: 2.308701\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [40960/50000 (82%)]#011Loss: 2.300639\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [42240/50000 (84%)]#011Loss: 2.285542\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [43520/50000 (87%)]#011Loss: 2.278069\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [44800/50000 (90%)]#011Loss: 2.258228\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [46080/50000 (92%)]#011Loss: 2.286201\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [47360/50000 (95%)]#011Loss: 2.358433\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [48640/50000 (97%)]#011Loss: 2.259420\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [31200/50000 (100%)]#011Loss: 2.334490\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: -0.0029, Accuracy: 111/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [0/50000 (0%)]#011Loss: 2.237061\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [1280/50000 (3%)]#011Loss: 2.318178\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [2560/50000 (5%)]#011Loss: 2.324427\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [3840/50000 (8%)]#011Loss: 2.286254\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [5120/50000 (10%)]#011Loss: 2.316817\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [6400/50000 (13%)]#011Loss: 2.289810\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [7680/50000 (15%)]#011Loss: 2.296616\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [8960/50000 (18%)]#011Loss: 2.291577\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [10240/50000 (20%)]#011Loss: 2.261294\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [11520/50000 (23%)]#011Loss: 2.306377\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [12800/50000 (26%)]#011Loss: 2.275026\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [14080/50000 (28%)]#011Loss: 2.250769\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [15360/50000 (31%)]#011Loss: 2.273229\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [16640/50000 (33%)]#011Loss: 2.261906\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [17920/50000 (36%)]#011Loss: 2.257539\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [19200/50000 (38%)]#011Loss: 2.308421\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [20480/50000 (41%)]#011Loss: 2.305005\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [21760/50000 (43%)]#011Loss: 2.269002\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [23040/50000 (46%)]#011Loss: 2.241260\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [24320/50000 (49%)]#011Loss: 2.349605\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [25600/50000 (51%)]#011Loss: 2.244497\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [26880/50000 (54%)]#011Loss: 2.272132\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [28160/50000 (56%)]#011Loss: 2.308155\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [29440/50000 (59%)]#011Loss: 2.288120\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [30720/50000 (61%)]#011Loss: 2.239300\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [32000/50000 (64%)]#011Loss: 2.306496\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [33280/50000 (66%)]#011Loss: 2.252958\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [34560/50000 (69%)]#011Loss: 2.283939\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [35840/50000 (72%)]#011Loss: 2.286483\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [37120/50000 (74%)]#011Loss: 2.279532\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [38400/50000 (77%)]#011Loss: 2.294198\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [39680/50000 (79%)]#011Loss: 2.307379\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [40960/50000 (82%)]#011Loss: 2.285506\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [42240/50000 (84%)]#011Loss: 2.251933\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [43520/50000 (87%)]#011Loss: 2.266656\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [44800/50000 (90%)]#011Loss: 2.236522\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [46080/50000 (92%)]#011Loss: 2.253339\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [47360/50000 (95%)]#011Loss: 2.353157\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [48640/50000 (97%)]#011Loss: 2.242848\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [31200/50000 (100%)]#011Loss: 2.317535\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: -0.0042, Accuracy: 112/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [0/50000 (0%)]#011Loss: 2.202903\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [1280/50000 (3%)]#011Loss: 2.289966\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [2560/50000 (5%)]#011Loss: 2.287710\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [3840/50000 (8%)]#011Loss: 2.259703\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [5120/50000 (10%)]#011Loss: 2.307101\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [6400/50000 (13%)]#011Loss: 2.266511\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [7680/50000 (15%)]#011Loss: 2.280638\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [8960/50000 (18%)]#011Loss: 2.272360\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [10240/50000 (20%)]#011Loss: 2.241750\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [11520/50000 (23%)]#011Loss: 2.296809\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [12800/50000 (26%)]#011Loss: 2.244737\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [14080/50000 (28%)]#011Loss: 2.232125\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [15360/50000 (31%)]#011Loss: 2.235546\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [16640/50000 (33%)]#011Loss: 2.237092\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [17920/50000 (36%)]#011Loss: 2.232618\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [19200/50000 (38%)]#011Loss: 2.312104\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [20480/50000 (41%)]#011Loss: 2.296811\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [21760/50000 (43%)]#011Loss: 2.247354\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [23040/50000 (46%)]#011Loss: 2.208507\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [24320/50000 (49%)]#011Loss: 2.370838\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [25600/50000 (51%)]#011Loss: 2.222202\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [26880/50000 (54%)]#011Loss: 2.242375\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [28160/50000 (56%)]#011Loss: 2.305491\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [29440/50000 (59%)]#011Loss: 2.281500\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [30720/50000 (61%)]#011Loss: 2.201103\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [32000/50000 (64%)]#011Loss: 2.284583\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [33280/50000 (66%)]#011Loss: 2.224406\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [34560/50000 (69%)]#011Loss: 2.254448\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [35840/50000 (72%)]#011Loss: 2.269166\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [37120/50000 (74%)]#011Loss: 2.260447\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [38400/50000 (77%)]#011Loss: 2.276155\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [39680/50000 (79%)]#011Loss: 2.297436\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [40960/50000 (82%)]#011Loss: 2.254827\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [42240/50000 (84%)]#011Loss: 2.209441\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [43520/50000 (87%)]#011Loss: 2.249086\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [44800/50000 (90%)]#011Loss: 2.198784\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [46080/50000 (92%)]#011Loss: 2.209044\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [47360/50000 (95%)]#011Loss: 2.334600\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [48640/50000 (97%)]#011Loss: 2.218639\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [31200/50000 (100%)]#011Loss: 2.283325\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: -0.0062, Accuracy: 117/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [0/50000 (0%)]#011Loss: 2.157276\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [1280/50000 (3%)]#011Loss: 2.248417\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [2560/50000 (5%)]#011Loss: 2.243589\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [3840/50000 (8%)]#011Loss: 2.218953\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [5120/50000 (10%)]#011Loss: 2.296763\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [6400/50000 (13%)]#011Loss: 2.228908\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [7680/50000 (15%)]#011Loss: 2.261876\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [8960/50000 (18%)]#011Loss: 2.248412\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [10240/50000 (20%)]#011Loss: 2.217420\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [11520/50000 (23%)]#011Loss: 2.289137\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [12800/50000 (26%)]#011Loss: 2.208497\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [14080/50000 (28%)]#011Loss: 2.208773\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [15360/50000 (31%)]#011Loss: 2.195998\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [16640/50000 (33%)]#011Loss: 2.208681\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [17920/50000 (36%)]#011Loss: 2.197752\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [19200/50000 (38%)]#011Loss: 2.312428\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [20480/50000 (41%)]#011Loss: 2.289293\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [21760/50000 (43%)]#011Loss: 2.228710\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [23040/50000 (46%)]#011Loss: 2.166044\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [24320/50000 (49%)]#011Loss: 2.401009\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [25600/50000 (51%)]#011Loss: 2.194744\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [26880/50000 (54%)]#011Loss: 2.211448\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [28160/50000 (56%)]#011Loss: 2.307012\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [29440/50000 (59%)]#011Loss: 2.276068\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [30720/50000 (61%)]#011Loss: 2.153710\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [32000/50000 (64%)]#011Loss: 2.250316\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [33280/50000 (66%)]#011Loss: 2.196454\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [34560/50000 (69%)]#011Loss: 2.219683\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [35840/50000 (72%)]#011Loss: 2.243715\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [37120/50000 (74%)]#011Loss: 2.242316\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [38400/50000 (77%)]#011Loss: 2.256040\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [39680/50000 (79%)]#011Loss: 2.276175\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [40960/50000 (82%)]#011Loss: 2.218805\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [42240/50000 (84%)]#011Loss: 2.166911\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [43520/50000 (87%)]#011Loss: 2.233311\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [44800/50000 (90%)]#011Loss: 2.160143\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [46080/50000 (92%)]#011Loss: 2.162106\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [47360/50000 (95%)]#011Loss: 2.309009\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [48640/50000 (97%)]#011Loss: 2.193876\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [31200/50000 (100%)]#011Loss: 2.242270\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: -0.0084, Accuracy: 116/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [0/50000 (0%)]#011Loss: 2.114303\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [1280/50000 (3%)]#011Loss: 2.205507\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [2560/50000 (5%)]#011Loss: 2.201748\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [3840/50000 (8%)]#011Loss: 2.175251\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [5120/50000 (10%)]#011Loss: 2.285529\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [6400/50000 (13%)]#011Loss: 2.188340\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [7680/50000 (15%)]#011Loss: 2.243380\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [8960/50000 (18%)]#011Loss: 2.228843\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [10240/50000 (20%)]#011Loss: 2.195707\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [11520/50000 (23%)]#011Loss: 2.280671\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [12800/50000 (26%)]#011Loss: 2.177540\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [14080/50000 (28%)]#011Loss: 2.188812\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [15360/50000 (31%)]#011Loss: 2.165732\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [16640/50000 (33%)]#011Loss: 2.183316\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [17920/50000 (36%)]#011Loss: 2.162889\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [19200/50000 (38%)]#011Loss: 2.309612\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [20480/50000 (41%)]#011Loss: 2.282012\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [21760/50000 (43%)]#011Loss: 2.214628\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [23040/50000 (46%)]#011Loss: 2.127238\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [24320/50000 (49%)]#011Loss: 2.433279\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [25600/50000 (51%)]#011Loss: 2.166882\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [26880/50000 (54%)]#011Loss: 2.184994\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [28160/50000 (56%)]#011Loss: 2.308601\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [29440/50000 (59%)]#011Loss: 2.271933\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [30720/50000 (61%)]#011Loss: 2.112073\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [32000/50000 (64%)]#011Loss: 2.211695\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [33280/50000 (66%)]#011Loss: 2.175882\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [34560/50000 (69%)]#011Loss: 2.189354\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [35840/50000 (72%)]#011Loss: 2.216334\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [37120/50000 (74%)]#011Loss: 2.228229\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [38400/50000 (77%)]#011Loss: 2.238055\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [39680/50000 (79%)]#011Loss: 2.251104\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [40960/50000 (82%)]#011Loss: 2.187371\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [42240/50000 (84%)]#011Loss: 2.132071\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [43520/50000 (87%)]#011Loss: 2.222913\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [44800/50000 (90%)]#011Loss: 2.128742\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [46080/50000 (92%)]#011Loss: 2.121405\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [47360/50000 (95%)]#011Loss: 2.283782\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [48640/50000 (97%)]#011Loss: 2.173453\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [31200/50000 (100%)]#011Loss: 2.205916\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: -0.0103, Accuracy: 119/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [0/50000 (0%)]#011Loss: 2.082009\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [1280/50000 (3%)]#011Loss: 2.169352\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [2560/50000 (5%)]#011Loss: 2.168563\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [3840/50000 (8%)]#011Loss: 2.137569\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [5120/50000 (10%)]#011Loss: 2.276169\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [6400/50000 (13%)]#011Loss: 2.156558\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [7680/50000 (15%)]#011Loss: 2.226261\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [8960/50000 (18%)]#011Loss: 2.214691\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [10240/50000 (20%)]#011Loss: 2.179703\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [11520/50000 (23%)]#011Loss: 2.271428\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [12800/50000 (26%)]#011Loss: 2.153667\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [14080/50000 (28%)]#011Loss: 2.175020\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [15360/50000 (31%)]#011Loss: 2.145727\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [16640/50000 (33%)]#011Loss: 2.166379\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [17920/50000 (36%)]#011Loss: 2.136184\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [19200/50000 (38%)]#011Loss: 2.306198\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [20480/50000 (41%)]#011Loss: 2.276931\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [21760/50000 (43%)]#011Loss: 2.205497\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [23040/50000 (46%)]#011Loss: 2.097076\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [24320/50000 (49%)]#011Loss: 2.460544\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [25600/50000 (51%)]#011Loss: 2.145754\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [26880/50000 (54%)]#011Loss: 2.166131\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [28160/50000 (56%)]#011Loss: 2.310502\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [29440/50000 (59%)]#011Loss: 2.269746\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [30720/50000 (61%)]#011Loss: 2.082436\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [32000/50000 (64%)]#011Loss: 2.179208\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [33280/50000 (66%)]#011Loss: 2.164613\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [34560/50000 (69%)]#011Loss: 2.165454\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [35840/50000 (72%)]#011Loss: 2.194448\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [37120/50000 (74%)]#011Loss: 2.219587\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [38400/50000 (77%)]#011Loss: 2.223562\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [39680/50000 (79%)]#011Loss: 2.228626\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [40960/50000 (82%)]#011Loss: 2.162610\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [42240/50000 (84%)]#011Loss: 2.105654\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [43520/50000 (87%)]#011Loss: 2.217144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [44800/50000 (90%)]#011Loss: 2.106286\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [46080/50000 (92%)]#011Loss: 2.089115\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [47360/50000 (95%)]#011Loss: 2.262179\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [48640/50000 (97%)]#011Loss: 2.159006\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [31200/50000 (100%)]#011Loss: 2.177566\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: -0.0119, Accuracy: 121/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [0/50000 (0%)]#011Loss: 2.059561\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [1280/50000 (3%)]#011Loss: 2.141825\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [2560/50000 (5%)]#011Loss: 2.144012\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [3840/50000 (8%)]#011Loss: 2.109859\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [5120/50000 (10%)]#011Loss: 2.269568\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [6400/50000 (13%)]#011Loss: 2.134207\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [7680/50000 (15%)]#011Loss: 2.212184\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [8960/50000 (18%)]#011Loss: 2.205456\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [10240/50000 (20%)]#011Loss: 2.168995\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [11520/50000 (23%)]#011Loss: 2.262732\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [12800/50000 (26%)]#011Loss: 2.136319\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [14080/50000 (28%)]#011Loss: 2.165730\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [15360/50000 (31%)]#011Loss: 2.133888\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [16640/50000 (33%)]#011Loss: 2.156258\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [17920/50000 (36%)]#011Loss: 2.117682\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [19200/50000 (38%)]#011Loss: 2.302702\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [20480/50000 (41%)]#011Loss: 2.273320\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [21760/50000 (43%)]#011Loss: 2.200193\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [23040/50000 (46%)]#011Loss: 2.074775\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [24320/50000 (49%)]#011Loss: 2.480388\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [25600/50000 (51%)]#011Loss: 2.131252\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [26880/50000 (54%)]#011Loss: 2.152730\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [28160/50000 (56%)]#011Loss: 2.312103\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [29440/50000 (59%)]#011Loss: 2.268481\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [30720/50000 (61%)]#011Loss: 2.062184\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [32000/50000 (64%)]#011Loss: 2.154088\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [33280/50000 (66%)]#011Loss: 2.159101\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [34560/50000 (69%)]#011Loss: 2.148403\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [35840/50000 (72%)]#011Loss: 2.178385\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [37120/50000 (74%)]#011Loss: 2.214633\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [38400/50000 (77%)]#011Loss: 2.212908\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [39680/50000 (79%)]#011Loss: 2.210366\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [40960/50000 (82%)]#011Loss: 2.144689\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [42240/50000 (84%)]#011Loss: 2.087234\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [43520/50000 (87%)]#011Loss: 2.214368\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [44800/50000 (90%)]#011Loss: 2.091053\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [46080/50000 (92%)]#011Loss: 2.064917\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [47360/50000 (95%)]#011Loss: 2.245067\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [48640/50000 (97%)]#011Loss: 2.149489\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [31200/50000 (100%)]#011Loss: 2.155840\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: -0.0131, Accuracy: 122/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [0/50000 (0%)]#011Loss: 2.044368\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [1280/50000 (3%)]#011Loss: 2.122692\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [2560/50000 (5%)]#011Loss: 2.125760\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [3840/50000 (8%)]#011Loss: 2.090341\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [5120/50000 (10%)]#011Loss: 2.265618\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [6400/50000 (13%)]#011Loss: 2.118737\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [7680/50000 (15%)]#011Loss: 2.201692\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [8960/50000 (18%)]#011Loss: 2.199059\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [10240/50000 (20%)]#011Loss: 2.161503\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [11520/50000 (23%)]#011Loss: 2.255660\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [12800/50000 (26%)]#011Loss: 2.124289\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [14080/50000 (28%)]#011Loss: 2.159611\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [15360/50000 (31%)]#011Loss: 2.127070\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [16640/50000 (33%)]#011Loss: 2.150126\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [17920/50000 (36%)]#011Loss: 2.105577\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [19200/50000 (38%)]#011Loss: 2.299679\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [20480/50000 (41%)]#011Loss: 2.270814\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [21760/50000 (43%)]#011Loss: 2.197062\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [23040/50000 (46%)]#011Loss: 2.058580\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [24320/50000 (49%)]#011Loss: 2.494277\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [25600/50000 (51%)]#011Loss: 2.121589\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [26880/50000 (54%)]#011Loss: 2.143171\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [28160/50000 (56%)]#011Loss: 2.312288\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [29440/50000 (59%)]#011Loss: 2.267777\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [30720/50000 (61%)]#011Loss: 2.048342\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [32000/50000 (64%)]#011Loss: 2.135722\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [33280/50000 (66%)]#011Loss: 2.156335\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [34560/50000 (69%)]#011Loss: 2.136862\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [35840/50000 (72%)]#011Loss: 2.167027\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [37120/50000 (74%)]#011Loss: 2.211721\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [38400/50000 (77%)]#011Loss: 2.205112\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [39680/50000 (79%)]#011Loss: 2.196461\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [40960/50000 (82%)]#011Loss: 2.132376\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [42240/50000 (84%)]#011Loss: 2.074054\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [43520/50000 (87%)]#011Loss: 2.213467\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [44800/50000 (90%)]#011Loss: 2.080797\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [46080/50000 (92%)]#011Loss: 2.047848\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [47360/50000 (95%)]#011Loss: 2.231983\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [48640/50000 (97%)]#011Loss: 2.142698\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [31200/50000 (100%)]#011Loss: 2.140028\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: -0.0139, Accuracy: 121/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [0/50000 (0%)]#011Loss: 2.033604\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [1280/50000 (3%)]#011Loss: 2.109673\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [2560/50000 (5%)]#011Loss: 2.113080\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [3840/50000 (8%)]#011Loss: 2.076701\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [5120/50000 (10%)]#011Loss: 2.262422\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [6400/50000 (13%)]#011Loss: 2.107980\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [7680/50000 (15%)]#011Loss: 2.193883\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [8960/50000 (18%)]#011Loss: 2.194618\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [10240/50000 (20%)]#011Loss: 2.156293\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [11520/50000 (23%)]#011Loss: 2.250303\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [12800/50000 (26%)]#011Loss: 2.115737\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [14080/50000 (28%)]#011Loss: 2.155357\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [15360/50000 (31%)]#011Loss: 2.122338\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [16640/50000 (33%)]#011Loss: 2.146011\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [17920/50000 (36%)]#011Loss: 2.097675\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [19200/50000 (38%)]#011Loss: 2.297411\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [20480/50000 (41%)]#011Loss: 2.268951\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [21760/50000 (43%)]#011Loss: 2.194896\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [23040/50000 (46%)]#011Loss: 2.047221\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [24320/50000 (49%)]#011Loss: 2.503833\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [25600/50000 (51%)]#011Loss: 2.115065\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [26880/50000 (54%)]#011Loss: 2.136583\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [28160/50000 (56%)]#011Loss: 2.312006\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [29440/50000 (59%)]#011Loss: 2.266946\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [30720/50000 (61%)]#011Loss: 2.039143\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [32000/50000 (64%)]#011Loss: 2.122925\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [33280/50000 (66%)]#011Loss: 2.154829\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [34560/50000 (69%)]#011Loss: 2.128927\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [35840/50000 (72%)]#011Loss: 2.159014\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [37120/50000 (74%)]#011Loss: 2.209991\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [38400/50000 (77%)]#011Loss: 2.199722\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [39680/50000 (79%)]#011Loss: 2.186321\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [40960/50000 (82%)]#011Loss: 2.123924\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [42240/50000 (84%)]#011Loss: 2.064996\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [43520/50000 (87%)]#011Loss: 2.213153\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [44800/50000 (90%)]#011Loss: 2.073951\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [46080/50000 (92%)]#011Loss: 2.035787\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [47360/50000 (95%)]#011Loss: 2.222392\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [48640/50000 (97%)]#011Loss: 2.137971\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [31200/50000 (100%)]#011Loss: 2.128777\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: -0.0145, Accuracy: 120/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [0/50000 (0%)]#011Loss: 2.025950\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [1280/50000 (3%)]#011Loss: 2.100760\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [2560/50000 (5%)]#011Loss: 2.104327\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [3840/50000 (8%)]#011Loss: 2.067286\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [5120/50000 (10%)]#011Loss: 2.260015\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [6400/50000 (13%)]#011Loss: 2.100693\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [7680/50000 (15%)]#011Loss: 2.188208\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [8960/50000 (18%)]#011Loss: 2.191298\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [10240/50000 (20%)]#011Loss: 2.152950\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [11520/50000 (23%)]#011Loss: 2.246325\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [12800/50000 (26%)]#011Loss: 2.109615\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [14080/50000 (28%)]#011Loss: 2.152287\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [15360/50000 (31%)]#011Loss: 2.119041\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [16640/50000 (33%)]#011Loss: 2.143123\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [17920/50000 (36%)]#011Loss: 2.092482\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [19200/50000 (38%)]#011Loss: 2.295818\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [20480/50000 (41%)]#011Loss: 2.267457\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [21760/50000 (43%)]#011Loss: 2.193540\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [23040/50000 (46%)]#011Loss: 2.039295\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [24320/50000 (49%)]#011Loss: 2.510344\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [25600/50000 (51%)]#011Loss: 2.110643\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [26880/50000 (54%)]#011Loss: 2.132091\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [28160/50000 (56%)]#011Loss: 2.311558\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [29440/50000 (59%)]#011Loss: 2.266122\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [30720/50000 (61%)]#011Loss: 2.032920\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [32000/50000 (64%)]#011Loss: 2.113924\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [33280/50000 (66%)]#011Loss: 2.154071\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [34560/50000 (69%)]#011Loss: 2.123488\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [35840/50000 (72%)]#011Loss: 2.153580\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [37120/50000 (74%)]#011Loss: 2.208948\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [38400/50000 (77%)]#011Loss: 2.195868\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [39680/50000 (79%)]#011Loss: 2.179015\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [40960/50000 (82%)]#011Loss: 2.118138\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [42240/50000 (84%)]#011Loss: 2.058828\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [43520/50000 (87%)]#011Loss: 2.212951\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [44800/50000 (90%)]#011Loss: 2.069318\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [46080/50000 (92%)]#011Loss: 2.027296\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [47360/50000 (95%)]#011Loss: 2.215672\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [48640/50000 (97%)]#011Loss: 2.134661\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [31200/50000 (100%)]#011Loss: 2.120921\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: -0.0149, Accuracy: 120/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [0/50000 (0%)]#011Loss: 2.020804\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [1280/50000 (3%)]#011Loss: 2.094645\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [2560/50000 (5%)]#011Loss: 2.098167\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [3840/50000 (8%)]#011Loss: 2.060816\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [5120/50000 (10%)]#011Loss: 2.258331\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [6400/50000 (13%)]#011Loss: 2.095703\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [7680/50000 (15%)]#011Loss: 2.184119\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [8960/50000 (18%)]#011Loss: 2.188989\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [10240/50000 (20%)]#011Loss: 2.150666\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [11520/50000 (23%)]#011Loss: 2.243319\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [12800/50000 (26%)]#011Loss: 2.105314\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [14080/50000 (28%)]#011Loss: 2.150057\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [15360/50000 (31%)]#011Loss: 2.116685\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [16640/50000 (33%)]#011Loss: 2.141190\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [17920/50000 (36%)]#011Loss: 2.089023\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [19200/50000 (38%)]#011Loss: 2.294683\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [20480/50000 (41%)]#011Loss: 2.266436\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [21760/50000 (43%)]#011Loss: 2.192595\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [23040/50000 (46%)]#011Loss: 2.033761\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [24320/50000 (49%)]#011Loss: 2.514794\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [25600/50000 (51%)]#011Loss: 2.107625\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [26880/50000 (54%)]#011Loss: 2.129054\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [28160/50000 (56%)]#011Loss: 2.311164\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [29440/50000 (59%)]#011Loss: 2.265480\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [30720/50000 (61%)]#011Loss: 2.028720\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [32000/50000 (64%)]#011Loss: 2.107643\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [33280/50000 (66%)]#011Loss: 2.153760\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [34560/50000 (69%)]#011Loss: 2.119628\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [35840/50000 (72%)]#011Loss: 2.149719\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [37120/50000 (74%)]#011Loss: 2.208308\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [38400/50000 (77%)]#011Loss: 2.193055\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [39680/50000 (79%)]#011Loss: 2.173783\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [40960/50000 (82%)]#011Loss: 2.114264\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [42240/50000 (84%)]#011Loss: 2.054626\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [43520/50000 (87%)]#011Loss: 2.212862\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [44800/50000 (90%)]#011Loss: 2.066128\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [46080/50000 (92%)]#011Loss: 2.021385\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [47360/50000 (95%)]#011Loss: 2.210918\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [48640/50000 (97%)]#011Loss: 2.132402\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [31200/50000 (100%)]#011Loss: 2.115370\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: -0.0152, Accuracy: 119/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [0/50000 (0%)]#011Loss: 2.017210\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [1280/50000 (3%)]#011Loss: 2.090425\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [2560/50000 (5%)]#011Loss: 2.093963\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [3840/50000 (8%)]#011Loss: 2.056330\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [5120/50000 (10%)]#011Loss: 2.257136\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [6400/50000 (13%)]#011Loss: 2.092243\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [7680/50000 (15%)]#011Loss: 2.181225\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [8960/50000 (18%)]#011Loss: 2.187269\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [10240/50000 (20%)]#011Loss: 2.149101\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [11520/50000 (23%)]#011Loss: 2.241134\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [12800/50000 (26%)]#011Loss: 2.102323\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [14080/50000 (28%)]#011Loss: 2.148396\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [15360/50000 (31%)]#011Loss: 2.115096\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [16640/50000 (33%)]#011Loss: 2.139978\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [17920/50000 (36%)]#011Loss: 2.086676\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [19200/50000 (38%)]#011Loss: 2.293880\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [20480/50000 (41%)]#011Loss: 2.265733\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [21760/50000 (43%)]#011Loss: 2.191953\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [23040/50000 (46%)]#011Loss: 2.029881\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [24320/50000 (49%)]#011Loss: 2.517868\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [25600/50000 (51%)]#011Loss: 2.105574\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [26880/50000 (54%)]#011Loss: 2.127095\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [28160/50000 (56%)]#011Loss: 2.310874\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [29440/50000 (59%)]#011Loss: 2.265030\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [30720/50000 (61%)]#011Loss: 2.025851\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [32000/50000 (64%)]#011Loss: 2.103249\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [33280/50000 (66%)]#011Loss: 2.153537\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [34560/50000 (69%)]#011Loss: 2.116946\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [35840/50000 (72%)]#011Loss: 2.147002\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [37120/50000 (74%)]#011Loss: 2.207877\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [38400/50000 (77%)]#011Loss: 2.191057\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [39680/50000 (79%)]#011Loss: 2.170133\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [40960/50000 (82%)]#011Loss: 2.111465\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [42240/50000 (84%)]#011Loss: 2.051707\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [43520/50000 (87%)]#011Loss: 2.212836\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [44800/50000 (90%)]#011Loss: 2.063945\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [46080/50000 (92%)]#011Loss: 2.017264\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [47360/50000 (95%)]#011Loss: 2.207563\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [48640/50000 (97%)]#011Loss: 2.130850\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [31200/50000 (100%)]#011Loss: 2.111395\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: -0.0155, Accuracy: 119/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [0/50000 (0%)]#011Loss: 2.014738\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [1280/50000 (3%)]#011Loss: 2.087503\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [2560/50000 (5%)]#011Loss: 2.090945\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [3840/50000 (8%)]#011Loss: 2.053218\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [5120/50000 (10%)]#011Loss: 2.256292\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [6400/50000 (13%)]#011Loss: 2.089825\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [7680/50000 (15%)]#011Loss: 2.179171\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [8960/50000 (18%)]#011Loss: 2.186050\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [10240/50000 (20%)]#011Loss: 2.148003\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [11520/50000 (23%)]#011Loss: 2.239562\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [12800/50000 (26%)]#011Loss: 2.100257\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [14080/50000 (28%)]#011Loss: 2.147231\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [15360/50000 (31%)]#011Loss: 2.114017\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [16640/50000 (33%)]#011Loss: 2.139128\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [17920/50000 (36%)]#011Loss: 2.085070\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [19200/50000 (38%)]#011Loss: 2.293322\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [20480/50000 (41%)]#011Loss: 2.265238\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [21760/50000 (43%)]#011Loss: 2.191516\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [23040/50000 (46%)]#011Loss: 2.027162\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [24320/50000 (49%)]#011Loss: 2.520029\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [25600/50000 (51%)]#011Loss: 2.104150\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [26880/50000 (54%)]#011Loss: 2.125777\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [28160/50000 (56%)]#011Loss: 2.310669\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [29440/50000 (59%)]#011Loss: 2.264751\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [30720/50000 (61%)]#011Loss: 2.023892\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [32000/50000 (64%)]#011Loss: 2.100148\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [33280/50000 (66%)]#011Loss: 2.153398\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [34560/50000 (69%)]#011Loss: 2.115085\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [35840/50000 (72%)]#011Loss: 2.145087\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [37120/50000 (74%)]#011Loss: 2.207607\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [38400/50000 (77%)]#011Loss: 2.189649\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [39680/50000 (79%)]#011Loss: 2.167578\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [40960/50000 (82%)]#011Loss: 2.109526\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [42240/50000 (84%)]#011Loss: 2.049675\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [43520/50000 (87%)]#011Loss: 2.212841\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [44800/50000 (90%)]#011Loss: 2.062436\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [46080/50000 (92%)]#011Loss: 2.014350\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [47360/50000 (95%)]#011Loss: 2.205201\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [48640/50000 (97%)]#011Loss: 2.129772\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [31200/50000 (100%)]#011Loss: 2.108609\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: -0.0156, Accuracy: 119/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [0/50000 (0%)]#011Loss: 2.013014\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [1280/50000 (3%)]#011Loss: 2.085480\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [2560/50000 (5%)]#011Loss: 2.088879\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [3840/50000 (8%)]#011Loss: 2.051100\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [5120/50000 (10%)]#011Loss: 2.255708\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [6400/50000 (13%)]#011Loss: 2.088162\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [7680/50000 (15%)]#011Loss: 2.177720\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [8960/50000 (18%)]#011Loss: 2.185190\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [10240/50000 (20%)]#011Loss: 2.147249\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [11520/50000 (23%)]#011Loss: 2.238435\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [12800/50000 (26%)]#011Loss: 2.098795\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [14080/50000 (28%)]#011Loss: 2.146422\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [15360/50000 (31%)]#011Loss: 2.113267\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [16640/50000 (33%)]#011Loss: 2.138517\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [17920/50000 (36%)]#011Loss: 2.083961\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [19200/50000 (38%)]#011Loss: 2.292959\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [20480/50000 (41%)]#011Loss: 2.264891\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [21760/50000 (43%)]#011Loss: 2.191221\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [23040/50000 (46%)]#011Loss: 2.025256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [24320/50000 (49%)]#011Loss: 2.521539\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [25600/50000 (51%)]#011Loss: 2.103165\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [26880/50000 (54%)]#011Loss: 2.124841\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [28160/50000 (56%)]#011Loss: 2.310517\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [29440/50000 (59%)]#011Loss: 2.264592\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [30720/50000 (61%)]#011Loss: 2.022542\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [32000/50000 (64%)]#011Loss: 2.097973\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [33280/50000 (66%)]#011Loss: 2.153312\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [34560/50000 (69%)]#011Loss: 2.113794\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [35840/50000 (72%)]#011Loss: 2.143745\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [37120/50000 (74%)]#011Loss: 2.207443\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [38400/50000 (77%)]#011Loss: 2.188662\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [39680/50000 (79%)]#011Loss: 2.165786\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [40960/50000 (82%)]#011Loss: 2.108180\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [42240/50000 (84%)]#011Loss: 2.048255\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [43520/50000 (87%)]#011Loss: 2.212856\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [44800/50000 (90%)]#011Loss: 2.061391\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [46080/50000 (92%)]#011Loss: 2.012316\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [47360/50000 (95%)]#011Loss: 2.203530\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [48640/50000 (97%)]#011Loss: 2.129022\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 15 [31200/50000 (100%)]#011Loss: 2.106661\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: -0.0157, Accuracy: 120/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [0/50000 (0%)]#011Loss: 2.011808\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [1280/50000 (3%)]#011Loss: 2.084071\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [2560/50000 (5%)]#011Loss: 2.087445\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [3840/50000 (8%)]#011Loss: 2.049635\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [5120/50000 (10%)]#011Loss: 2.255298\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [6400/50000 (13%)]#011Loss: 2.087010\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [7680/50000 (15%)]#011Loss: 2.176711\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [8960/50000 (18%)]#011Loss: 2.184580\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [10240/50000 (20%)]#011Loss: 2.146727\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [11520/50000 (23%)]#011Loss: 2.237640\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [12800/50000 (26%)]#011Loss: 2.097767\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [14080/50000 (28%)]#011Loss: 2.145852\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [15360/50000 (31%)]#011Loss: 2.112744\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [16640/50000 (33%)]#011Loss: 2.138082\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [17920/50000 (36%)]#011Loss: 2.083181\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [19200/50000 (38%)]#011Loss: 2.292706\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [20480/50000 (41%)]#011Loss: 2.264624\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [21760/50000 (43%)]#011Loss: 2.191017\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [23040/50000 (46%)]#011Loss: 2.023916\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [24320/50000 (49%)]#011Loss: 2.522583\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [25600/50000 (51%)]#011Loss: 2.102486\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [26880/50000 (54%)]#011Loss: 2.124193\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [28160/50000 (56%)]#011Loss: 2.310403\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [29440/50000 (59%)]#011Loss: 2.264478\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [30720/50000 (61%)]#011Loss: 2.021607\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [32000/50000 (64%)]#011Loss: 2.096451\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [33280/50000 (66%)]#011Loss: 2.153263\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [34560/50000 (69%)]#011Loss: 2.112895\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [35840/50000 (72%)]#011Loss: 2.142811\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [37120/50000 (74%)]#011Loss: 2.207334\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [38400/50000 (77%)]#011Loss: 2.187968\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [39680/50000 (79%)]#011Loss: 2.164537\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [40960/50000 (82%)]#011Loss: 2.107243\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [42240/50000 (84%)]#011Loss: 2.047266\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [43520/50000 (87%)]#011Loss: 2.212874\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [44800/50000 (90%)]#011Loss: 2.060676\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [46080/50000 (92%)]#011Loss: 2.010897\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [47360/50000 (95%)]#011Loss: 2.202353\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [48640/50000 (97%)]#011Loss: 2.128498\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 16 [31200/50000 (100%)]#011Loss: 2.105295\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: -0.0158, Accuracy: 120/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [0/50000 (0%)]#011Loss: 2.010966\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [1280/50000 (3%)]#011Loss: 2.083085\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [2560/50000 (5%)]#011Loss: 2.086444\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [3840/50000 (8%)]#011Loss: 2.048587\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [5120/50000 (10%)]#011Loss: 2.255012\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [6400/50000 (13%)]#011Loss: 2.086205\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [7680/50000 (15%)]#011Loss: 2.176011\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [8960/50000 (18%)]#011Loss: 2.184155\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [10240/50000 (20%)]#011Loss: 2.146366\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [11520/50000 (23%)]#011Loss: 2.237084\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [12800/50000 (26%)]#011Loss: 2.097047\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [14080/50000 (28%)]#011Loss: 2.145460\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [15360/50000 (31%)]#011Loss: 2.112384\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [16640/50000 (33%)]#011Loss: 2.137776\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [17920/50000 (36%)]#011Loss: 2.082637\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [19200/50000 (38%)]#011Loss: 2.292529\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [20480/50000 (41%)]#011Loss: 2.264426\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [21760/50000 (43%)]#011Loss: 2.190875\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [23040/50000 (46%)]#011Loss: 2.022979\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [24320/50000 (49%)]#011Loss: 2.523312\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [25600/50000 (51%)]#011Loss: 2.102015\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [26880/50000 (54%)]#011Loss: 2.123747\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [28160/50000 (56%)]#011Loss: 2.310324\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [29440/50000 (59%)]#011Loss: 2.264398\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [30720/50000 (61%)]#011Loss: 2.020957\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [32000/50000 (64%)]#011Loss: 2.095385\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [33280/50000 (66%)]#011Loss: 2.153229\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [34560/50000 (69%)]#011Loss: 2.112270\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [35840/50000 (72%)]#011Loss: 2.142157\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [37120/50000 (74%)]#011Loss: 2.207256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [38400/50000 (77%)]#011Loss: 2.187486\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [39680/50000 (79%)]#011Loss: 2.163666\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [40960/50000 (82%)]#011Loss: 2.106593\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [42240/50000 (84%)]#011Loss: 2.046577\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [43520/50000 (87%)]#011Loss: 2.212888\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [44800/50000 (90%)]#011Loss: 2.060177\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [46080/50000 (92%)]#011Loss: 2.009907\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [47360/50000 (95%)]#011Loss: 2.201529\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [48640/50000 (97%)]#011Loss: 2.128134\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 17 [31200/50000 (100%)]#011Loss: 2.104337\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: -0.0158, Accuracy: 120/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [0/50000 (0%)]#011Loss: 2.010378\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [1280/50000 (3%)]#011Loss: 2.082396\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [2560/50000 (5%)]#011Loss: 2.085739\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [3840/50000 (8%)]#011Loss: 2.047853\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [5120/50000 (10%)]#011Loss: 2.254817\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [6400/50000 (13%)]#011Loss: 2.085642\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [7680/50000 (15%)]#011Loss: 2.175520\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [8960/50000 (18%)]#011Loss: 2.183858\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [10240/50000 (20%)]#011Loss: 2.146116\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [11520/50000 (23%)]#011Loss: 2.236693\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [12800/50000 (26%)]#011Loss: 2.096546\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [14080/50000 (28%)]#011Loss: 2.145187\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [15360/50000 (31%)]#011Loss: 2.112138\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [16640/50000 (33%)]#011Loss: 2.137561\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [17920/50000 (36%)]#011Loss: 2.082258\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [19200/50000 (38%)]#011Loss: 2.292404\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [20480/50000 (41%)]#011Loss: 2.264287\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [21760/50000 (43%)]#011Loss: 2.190774\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [23040/50000 (46%)]#011Loss: 2.022323\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [24320/50000 (49%)]#011Loss: 2.523810\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [25600/50000 (51%)]#011Loss: 2.101687\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [26880/50000 (54%)]#011Loss: 2.123433\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [28160/50000 (56%)]#011Loss: 2.310277\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [29440/50000 (59%)]#011Loss: 2.264342\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [30720/50000 (61%)]#011Loss: 2.020501\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [32000/50000 (64%)]#011Loss: 2.094638\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [33280/50000 (66%)]#011Loss: 2.153223\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [34560/50000 (69%)]#011Loss: 2.111833\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [35840/50000 (72%)]#011Loss: 2.141701\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [37120/50000 (74%)]#011Loss: 2.207202\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [38400/50000 (77%)]#011Loss: 2.187152\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [39680/50000 (79%)]#011Loss: 2.163056\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [40960/50000 (82%)]#011Loss: 2.106144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [42240/50000 (84%)]#011Loss: 2.046094\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [43520/50000 (87%)]#011Loss: 2.212899\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [44800/50000 (90%)]#011Loss: 2.059829\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [46080/50000 (92%)]#011Loss: 2.009215\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [47360/50000 (95%)]#011Loss: 2.200951\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [48640/50000 (97%)]#011Loss: 2.127878\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 18 [31200/50000 (100%)]#011Loss: 2.103664\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: -0.0159, Accuracy: 121/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [0/50000 (0%)]#011Loss: 2.009967\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [1280/50000 (3%)]#011Loss: 2.081914\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [2560/50000 (5%)]#011Loss: 2.085245\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [3840/50000 (8%)]#011Loss: 2.047340\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [5120/50000 (10%)]#011Loss: 2.254682\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [6400/50000 (13%)]#011Loss: 2.085249\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [7680/50000 (15%)]#011Loss: 2.175177\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [8960/50000 (18%)]#011Loss: 2.183649\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [10240/50000 (20%)]#011Loss: 2.145941\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [11520/50000 (23%)]#011Loss: 2.236420\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [12800/50000 (26%)]#011Loss: 2.096195\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [14080/50000 (28%)]#011Loss: 2.144997\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [15360/50000 (31%)]#011Loss: 2.111969\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [16640/50000 (33%)]#011Loss: 2.137410\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [17920/50000 (36%)]#011Loss: 2.081991\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [19200/50000 (38%)]#011Loss: 2.292317\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [20480/50000 (41%)]#011Loss: 2.264190\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [21760/50000 (43%)]#011Loss: 2.190702\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [23040/50000 (46%)]#011Loss: 2.021861\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [24320/50000 (49%)]#011Loss: 2.524159\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [25600/50000 (51%)]#011Loss: 2.101458\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [26880/50000 (54%)]#011Loss: 2.123214\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [28160/50000 (56%)]#011Loss: 2.310243\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [29440/50000 (59%)]#011Loss: 2.264301\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [30720/50000 (61%)]#011Loss: 2.020182\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [32000/50000 (64%)]#011Loss: 2.094115\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [33280/50000 (66%)]#011Loss: 2.153222\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [34560/50000 (69%)]#011Loss: 2.111528\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [35840/50000 (72%)]#011Loss: 2.141380\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [37120/50000 (74%)]#011Loss: 2.207168\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [38400/50000 (77%)]#011Loss: 2.186919\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [39680/50000 (79%)]#011Loss: 2.162629\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [40960/50000 (82%)]#011Loss: 2.105830\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [42240/50000 (84%)]#011Loss: 2.045756\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [43520/50000 (87%)]#011Loss: 2.212908\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [44800/50000 (90%)]#011Loss: 2.059586\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [46080/50000 (92%)]#011Loss: 2.008729\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [47360/50000 (95%)]#011Loss: 2.200547\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [48640/50000 (97%)]#011Loss: 2.127699\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 19 [31200/50000 (100%)]#011Loss: 2.103194\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: -0.0159, Accuracy: 121/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [0/50000 (0%)]#011Loss: 2.009679\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [1280/50000 (3%)]#011Loss: 2.081578\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [2560/50000 (5%)]#011Loss: 2.084901\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [3840/50000 (8%)]#011Loss: 2.046979\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [5120/50000 (10%)]#011Loss: 2.254587\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [6400/50000 (13%)]#011Loss: 2.084977\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [7680/50000 (15%)]#011Loss: 2.174937\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [8960/50000 (18%)]#011Loss: 2.183502\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [10240/50000 (20%)]#011Loss: 2.145819\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [11520/50000 (23%)]#011Loss: 2.236228\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [12800/50000 (26%)]#011Loss: 2.095950\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [14080/50000 (28%)]#011Loss: 2.144864\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [15360/50000 (31%)]#011Loss: 2.111851\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [16640/50000 (33%)]#011Loss: 2.137305\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [17920/50000 (36%)]#011Loss: 2.081804\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [19200/50000 (38%)]#011Loss: 2.292255\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [20480/50000 (41%)]#011Loss: 2.264122\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [21760/50000 (43%)]#011Loss: 2.190651\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [23040/50000 (46%)]#011Loss: 2.021538\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [24320/50000 (49%)]#011Loss: 2.524402\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [25600/50000 (51%)]#011Loss: 2.101297\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [26880/50000 (54%)]#011Loss: 2.123061\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [28160/50000 (56%)]#011Loss: 2.310217\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [29440/50000 (59%)]#011Loss: 2.264272\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [30720/50000 (61%)]#011Loss: 2.019960\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [32000/50000 (64%)]#011Loss: 2.093750\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [33280/50000 (66%)]#011Loss: 2.153221\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [34560/50000 (69%)]#011Loss: 2.111315\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [35840/50000 (72%)]#011Loss: 2.141155\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [37120/50000 (74%)]#011Loss: 2.207144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [38400/50000 (77%)]#011Loss: 2.186756\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [39680/50000 (79%)]#011Loss: 2.162329\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [40960/50000 (82%)]#011Loss: 2.105611\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [42240/50000 (84%)]#011Loss: 2.045519\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [43520/50000 (87%)]#011Loss: 2.212914\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [44800/50000 (90%)]#011Loss: 2.059416\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [46080/50000 (92%)]#011Loss: 2.008388\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [47360/50000 (95%)]#011Loss: 2.200264\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [48640/50000 (97%)]#011Loss: 2.127575\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 20 [31200/50000 (100%)]#011Loss: 2.102864\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Training is finished\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:Training is finished\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:Training is finished\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Training is finished\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Training is finished\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:Training is finished\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Training is finished\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Training is finished\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Training is finished\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:Training is finished\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:Training is finished\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:Training is finished\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Training is finished\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:Training is finished\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:Training is finished\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: -0.0159, Accuracy: 121/10000 (1%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Training is finished\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Saving the model.\u001b[0m\n",
      "\u001b[35m2021-09-27 14:14:23,526 sagemaker-training-toolkit INFO     Orted process exited\u001b[0m\n",
      "\u001b[34mWarning: Permanently added 'algo-2,10.2.249.254' (ECDSA) to the list of known hosts.#015\n",
      "\u001b[0m\n",
      "\u001b[34m2021-09-27 14:14:23,512 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[35m2021-09-27 14:14:53,555 sagemaker-training-toolkit INFO     MPI process finished.\u001b[0m\n",
      "\u001b[35m2021-09-27 14:14:53,555 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-09-27 14:15:07 Uploading - Uploading generated training model\n",
      "2021-09-27 14:15:07 Completed - Training job completed\n",
      "Training seconds: 846\n",
      "Billable seconds: 846\n"
     ]
    }
   ],
   "source": [
    "estimator.logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 정리 작업\n",
    "\n",
    "## 모델 아티펙트 저장\n",
    "- S3 에 저장된 모델 아티펙트를 저장하여 추론시 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ddp_artifact_path:  s3://sagemaker-us-east-1-057716757052/cifar10-ddp-2021-09-27-14-04-32-403/output/model.tar.gz\n",
      "Stored 'ddp_artifact_path' (str)\n"
     ]
    }
   ],
   "source": [
    "ddp_artifact_path = estimator.model_data\n",
    "print(\"ddp_artifact_path: \", ddp_artifact_path)\n",
    "\n",
    "\n",
    "%store ddp_artifact_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-27 14:15:01     230774 cifar10-ddp-2021-09-27-14-04-32-403/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "! aws s3 ls {ddp_artifact_path} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
